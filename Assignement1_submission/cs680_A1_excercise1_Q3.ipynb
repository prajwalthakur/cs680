{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Question-3"
      ],
      "metadata": {
        "id": "BDzCk5bz1b_G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6xTklOd0koxk",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# @title include the libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import genfromtxt\n",
        "import pdb\n",
        "from matplotlib import pyplot as plt\n",
        "import math\n",
        "from itertools import combinations"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mVAHN1xeheRh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Load the training Data\n",
        "import numpy as np\n",
        "\n",
        "def ReadX(path):\n",
        "    print(f'>>> Reading data from: {path} ...')\n",
        "    with open(path) as f:\n",
        "        # only one line that includes everything\n",
        "        file = f.readlines()\n",
        "\n",
        "    print(f'#instances: {len(file)}') # 7352 for training set, 2947 for test set\n",
        "\n",
        "    X_all = []\n",
        "    for instance in file:\n",
        "        f = filter(None, instance.split(' '))\n",
        "        instance_filterd = list(f)\n",
        "        instance_cleaned = [float(attr.strip()) for attr in instance_filterd]\n",
        "        X_all.append(instance_cleaned)\n",
        "    X_all = np.array(X_all)\n",
        "    print('>>> Reading finished! Data are converted to numpy array.')\n",
        "    print(f'shape of X: {X_all.shape} ==> each instance has {X_all.shape[1]} attributes.')\n",
        "\n",
        "    return X_all\n",
        "\n",
        "def ReadY(path):\n",
        "    print(f'>>> Reading data from: {path} ...')\n",
        "    with open(path) as f:\n",
        "        # only one line that includes everything\n",
        "        file = f.readlines()\n",
        "\n",
        "        print(f'#instances: {len(file)}')  # 7352 for training set, 2947 for test set\n",
        "\n",
        "    y_all = [float(label.strip()) for label in file]\n",
        "    y_all = np.array(y_all)\n",
        "    print('>>> Reading finished! Data are converted to numpy array.')\n",
        "    print(f'shape of y: {y_all.shape}')\n",
        "    return y_all\n",
        "\n",
        "\n",
        "\n",
        "# You can change the path of the files\n",
        "X_train = ReadX('/content/activity_X_train.txt')\n",
        "y_train = ReadY('/content/activity_y_train.txt')\n",
        "\n",
        "X_test = ReadX('/content/activity_X_test.txt')\n",
        "y_test = ReadY('/content/activity_y_test.txt')\n",
        "\n",
        "\n",
        "# num_features = X_train.shape[0]\n",
        "# num_training_example = training_data.shape[1]\n",
        "# num_training_labels = training_labels.shape[0]\n",
        "# print(\"num of features =\",num_features,\"num_training_example=\",num_training_example)\n",
        "# print(\"num_labels=\",num_training_labels)"
      ],
      "metadata": {
        "id": "skD5zeppoU4N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "c0006dc3-33d6-4423-e615-7407fbb9cc72"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> Reading data from: /content/activity_X_train.txt ...\n",
            "#instances: 7352\n",
            ">>> Reading finished! Data are converted to numpy array.\n",
            "shape of X: (7352, 561) ==> each instance has 561 attributes.\n",
            ">>> Reading data from: /content/activity_y_train.txt ...\n",
            "#instances: 7352\n",
            ">>> Reading finished! Data are converted to numpy array.\n",
            "shape of y: (7352,)\n",
            ">>> Reading data from: /content/activity_X_test.txt ...\n",
            "#instances: 2947\n",
            ">>> Reading finished! Data are converted to numpy array.\n",
            "shape of X: (2947, 561) ==> each instance has 561 attributes.\n",
            ">>> Reading data from: /content/activity_y_test.txt ...\n",
            "#instances: 2947\n",
            ">>> Reading finished! Data are converted to numpy array.\n",
            "shape of y: (2947,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title  Implementation of perceptron Algorithm (Binary Classification)\n",
        "def perceptron_algo(X:np.asarray,y:np.asarray,max_pass:int=500, w:np.asarray=np.zeros((57,1)),b:np.float32=0):\n",
        "  mistakes = np.zeros((0)) # to record the mistakes in each iteration\n",
        "  num_features = X.shape[0]\n",
        "  num_training_example = X.shape[1]\n",
        "  for j in range(max_pass):\n",
        "    mistake_t = 0\n",
        "    for i in range(num_training_example):\n",
        "      if(y[i]*(X[:,i][...,np.newaxis].T@w+b).squeeze() <= 0) :\n",
        "        w = w + y[i]*X[:,i][...,np.newaxis]\n",
        "        b = b + y[i]\n",
        "        mistake_t+=1\n",
        "    mistakes = np.hstack((mistakes,np.asarray([mistake_t])))\n",
        "    #print(f\"mistake-at-{j}\",mistake_t)\n",
        "  return w,b,mistakes"
      ],
      "metadata": {
        "id": "Dh0ZjkNrmx_n"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Multiclass-Perceptron (One Vs One), This calls the perceptron_algo for a pair of  labels\n",
        "def perceptron_algo_multiclass(X:np.asarray,y:np.asarray,w,b,max_pass:int=500,num_classes:int=1):\n",
        "  num_perceptron_models = math.comb(num_classes, 2)   #(n(6,2))\n",
        "  class_pairs =  list(combinations(np.arange(1,num_classes+1), 2)) # for 6 classes , this will calculate the pairs = [(1,2),(1,3),(1,4),(1,5),(1,6),(2,3),(2,4),(2,5),(2,6),(3,4),(3,5),(3,6),(4,5),(4,6),(5,6)]\n",
        "  mistakes = np.zeros((num_perceptron_models,max_pass))\n",
        "  w_final = np.zeros((num_perceptron_models,X.shape[0],1))\n",
        "  print(\"num-perceptron\",num_perceptron_models)\n",
        "  b_final = np.zeros((num_perceptron_models,))\n",
        "  for i in range(num_perceptron_models):\n",
        "    class_k = class_pairs[i][0]\n",
        "    class_k_ = class_pairs[i][1]\n",
        "    print(\"Training for the Class pair:\",class_k,\" & \",class_k_)\n",
        "    # The following three lines of code perform data isolation for binary classification. They filter the training data to include only instances where the label belongs to either class_k or class_k_.\n",
        "    #This effectively creates a new dataset specifically for training a linear separator that can distinguish between these two classes.\n",
        "    idx_ = np.argwhere((y == class_k ) | (y == class_k_)).squeeze()\n",
        "    X_i = X[:,idx_]\n",
        "    Y_i = y[idx_]\n",
        "    # Preparing the data for Binary Perceptron Algorithm\n",
        "    y_i = -1*np.ones([X_i.shape[1],])\n",
        "    idx = np.argwhere(Y_i == class_k)\n",
        "    y_i[idx] = 1\n",
        "    # calling binary perceptron algorithm\n",
        "    w_i,b_i,mistake_i = perceptron_algo(X_i,y_i,max_pass=500, w=w[i,:,:],b=b[i])\n",
        "    # storing Weights , bias and mistakes\n",
        "    w_final[i,:,:] = w_i\n",
        "    b_final[i] = b_i\n",
        "    mistakes[i] = mistake_i\n",
        "    print(f\"final-mistake for class-{i+1}:=\",mistake_i[-1])\n",
        "  return w_final,b_final,mistakes"
      ],
      "metadata": {
        "id": "Ss7ybpIJ8-J3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Calling Perceptron Algorithm\n",
        "X = X_train.T\n",
        "y = y_train\n",
        "max_pass_itr = 500\n",
        "num_classes = 6\n",
        "num_perceptron_models = math.comb(num_classes, 2)\n",
        "num_features = X.shape[0]\n",
        "w,b,mistakes = perceptron_algo_multiclass(X,y,w=np.zeros((num_perceptron_models,num_features,1)),b=np.zeros((num_perceptron_models,)) , max_pass=max_pass_itr,num_classes=6)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "gDyeGZF8u_A1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9feeaee-db59-419d-82c5-eb210ae24c4c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num-perceptron 15\n",
            "Training for the Class pair: 1  &  2\n",
            "final-mistake for class-1:= 0.0\n",
            "Training for the Class pair: 1  &  3\n",
            "final-mistake for class-2:= 0.0\n",
            "Training for the Class pair: 1  &  4\n",
            "final-mistake for class-3:= 0.0\n",
            "Training for the Class pair: 1  &  5\n",
            "final-mistake for class-4:= 0.0\n",
            "Training for the Class pair: 1  &  6\n",
            "final-mistake for class-5:= 0.0\n",
            "Training for the Class pair: 2  &  3\n",
            "final-mistake for class-6:= 0.0\n",
            "Training for the Class pair: 2  &  4\n",
            "final-mistake for class-7:= 0.0\n",
            "Training for the Class pair: 2  &  5\n",
            "final-mistake for class-8:= 0.0\n",
            "Training for the Class pair: 2  &  6\n",
            "final-mistake for class-9:= 0.0\n",
            "Training for the Class pair: 3  &  4\n",
            "final-mistake for class-10:= 0.0\n",
            "Training for the Class pair: 3  &  5\n",
            "final-mistake for class-11:= 0.0\n",
            "Training for the Class pair: 3  &  6\n",
            "final-mistake for class-12:= 0.0\n",
            "Training for the Class pair: 4  &  5\n",
            "final-mistake for class-13:= 44.0\n",
            "Training for the Class pair: 4  &  6\n",
            "final-mistake for class-14:= 0.0\n",
            "Training for the Class pair: 5  &  6\n",
            "final-mistake for class-15:= 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Calculating Metrices\n",
        "total_training_error = np.sum(mistakes[:,-1])\n",
        "print(f\"total-training-error=\",total_training_error)"
      ],
      "metadata": {
        "id": "7ssYV5ljYvWl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9a88cc6-d428-4d2a-ec61-d5e7b104c5cf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total-training-error= 44.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Evaluation on Testing Dataset\n",
        "test_data = X_test.T\n",
        "test_true_label = y_test\n",
        "mistakes_test = 0\n",
        "w = w.squeeze()\n",
        "class_pairs =  list(combinations(np.arange(1,num_classes+1), 2))\n",
        "for i in range(test_data.shape[1]):\n",
        "  temp = np.zeros((num_perceptron_models))\n",
        "  for j in range(num_perceptron_models):\n",
        "    predicted_test_output = w[j,:]@test_data[:,i]+ b[j]\n",
        "    if (predicted_test_output>0):\n",
        "      #print(class_pairs[j][0])\n",
        "      temp[j] = class_pairs[j][0]\n",
        "    else:\n",
        "      temp[j] = class_pairs[j][1]\n",
        "  # count the maximum occurance of a number in an array , this is to find a class-k which is repeated  most in temp\n",
        "  # Count occurrences of each unique element\n",
        "  unique, counts = np.unique(temp, return_counts=True)\n",
        "  # Find the index of the maximum count\n",
        "  max_count_index = np.argmax(counts)\n",
        "  # Get the number that occurs the maximum number of times\n",
        "  predicted_test_label = unique[max_count_index]\n",
        "  # checking if mistakes has occured\n",
        "  if test_true_label[i] != predicted_test_label:\n",
        "    mistakes_test+=1\n",
        "print(\"Total mistakes-in-test-data\",mistakes_test)"
      ],
      "metadata": {
        "id": "2Zi_c76_I7Pg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fefdf81-f5fe-4b72-9b79-fa3b94da1832",
        "collapsed": true
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total mistakes-in-test-data 148\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F8Xrfsu3oFVi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}