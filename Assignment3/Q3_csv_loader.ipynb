{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70060883",
   "metadata": {},
   "source": [
    "## Data Split for default of credit card clients dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37e9451",
   "metadata": {},
   "source": [
    "We first load the dataset from the .xls file (downloaded from https://archive.ics.uci.edu/ml/machine-learning-databases/00350/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99f4b361",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# here we use pandas to read xls file conveniently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cb1b89a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30001, 25)\n",
      "['ID' 'LIMIT_BAL' 'SEX' 'EDUCATION' 'MARRIAGE' 'AGE' 'PAY_0' 'PAY_2'\n",
      " 'PAY_3' 'PAY_4' 'PAY_5' 'PAY_6' 'BILL_AMT1' 'BILL_AMT2' 'BILL_AMT3'\n",
      " 'BILL_AMT4' 'BILL_AMT5' 'BILL_AMT6' 'PAY_AMT1' 'PAY_AMT2' 'PAY_AMT3'\n",
      " 'PAY_AMT4' 'PAY_AMT5' 'PAY_AMT6' 'default payment next month']\n"
     ]
    }
   ],
   "source": [
    "data_df=pd.read_excel('default.xls')\n",
    "data_df.dropna(inplace=True)\n",
    "\n",
    "# here we see that there are 30000 instances in total and 25 features\n",
    "# Note that data is DataFrame type\n",
    "print(data_df.shape)\n",
    "\n",
    "# now we transfer the data to numpy arrays\n",
    "data_np = data_df.to_numpy()\n",
    "\n",
    "# here we can see the name of the features\n",
    "print(data_np[0])\n",
    "\n",
    "# the feature names and IDs are irrelevant to training/test, thus we remove them\n",
    "data_np = data_np[1:,1:]\n",
    "\n",
    "# let us randomly permute the dataset\n",
    "np.random.seed(0) # fix the random seed for ease of marking\n",
    "data_np = np.random.permutation(data_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be52e20",
   "metadata": {},
   "source": [
    "now we want to check if the data is balanced with respect to the target value, i.e., default payment next month:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bbfd301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6636\n"
     ]
    }
   ],
   "source": [
    "target = data_np[:,23]\n",
    "print(target.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "819f6438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 1, 0, 0, 0], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa34ffe",
   "metadata": {},
   "source": [
    "Here we clearly identiy only 6636 out of 30000 (around 22%) of clients will default next month. Thus we want to split the data carefully such that this ratio is mantained across training and test data.\n",
    "\n",
    "Next we aplit the dataset to training (20000 instances) and test (10000 instances). Thus we need to have (6636*2)/3=4424 positive samples and 15576 negative samples in training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e15a825e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_np = []\n",
    "test_np = []\n",
    "pos_count = 0\n",
    "for i,sample in enumerate(data_np):\n",
    "    if len(train_np)==20000:\n",
    "        test_np.append(sample)\n",
    "    else:\n",
    "        if sample[23]==1:\n",
    "            if pos_count<4424:\n",
    "                train_np.append(sample)\n",
    "            else:\n",
    "                test_np.append(sample)\n",
    "            pos_count+=1\n",
    "        else:\n",
    "            train_np.append(sample)\n",
    "    \n",
    "train_np = np.array(train_np)\n",
    "test_np = np.array(test_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3925db6d",
   "metadata": {},
   "source": [
    "Then we verify the correctness of such split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "123aacbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 24)\n",
      "4363\n",
      "(10000, 24)\n",
      "2273\n"
     ]
    }
   ],
   "source": [
    "print(train_np.shape)\n",
    "print(train_np[:,23].sum())\n",
    "print(test_np.shape)\n",
    "print(test_np[:,23].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76a5a8f",
   "metadata": {},
   "source": [
    "Finally, we save the data split using pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46f4da50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"train_test_split.pkl\", \"bw\") as fh:\n",
    "    data = (train_np, test_np)\n",
    "    pickle.dump(data, fh)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
