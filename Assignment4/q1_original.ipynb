{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ImmyKcwQPvJB",
    "outputId": "afe0e42e-4f47-4c68-dcef-f6e98146c1b8"
   },
   "source": [
    "### Assignment 4 Generative Adversarial Nets (Unconditional, 10 pts)\n",
    "\n",
    "\n",
    "In this exercise, we will implement a Generative Adversarial Net (GAN), specifically, a Wasserstein GAN and train it on the MNIST dataset. *We recommend completing this assignment using Google Colab with Chrome Browser*.\n",
    "\n",
    "**Submit**\n",
    "1. (<font color='red'>Doc A</font>) Include the two figures at the end in the pdf generated by the latex file with Exercise 2\n",
    "2. (<font color='red'>Doc B</font>) The completed *.ipynb file with all the command outputs (can be created by saving the file after finishing the experiment and downloading it from Colab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "\n",
    "1. In Colab, open tab Runtime > Change runtime type, choose *python3* and *T4 GPU*.\n",
    "2. Run the following command to set up the environment. (Takes ~ 1.5 min)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --quiet \"ipython[notebook]==7.34.0, <8.17.0\" \"setuptools>=68.0.0, <68.3.0\"  \"torch==1.13.0\" \"matplotlib\"  \"torchvision\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with importing our standard set of libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim, autograd\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils as vutils\n",
    "from dataclasses import dataclass\n",
    "import time\n",
    "import sys\n",
    "%matplotlib inline\n",
    "torch.set_num_threads(1)\n",
    "torch.manual_seed(1)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "if device == torch.device(\"cuda:0\"):\n",
    "  print('Everything looks good; continue')\n",
    "else:\n",
    "  # It is OK if you cannot connect to a GPU. In this case, training the model for\n",
    "  # 2 epoch is sufficient to get full mark. (NOTE THAT 2 epoch takes approximately 1.5 hours to train for CPU)\n",
    "  print('GPU is not detected. Make sure you have chosen the right runtime type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloaders and hyperparameters (0 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qljorf0rVrwv"
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Hyperparameter:\n",
    "    batchsize: int          = 64\n",
    "    num_epochs: int         = 5\n",
    "    latent_size: int        = 32\n",
    "    n_critic: int           = 5\n",
    "    critic_size: int        = 1024\n",
    "    generator_size: int     = 1024\n",
    "    critic_hidden_size: int = 1024\n",
    "    gp_lambda: float        = 10.\n",
    "        \n",
    "hp = Hyperparameter()\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "                                \n",
    "dataset  = torchvision.datasets.MNIST(\"mnist\", download=True, transform=transform)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=hp.batchsize, num_workers=1, shuffle=True, drop_last=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Models (2 pts)\n",
    "\n",
    "After examining the preprocessing steps, we can now start building the models, including the generator for generating new images from random noise, and a critic of the realness of the image.\n",
    "\n",
    "\n",
    "In this assignment we adopt the implementation of [DCGAN](https://arxiv.org/pdf/1511.06434), which is a direct extension of [GAN](https://proceedings.neurips.cc/paper_files/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf), with convolutional and convolutional-transpose layers in the critic and genrator, respectively. Specifically, we will use the [ConvTranspose2d](https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html) layers to upscale the noise.\n",
    "\n",
    "Moreover, we apply an improved version of [Wasserstein-GAN](https://arxiv.org/pdf/1701.07875) with a [Gradient Penalty](https://arxiv.org/pdf/1704.00028) (you may read Algorithm 1 to fully understand the code we are implementing). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "u05eDLLwbYAo",
    "outputId": "20775a1f-2619-42b8-e5e0-7dfba19e4f0f"
   },
   "outputs": [],
   "source": [
    "# Define the generator\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        #VVVVVVVVVVV TO BE COMPLETE (START) VVVVVVVVVVVV\n",
    "        # Add latent embedding layer to adjust the dimension of the input (1 pt)\n",
    "\n",
    "        # Hint: you should use the hyperparameters defined above\n",
    "\n",
    "        self.latent_embedding = \n",
    "        \n",
    "        # ^^^^^^^^^^^^ TO BE COMPLETE (END) ^^^^^^^^^^^^\n",
    "        \n",
    "        \n",
    "        # Transposed CNN layers to transfer noise to image \n",
    "        \n",
    "        self.tcnn = nn.Sequential(\n",
    "        # input is Z, going into a convolution\n",
    "        nn.ConvTranspose2d(hp.generator_size, hp.generator_size, 4, 1, 0),\n",
    "        nn.BatchNorm2d(hp.generator_size),\n",
    "        nn.ReLU(inplace=True),\n",
    "        # upscaling\n",
    "        nn.ConvTranspose2d(hp.generator_size, hp.generator_size // 2, 3, 2, 1),\n",
    "        nn.BatchNorm2d(hp.generator_size // 2),\n",
    "        nn.ReLU(inplace=True),\n",
    "        # upscaling\n",
    "        nn.ConvTranspose2d(hp.generator_size // 2, hp.generator_size // 4, 4, 2, 1),\n",
    "        nn.BatchNorm2d(hp.generator_size // 4),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.ConvTranspose2d(hp.generator_size // 4, 1, 4, 2, 1),\n",
    "        nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, latent):\n",
    "        vec_latent = self.latent_embedding(latent).reshape(-1, hp.generator_size, 1, 1)\n",
    "        return self.tcnn(vec_latent)\n",
    "\n",
    "    \n",
    "# Define the critic\n",
    "\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Critic, self).__init__()\n",
    "        \n",
    "        # CNN layers that perform downscaling\n",
    "        self.cnn_net = nn.Sequential(\n",
    "        nn.Conv2d(1, hp.critic_size // 4, 3, 2),\n",
    "        nn.InstanceNorm2d(hp.critic_size // 4, affine=True),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        nn.Conv2d(hp.critic_size // 4, hp.critic_size // 2, 3, 2),\n",
    "        nn.InstanceNorm2d(hp.critic_size // 2, affine=True),\n",
    "        nn.LeakyReLU(0.2, inplace=True),   \n",
    "        nn.Conv2d(hp.critic_size // 2, hp.critic_size, 3, 2),\n",
    "        nn.InstanceNorm2d(hp.critic_size, affine=True),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        nn.Flatten(),\n",
    "        )\n",
    "        \n",
    "        # Linear layers that produce the output from the features\n",
    "        self.critic_net = nn.Sequential(\n",
    "        nn.Linear(hp.critic_size * 4, hp.critic_hidden_size),\n",
    "        nn.LeakyReLU(0.2, inplace=True), \n",
    "            \n",
    "        #VVVVVVVVVVV TO BE COMPLETE (START) VVVVVVVVVVVV\n",
    "        # Add the last layer to reflect the output (1 pt)\n",
    "        \n",
    "\n",
    "        # Hint: Given an image, the output of the critic is a value (or a scalar)\n",
    "        \n",
    "        # ^^^^^^^^^^^^ TO BE COMPLETE (END) ^^^^^^^^^^^^\n",
    "        )\n",
    "    \n",
    "    def forward(self, image):\n",
    "        cnn_features = self.cnn_net(image)\n",
    "        return self.critic_net(cnn_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before Training \n",
    "\n",
    "Next we define the two models and the optimizers. We use the [AdamW](https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html) algorithm.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic, generator = Critic().to(device), Generator().to(device)\n",
    "\n",
    "critic_optimizer = optim.AdamW(critic.parameters(), lr=1e-4,betas=(0., 0.9))\n",
    "generator_optimizer = optim.AdamW(generator.parameters(), lr=1e-4,betas=(0., 0.9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training pipeline (6 points)\n",
    "\n",
    "\n",
    "Finally, we perform training on the two networks. The training consists of two steps: (1) Updating discriminators for n_critic steps (such that we have an optimal critic): here we use an aggregation of three loss functions, (a) The real loss (the output scalar of the critic for real images); (b) The fake loss (same value for fake images); (c) The [gradient penalty](https://arxiv.org/pdf/1704.00028). (2) Updating generators by only considering the fake loss (to fool the critic).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "AKkYiOC2P9mi",
    "outputId": "238aca44-9928-40df-f20f-45615efe7853"
   },
   "outputs": [],
   "source": [
    "img_list, generator_losses, critic_losses = [], [], []\n",
    "iters = 0\n",
    "fixed_noise = torch.randn((64, hp.latent_size), device=device)\n",
    "grad_tensor = torch.ones((hp.batchsize, 1), device=device)\n",
    "start_time = time.time()\n",
    "for epoch in range(hp.num_epochs):\n",
    "    for batch_idx, data in enumerate(dataloader, 0):\n",
    "        real_images = data[0].to(device)\n",
    "        \n",
    "        # Update Critic\n",
    "        critic_optimizer.zero_grad()\n",
    "        \n",
    "        # (a) Real loss\n",
    "        critic_output_real = critic(real_images)\n",
    "        critic_loss_real = critic_output_real.mean()\n",
    "        \n",
    "        # (b) Fake loss\n",
    "        \n",
    "        #VVVVVVVVVVV TO BE COMPLETE (START) VVVVVVVVVVVV\n",
    "        # Implement the fake loss\n",
    "        \n",
    "        # (1) Generating a noise tensor (of dimension (batch_size, latent_size)), you are required to \n",
    "        # use the hyperparameters in the hp class (0.5 pt)\n",
    "        \n",
    "        noise = \n",
    "\n",
    "        # (2) Generate fake images using the generator (hint: you are not supposed to perform gradient\n",
    "        # update on the generator) (1.5 pts)\n",
    "\n",
    "        \n",
    "            fake_image =\n",
    "\n",
    "        # (3) Calculate the fake loss using the output of the generator (1 pt)\n",
    "        critic_output_fake = \n",
    "        critic_loss_fake = \n",
    "\n",
    "        # ^^^^^^^^^^^^ TO BE COMPLETE (END) ^^^^^^^^^^^^\n",
    "        \n",
    "        #  (c) Gradient penalty\n",
    "        alpha = torch.rand((hp.batchsize, 1, 1, 1), device=device)\n",
    "        interpolates = (alpha * real_images + ((1. - alpha) * fake_image)).requires_grad_(True)\n",
    "        d_interpolates = critic(interpolates)\n",
    "        gradients = autograd.grad(d_interpolates, interpolates, grad_tensor, create_graph=True, only_inputs=True)[0]\n",
    "        gradient_penalty = hp.gp_lambda * ((gradients.view(hp.batchsize, -1).norm(dim=1) - 1.) ** 2).mean()\n",
    "\n",
    "        #VVVVVVVVVVV TO BE COMPLETE (START) VVVVVVVVVVVV\n",
    "        # Implement the aggregated loss using the above three components, be careful with the signs (1 pt)\n",
    "        \n",
    "        critic_loss =\n",
    "        \n",
    "        # ^^^^^^^^^^^^ TO BE COMPLETE (END) ^^^^^^^^^^^  \n",
    "        \n",
    "        critic_loss.backward()\n",
    "        critic_optimizer.step()\n",
    "\n",
    "        if batch_idx % hp.n_critic == 0:\n",
    "            # Update Generator\n",
    "            generator_optimizer.zero_grad()\n",
    "            \n",
    "            \n",
    "            #VVVVVVVVVVV TO BE COMPLETE (START) VVVVVVVVVVVV\n",
    "            # Implement the generator loss (2 pts)\n",
    "\n",
    "            noise = \n",
    "            fake_image = \n",
    "            critic_output_fake =\n",
    "            generator_loss =\n",
    "\n",
    "            # ^^^^^^^^^^^^ TO BE COMPLETE (END) ^^^^^^^^^^^^\n",
    "            \n",
    "            generator_loss.backward()\n",
    "            generator_optimizer.step()\n",
    "        \n",
    "        # Output training stats\n",
    "        if batch_idx % 100 == 0:\n",
    "            elapsed_time = time.time() - start_time\n",
    "            print(f\"[{epoch:>2}/{hp.num_epochs}][{iters:>7}][{elapsed_time:8.2f}s]\\t\"\n",
    "                  f\"d_loss/g_loss: {critic_loss.item():4.2}/{generator_loss.item():4.2}\\t\")\n",
    "       \n",
    "        # Save Losses for plotting later\n",
    "        generator_losses.append(generator_loss.item())\n",
    "        critic_losses.append(critic_loss.item())\n",
    "\n",
    "        # Check how the generator is doing by saving G's output on fixed_noise\n",
    "        if (iters % 500 == 0) or ((epoch == hp.num_epochs - 1) and (batch_idx == len(dataloader) - 1)):\n",
    "            with torch.no_grad(): fake_images = generator(fixed_noise).cpu()\n",
    "            img_list.append(vutils.make_grid(fake_images, padding=2, normalize=True))\n",
    "            \n",
    "        iters += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization (2 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JhDPdes7QYyf"
   },
   "outputs": [],
   "source": [
    "# Visualize the loss\n",
    "# include the figure in the latex file (1 pt)\n",
    "plt.title(\"Generator and Critic Loss During Training\")\n",
    "plt.plot(generator_losses,label=\"G\")\n",
    "plt.plot(critic_losses,label=\"D\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OX_sQ_1lTPdd"
   },
   "outputs": [],
   "source": [
    "# Visualize the generation (you may scroll to see the animation of training)\n",
    "# include the final figure in the latex file (1 pt)\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "#%%capture\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "ims = [[plt.imshow(i.permute(1,2,0), animated=True)] for i in img_list] \n",
    "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
    "\n",
    "HTML(ani.to_jshtml())"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "wgan.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
