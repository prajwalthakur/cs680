{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.13 (you have 1.4.10). Upgrade using: pip install --upgrade albumentations\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 \n",
    "import IPython\n",
    "from glob import glob\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tqdm\n",
    "#import seaborn as sns\n",
    "import albumentations as A\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "import torcheval \n",
    "import wandb\n",
    "import torchvision\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams.update(**{'figure.dpi':150})\n",
    "import psutil\n",
    "import imageio.v3 as imageio\n",
    "\n",
    "# %%\n",
    "RANDOM_NUMBER = 42\n",
    "torch.manual_seed(RANDOM_NUMBER)\n",
    "\n",
    "# %% [markdown]\n",
    "# # select Device\n",
    "\n",
    "# %%\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DATA_DIRECTORY = os.path.join(os.getcwd(),\"data\")\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# %%\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler , MinMaxScaler\n",
    "import scipy as sp\n",
    "\n",
    "# %%\n",
    "class Config():\n",
    "\n",
    "    BASE_DIR = os.path.join(os.getcwd() , 'data')\n",
    "    train_df = pd.read_csv(BASE_DIR  +  '/train.csv')\n",
    "    TRAIN_VAL_SPLIT_SIZE = 0.14\n",
    "    TRAIN_BATCH_SIZE = 128\n",
    "    VAL_BATCH_SIZE = 128\n",
    "    TEST_BATCH_SIZE =128\n",
    "    LR_MAX = 1e-4 \n",
    "    NUM_EPOCHS = 20\n",
    "    IMG_OUT_FEATURES = 512  # swin     #768<-vit   \n",
    "    NORMALIZE_TARGET = \"log_transform_mean_std\"   #\"log_transform\" #\n",
    "    RANDOM_NUMBER = 42\n",
    "    NUM_FLODS  = 5\n",
    "    NUM_CLASSES = 6\n",
    "    TRAITS_NAME = ['X4_mean', 'X11_mean', 'X18_mean', 'X26_mean', 'X50_mean', 'X3112_mean' ]\n",
    "    WANDB_INIT =  False\n",
    "    FOLD = 0 # Which fold to set as validation data\n",
    "    IMAGE_SIZE =128\n",
    "    TARGET_IMAGE_SIZE =  256\n",
    "    T_MAX =        9\n",
    "    torch.manual_seed(RANDOM_NUMBER)\n",
    "    INCLUDE_EXTRA_FEATURES = True\n",
    "    EXTRA_FEATURES_NORMALIZATION = \"standard_scalar\"  #\"min_max_normalization\"  #\n",
    "    WEIGHT_DECAY = 0.01\n",
    "    TABULAR_NN_OUTPUT  = 256\n",
    "    IMG_MODEL_NAME = \"swinV2\" #\"efficientnet_v2\" # \n",
    "    IMG_FINED_TUNED_WEIGHT = f'{BASE_DIR}/swinV2.pth'\n",
    "    Lower_Quantile = 0.005\n",
    "    Upper_Quantile = 0.99 #0.985\n",
    "    # use XGBBOOST to find prominant features\n",
    "    EXTRA_COLOUMN = ['WORLDCLIM_BIO1_annual_mean_temperature',\n",
    "       'WORLDCLIM_BIO12_annual_precipitation',\n",
    "       'WORLDCLIM_BIO13.BIO14_delta_precipitation_of_wettest_and_dryest_month',\n",
    "       'WORLDCLIM_BIO15_precipitation_seasonality',\n",
    "       'WORLDCLIM_BIO4_temperature_seasonality',\n",
    "       'WORLDCLIM_BIO7_temperature_annual_range',\n",
    "       'SOIL_bdod_0.5cm_mean_0.01_deg',\n",
    "       'SOIL_bdod_100.200cm_mean_0.01_deg',\n",
    "       'SOIL_bdod_15.30cm_mean_0.01_deg',\n",
    "       'SOIL_bdod_30.60cm_mean_0.01_deg',\n",
    "       'SOIL_bdod_5.15cm_mean_0.01_deg',\n",
    "       'SOIL_bdod_60.100cm_mean_0.01_deg', 'SOIL_cec_0.5cm_mean_0.01_deg',\n",
    "       'SOIL_cec_100.200cm_mean_0.01_deg',\n",
    "       'SOIL_cec_15.30cm_mean_0.01_deg', 'SOIL_cec_30.60cm_mean_0.01_deg',\n",
    "       'SOIL_cec_5.15cm_mean_0.01_deg', 'SOIL_cec_60.100cm_mean_0.01_deg',\n",
    "       'SOIL_cfvo_0.5cm_mean_0.01_deg',\n",
    "       'SOIL_cfvo_100.200cm_mean_0.01_deg',\n",
    "       'SOIL_cfvo_15.30cm_mean_0.01_deg',\n",
    "       'SOIL_cfvo_30.60cm_mean_0.01_deg',\n",
    "       'SOIL_cfvo_5.15cm_mean_0.01_deg',\n",
    "       'SOIL_cfvo_60.100cm_mean_0.01_deg',\n",
    "       'SOIL_clay_0.5cm_mean_0.01_deg',\n",
    "       'SOIL_clay_100.200cm_mean_0.01_deg',\n",
    "       'SOIL_clay_15.30cm_mean_0.01_deg',\n",
    "       'SOIL_clay_30.60cm_mean_0.01_deg',\n",
    "       'SOIL_clay_5.15cm_mean_0.01_deg',\n",
    "       'SOIL_clay_60.100cm_mean_0.01_deg',\n",
    "       'SOIL_nitrogen_0.5cm_mean_0.01_deg',\n",
    "       'SOIL_nitrogen_100.200cm_mean_0.01_deg',\n",
    "       'SOIL_nitrogen_15.30cm_mean_0.01_deg',\n",
    "       'SOIL_nitrogen_30.60cm_mean_0.01_deg',\n",
    "       'SOIL_nitrogen_5.15cm_mean_0.01_deg',\n",
    "       'SOIL_nitrogen_60.100cm_mean_0.01_deg',\n",
    "       'SOIL_ocd_0.5cm_mean_0.01_deg', 'SOIL_ocd_100.200cm_mean_0.01_deg',\n",
    "       'SOIL_ocd_15.30cm_mean_0.01_deg', 'SOIL_ocd_30.60cm_mean_0.01_deg',\n",
    "       'SOIL_ocd_5.15cm_mean_0.01_deg', 'SOIL_ocd_60.100cm_mean_0.01_deg',\n",
    "       'SOIL_ocs_0.30cm_mean_0.01_deg', 'SOIL_phh2o_0.5cm_mean_0.01_deg',\n",
    "       'SOIL_phh2o_100.200cm_mean_0.01_deg',\n",
    "       'SOIL_phh2o_15.30cm_mean_0.01_deg',\n",
    "       'SOIL_phh2o_30.60cm_mean_0.01_deg',\n",
    "       'SOIL_phh2o_5.15cm_mean_0.01_deg',\n",
    "       'SOIL_phh2o_60.100cm_mean_0.01_deg',\n",
    "       'SOIL_sand_0.5cm_mean_0.01_deg',\n",
    "       'SOIL_sand_100.200cm_mean_0.01_deg',\n",
    "       'SOIL_sand_15.30cm_mean_0.01_deg',\n",
    "       'SOIL_sand_30.60cm_mean_0.01_deg',\n",
    "       'SOIL_sand_5.15cm_mean_0.01_deg',\n",
    "       'SOIL_sand_60.100cm_mean_0.01_deg',\n",
    "       'SOIL_silt_0.5cm_mean_0.01_deg',\n",
    "       'SOIL_silt_100.200cm_mean_0.01_deg',\n",
    "       'SOIL_silt_15.30cm_mean_0.01_deg',\n",
    "       'SOIL_silt_30.60cm_mean_0.01_deg',\n",
    "       'SOIL_silt_5.15cm_mean_0.01_deg',\n",
    "       'SOIL_silt_60.100cm_mean_0.01_deg', 'SOIL_soc_0.5cm_mean_0.01_deg',\n",
    "       'SOIL_soc_100.200cm_mean_0.01_deg',\n",
    "       'SOIL_soc_15.30cm_mean_0.01_deg', 'SOIL_soc_30.60cm_mean_0.01_deg',\n",
    "       'SOIL_soc_5.15cm_mean_0.01_deg', 'SOIL_soc_60.100cm_mean_0.01_deg',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_01_._month_m1',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_02_._month_m1',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_03_._month_m1',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_04_._month_m1',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_05_._month_m1',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_01_._month_m10',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_02_._month_m10',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_03_._month_m10',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_04_._month_m10',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_05_._month_m10',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_01_._month_m11',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_02_._month_m11',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_03_._month_m11',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_04_._month_m11',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_05_._month_m11',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_01_._month_m12',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_02_._month_m12',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_03_._month_m12',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_04_._month_m12',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_05_._month_m12',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_01_._month_m2',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_02_._month_m2',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_03_._month_m2',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_04_._month_m2',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_05_._month_m2',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_01_._month_m3',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_02_._month_m3',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_03_._month_m3',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_04_._month_m3',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_05_._month_m3',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_01_._month_m4',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_02_._month_m4',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_03_._month_m4',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_04_._month_m4',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_05_._month_m4',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_01_._month_m5',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_02_._month_m5',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_03_._month_m5',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_04_._month_m5',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_05_._month_m5',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_01_._month_m6',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_02_._month_m6',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_03_._month_m6',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_04_._month_m6',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_05_._month_m6',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_01_._month_m7',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_02_._month_m7',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_03_._month_m7',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_04_._month_m7',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_05_._month_m7',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_01_._month_m8',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_02_._month_m8',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_03_._month_m8',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_04_._month_m8',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_05_._month_m8',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_01_._month_m9',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_02_._month_m9',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_03_._month_m9',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_04_._month_m9',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_05_._month_m9',\n",
    "       'VOD_C_2002_2018_multiyear_mean_m01',\n",
    "       'VOD_C_2002_2018_multiyear_mean_m02',\n",
    "       'VOD_C_2002_2018_multiyear_mean_m03',\n",
    "       'VOD_C_2002_2018_multiyear_mean_m04',\n",
    "       'VOD_C_2002_2018_multiyear_mean_m05',\n",
    "       'VOD_C_2002_2018_multiyear_mean_m06',\n",
    "       'VOD_C_2002_2018_multiyear_mean_m07',\n",
    "       'VOD_C_2002_2018_multiyear_mean_m08',\n",
    "       'VOD_C_2002_2018_multiyear_mean_m09',\n",
    "       'VOD_C_2002_2018_multiyear_mean_m10',\n",
    "       'VOD_C_2002_2018_multiyear_mean_m11',\n",
    "       'VOD_C_2002_2018_multiyear_mean_m12',\n",
    "       'VOD_Ku_1987_2017_multiyear_mean_m01',\n",
    "       'VOD_Ku_1987_2017_multiyear_mean_m02',\n",
    "       'VOD_Ku_1987_2017_multiyear_mean_m03',\n",
    "       'VOD_Ku_1987_2017_multiyear_mean_m04',\n",
    "       'VOD_Ku_1987_2017_multiyear_mean_m05',\n",
    "       'VOD_Ku_1987_2017_multiyear_mean_m06',\n",
    "       'VOD_Ku_1987_2017_multiyear_mean_m07',\n",
    "       'VOD_Ku_1987_2017_multiyear_mean_m08',\n",
    "       'VOD_Ku_1987_2017_multiyear_mean_m09',\n",
    "       'VOD_Ku_1987_2017_multiyear_mean_m10',\n",
    "       'VOD_Ku_1987_2017_multiyear_mean_m11',\n",
    "       'VOD_Ku_1987_2017_multiyear_mean_m12',\n",
    "       'VOD_X_1997_2018_multiyear_mean_m01',\n",
    "       'VOD_X_1997_2018_multiyear_mean_m02',\n",
    "       'VOD_X_1997_2018_multiyear_mean_m03',\n",
    "       'VOD_X_1997_2018_multiyear_mean_m04',\n",
    "       'VOD_X_1997_2018_multiyear_mean_m05',\n",
    "       'VOD_X_1997_2018_multiyear_mean_m06',\n",
    "       'VOD_X_1997_2018_multiyear_mean_m07',\n",
    "       'VOD_X_1997_2018_multiyear_mean_m08',\n",
    "       'VOD_X_1997_2018_multiyear_mean_m09',\n",
    "       'VOD_X_1997_2018_multiyear_mean_m10',\n",
    "       'VOD_X_1997_2018_multiyear_mean_m11',\n",
    "       'VOD_X_1997_2018_multiyear_mean_m12'\n",
    "       ]\n",
    "\n",
    "    \n",
    "    # EXTRA_COLOUMN =['VOD_C_2002_2018_multiyear_mean_m06',\n",
    "    # 'VOD_C_2002_2018_multiyear_mean_m01',\n",
    "    # 'SOIL_nitrogen_100.200cm_mean_0.01_deg',\n",
    "    # 'SOIL_nitrogen_0.5cm_mean_0.01_deg',\n",
    "    # 'SOIL_soc_0.5cm_mean_0.01_deg',\n",
    "    # 'SOIL_ocd_0.5cm_mean_0.01_deg',\n",
    "    # 'SOIL_bdod_0.5cm_mean_0.01_deg',\n",
    "    # 'SOIL_soc_100.200cm_mean_0.01_deg',\n",
    "    # 'WORLDCLIM_BIO15_precipitation_seasonality',\n",
    "    # 'SOIL_bdod_100.200cm_mean_0.01_deg',\n",
    "    # 'SOIL_ocd_100.200cm_mean_0.01_deg',\n",
    "    # 'SOIL_ocd_30.60cm_mean_0.01_deg',\n",
    "    # 'MODIS_2000.2020_monthly_mean_surface_reflectance_band_01_._month_m1',\n",
    "    # 'MODIS_2000.2020_monthly_mean_surface_reflectance_band_01_._month_m11',\n",
    "    # 'MODIS_2000.2020_monthly_mean_surface_reflectance_band_01_._month_m4',\n",
    "    # 'MODIS_2000.2020_monthly_mean_surface_reflectance_band_01_._month_m5',\n",
    "    # 'SOIL_phh2o_0.5cm_mean_0.01_deg',\n",
    "    # 'WORLDCLIM_BIO12_annual_precipitation',\n",
    "    # 'MODIS_2000.2020_monthly_mean_surface_reflectance_band_01_._month_m6',\n",
    "    # 'MODIS_2000.2020_monthly_mean_surface_reflectance_band_01_._month_m10',\n",
    "    # 'MODIS_2000.2020_monthly_mean_surface_reflectance_band_01_._month_m7',\n",
    "    # 'WORLDCLIM_BIO4_temperature_seasonality',\n",
    "    # 'WORLDCLIM_BIO13.BIO14_delta_precipitation_of_wettest_and_dryest_month',\n",
    "    # 'WORLDCLIM_BIO1_annual_mean_temperature',\n",
    "    # 'SOIL_cfvo_0.5cm_mean_0.01_deg',\n",
    "    # 'SOIL_clay_100.200cm_mean_0.01_deg',\n",
    "    # 'SOIL_clay_0.5cm_mean_0.01_deg',\n",
    "    # 'SOIL_silt_0.5cm_mean_0.01_deg',\n",
    "    # 'SOIL_sand_0.5cm_mean_0.01_deg',\n",
    "    # 'SOIL_cec_15.30cm_mean_0.01_deg',\n",
    "    # 'SOIL_cec_100.200cm_mean_0.01_deg',\n",
    "    # 'SOIL_cec_0.5cm_mean_0.01_deg',\n",
    "    # 'MODIS_2000.2020_monthly_mean_surface_reflectance_band_02_._month_m1',\n",
    "    # 'MODIS_2000.2020_monthly_mean_surface_reflectance_band_02_._month_m3',\n",
    "    # 'MODIS_2000.2020_monthly_mean_surface_reflectance_band_05_._month_m1',\n",
    "    # 'MODIS_2000.2020_monthly_mean_surface_reflectance_band_02_._month_m11',\n",
    "    # 'MODIS_2000.2020_monthly_mean_surface_reflectance_band_02_._month_m6',\n",
    "    # 'MODIS_2000.2020_monthly_mean_surface_reflectance_band_02_._month_m10',\n",
    "    # 'MODIS_2000.2020_monthly_mean_surface_reflectance_band_02_._month_m4',\n",
    "    # 'MODIS_2000.2020_monthly_mean_surface_reflectance_band_02_._month_m5',\n",
    "    # 'MODIS_2000.2020_monthly_mean_surface_reflectance_band_05_._month_m5',\n",
    "    # 'MODIS_2000.2020_monthly_mean_surface_reflectance_band_05_._month_m10',\n",
    "    # 'MODIS_2000.2020_monthly_mean_surface_reflectance_band_05_._month_m4']\n",
    "    N_TARGETS  =len(TRAITS_NAME)  \n",
    "\n",
    "\n",
    "CONFIG = Config()\n",
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "if CONFIG.WANDB_INIT:\n",
    "    wandb.login()\n",
    "    wandb.init(project=\"cs680v3\",group=\"swin_tf\",name=\"swinV2_large_self_fine_tuned\",\n",
    "            config = {\n",
    "        \"LR_max\": CONFIG.LR_MAX,\n",
    "        \"WEIGHT_DECAY\":CONFIG.WEIGHT_DECAY,\n",
    "        \"train_batch\" : CONFIG.TRAIN_BATCH_SIZE\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Preprocessing the Tabular Data And Image Transformation\n",
    "\n",
    "# %%\n",
    "# define_transformation for the tabular data\n",
    "log_tf_col = CONFIG.TRAITS_NAME\n",
    "scale_feature_col =  CONFIG.EXTRA_COLOUMN + CONFIG.TRAITS_NAME\n",
    "log_transform = ColumnTransformer(transformers= [\n",
    "    ('log' , FunctionTransformer( np.log10  , inverse_func=sp.special.exp10, validate=False, check_inverse = True ,feature_names_out='one-to-one') , log_tf_col)\n",
    "        ] , verbose_feature_names_out=False ,remainder= 'passthrough'\n",
    "          )\n",
    "log_transform.set_output(transform='pandas')\n",
    "\n",
    "std_scale =  ColumnTransformer(transformers=[('scale',StandardScaler() ,scale_feature_col )  ],\n",
    "                               verbose_feature_names_out=False,\n",
    "                               remainder='passthrough'\n",
    "                               )\n",
    "std_scale.set_output(transform='pandas')\n",
    "scaling_pipeline = Pipeline(steps=[   \n",
    "                        (\"log\" , log_transform),\n",
    "                        (\"std_scale\" , std_scale )])\n",
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "# preparing the tabular data that has been given \n",
    "BASE_DIR = CONFIG.BASE_DIR\n",
    "Train_DF = pd.read_csv(BASE_DIR  +  '/train.csv')\n",
    "Test_DF =  pd.read_csv(BASE_DIR  +  '/test.csv')\n",
    "Test_DF[log_tf_col] =1\n",
    "\n",
    "train_df , val_df = train_test_split(Train_DF,test_size=CONFIG.TRAIN_VAL_SPLIT_SIZE,shuffle=True)\n",
    "for column in CONFIG.TRAITS_NAME:\n",
    "    lower_quantile = train_df[column].quantile(CONFIG.Lower_Quantile)\n",
    "    upper_quantile = train_df[column].quantile(CONFIG.Upper_Quantile)\n",
    "    train_df = train_df[(train_df[column] >= lower_quantile) & (train_df[column] <= upper_quantile)]\n",
    "\n",
    "# train_df = train_df[(np.abs(stats.zscore(np.log10(train_df[CONFIG.TRAITS_NAME]))<2).all(axis=1)  )]\n",
    "\n",
    "print('JPEG Files Processing:')\n",
    "train_df['file_path'] = train_df['id'].apply(lambda s: f'{BASE_DIR}/train_images/{s}.jpeg')\n",
    "train_df['jpeg_bytes'] = train_df['file_path'].apply(lambda fp: open(fp, 'rb').read())\n",
    "\n",
    "val_df['file_path'] = val_df['id'].apply(lambda s: f'{BASE_DIR}/train_images/{s}.jpeg')\n",
    "val_df['jpeg_bytes'] = val_df['file_path'].apply(lambda fp: open(fp, 'rb').read())\n",
    "\n",
    "Test_DF['file_path'] = Test_DF['id'].apply(lambda s: f'{BASE_DIR}/test_images/{s}.jpeg')\n",
    "Test_DF['jpeg_bytes'] = Test_DF['file_path'].apply(lambda fp: open(fp, 'rb').read())\n",
    "print('JPEG Files Processing End')    \n",
    "\n",
    "\n",
    "# train_tabular = train_df.drop(columns = ['id'] + CONFIG.TRAITS_NAME)\n",
    "# val_tabular =    val_df.drop(columns = ['id'] + CONFIG.TRAITS_NAME)\n",
    "# test_tabular = test.drop(columns = ['id'])\n",
    "\n",
    "# scaling of the training data !\n",
    "\n",
    "training_scaling_pipeline = Pipeline(steps=[   \n",
    "                        (\"log\" , log_transform),\n",
    "                        (\"std_scale\" , std_scale )])\n",
    "\n",
    "train_tabular_scaled =  training_scaling_pipeline.fit_transform(train_df)\n",
    "validation_tabular_scaled = training_scaling_pipeline.transform(val_df)\n",
    "\n",
    "test_tabular_scaled = training_scaling_pipeline.transform(Test_DF)\n",
    "Test_DF[log_tf_col]\n",
    "\"inverse\"\n",
    "# tt =   scaling_pipeline['std_scale']['scale'].inverse_transform(train_tabular_scaled[CONFIG.EXTRA_COLOUMN + CONFIG.TRAITS_NAME])\n",
    "# tt = pd.DataFrame(tt, columns=CONFIG.EXTRA_COLOUMN + CONFIG.TRAITS_NAME)\n",
    "# tt2 = scaling_pipeline['log']['log'].inverse_transform(tt[CONFIG.TRAITS_NAME])\n",
    "# tt2  = pd.concat([tt2 ,tt[CONFIG.EXTRA_COLOUMN]],axis=1)                 \n",
    "                  \n",
    "\n",
    "\n",
    "# some hyper parameter for lr scheduler\n",
    "CONFIG.N_TRAIN_SAMPLES = len(train_df)\n",
    "CONFIG.N_STEPS_PER_EPOCH = (CONFIG.N_TRAIN_SAMPLES // CONFIG.TRAIN_BATCH_SIZE)\n",
    "CONFIG.N_STEPS = CONFIG.N_STEPS_PER_EPOCH * CONFIG.NUM_EPOCHS + 1   \n",
    "\n",
    "# %%\n",
    "# Image PreProcessing\n",
    "\n",
    "MEAN = [0.485, 0.456, 0.406]\n",
    "STD = [0.229, 0.224, 0.225]\n",
    "TRAIN_TRANSFORMS = A.Compose([\n",
    "    A.RandomResizedCrop(size=(CONFIG.TARGET_IMAGE_SIZE,CONFIG.TARGET_IMAGE_SIZE), interpolation=cv2.INTER_CUBIC ),  # Simulate different crops\n",
    "    #A.HorizontalFlip(p=0.2),  \n",
    "    A.GaussianBlur(blur_limit=(3, 7), p=0.5),  # Introduce slight blur\n",
    "    A.ToFloat(),\n",
    "    A.Normalize(mean=MEAN, std=STD, max_pixel_value=1),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "TEST_TRANSFORMS = A.Compose([\n",
    "    A.Resize(CONFIG.TARGET_IMAGE_SIZE,CONFIG.TARGET_IMAGE_SIZE),\n",
    "    #A.CenterCrop(CONFIG.TARGET_IMAGE_SIZE,CONFIG.TARGET_IMAGE_SIZE),\n",
    "    A.ToFloat(),\n",
    "    A.Normalize(mean=MEAN, std=STD, max_pixel_value=1),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "\n",
    "# TRAIN_TRANSFORMS = A.Compose([\n",
    "#     #A.HorizontalFlip(p=0.5),\n",
    "#     A.Resize(CONFIG.TARGET_IMAGE_SIZE, CONFIG.TARGET_IMAGE_SIZE),\n",
    "#     #A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.25),\n",
    "#     #A.ImageCompression(quality_lower=85, quality_upper=100, p=0.25),\n",
    "#     A.ToFloat(),\n",
    "#     A.Normalize(mean=MEAN, std=STD, max_pixel_value=1),\n",
    "#     ToTensorV2(),\n",
    "# ])\n",
    "\n",
    "# TEST_TRANSFORMS = A.Compose([\n",
    "#     A.Resize(CONFIG.TARGET_IMAGE_SIZE, CONFIG.TARGET_IMAGE_SIZE),\n",
    "#     A.ToFloat(),\n",
    "#     A.Normalize(mean=MEAN, std=STD, max_pixel_value=1),\n",
    "#     ToTensorV2(),\n",
    "# ])\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# # Creating the Dataloader for Train , Validation and Testing \n",
    "\n",
    "# %%\n",
    "class create_dataset(Dataset):\n",
    "    def __init__(self, X_jpeg_bytes, X_tabular, y, transforms=None):\n",
    "        self.X_jpeg_bytes = X_jpeg_bytes\n",
    "        self.X_tabular = X_tabular\n",
    "        self.y = y\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X_sample = self.transforms(\n",
    "            image=imageio.imread(self.X_jpeg_bytes[index]),\n",
    "        )['image']\n",
    "        X_tabular_sample = self.X_tabular[index]\n",
    "        y_sample = self.y[index]\n",
    "\n",
    "        return X_sample, X_tabular_sample, y_sample\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = create_dataset(\n",
    "    X_jpeg_bytes = train_tabular_scaled['jpeg_bytes'].values,\n",
    "    X_tabular = train_tabular_scaled[CONFIG.EXTRA_COLOUMN].values.astype(np.float32),\n",
    "    y = train_tabular_scaled[CONFIG.TRAITS_NAME].values.astype(np.float32),\n",
    "    transforms= TRAIN_TRANSFORMS\n",
    ")\n",
    "\n",
    "validation_dataset = create_dataset(\n",
    "    X_jpeg_bytes = validation_tabular_scaled['jpeg_bytes'].values,\n",
    "    X_tabular = validation_tabular_scaled[CONFIG.EXTRA_COLOUMN].values.astype(np.float32),\n",
    "    y = validation_tabular_scaled[CONFIG.TRAITS_NAME].values.astype(np.float32),\n",
    "    transforms= TEST_TRANSFORMS\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=CONFIG.TRAIN_BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=0#psutil.cpu_count(),\n",
    ")\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "    validation_dataset,\n",
    "    batch_size=CONFIG.VAL_BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers= 0 #psutil.cpu_count(),\n",
    ")\n",
    "\n",
    "test_dataset = create_dataset(\n",
    "    X_jpeg_bytes = test_tabular_scaled['jpeg_bytes'].values,\n",
    "    X_tabular = test_tabular_scaled[CONFIG.EXTRA_COLOUMN].values.astype(np.float32),\n",
    "    y = test_tabular_scaled[CONFIG.TRAITS_NAME].values.astype(np.float32),\n",
    "    transforms= TEST_TRANSFORMS\n",
    "    )\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=CONFIG.TEST_BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers= 0 #psutil.cpu_count(),\n",
    ")\n",
    "\n",
    "# %%\n",
    "# histograms after filtering out bad observations\n",
    "n_rows = 2\n",
    "n_cols = 3\n",
    "fig, axs = plt.subplots(n_rows, n_cols, figsize=(4 * n_cols, 3 * n_rows))\n",
    "for i, column in enumerate(CONFIG.TRAITS_NAME):\n",
    "    row_idx, col_idx = divmod(i, n_cols)\n",
    "    _ = sns.histplot(data=train_df, x=column, ax=axs[row_idx, col_idx], bins=20)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Defining the MODEL\n",
    "# \n",
    "# # Define the Image Backbone and Tabular Model\n",
    "\n",
    "# %%\n",
    "   \n",
    "   # load custom model\n",
    "   # get weight\n",
    "   # model.backbone get weight\n",
    "class ImageBackbone_swinV2(nn.Module):\n",
    "    def __init__(self, backbone_name, weight_path, out_features, fixed_feature_extractor=False):\n",
    "        super().__init__()\n",
    "        self.out_features = out_features\n",
    "        self.backbone =timm.create_model('swinv2_large_window12to16_192to256.ms_in22k_ft_in1k', pretrained=False, num_classes=CONFIG.N_TARGETS) # timm.create_model('swin_large_patch4_window12_384.ms_in22k_ft_in1k', pretrained=True, num_classes=CONFIG.N_TARGETS)\n",
    "        swin_fine_tuned_weight = torch.load(weight_path)\n",
    "        swin_fine_tuned_weight  = {key.replace(\"img_backbone.backbone.\", \"\"): value for key, value in swin_fine_tuned_weight.items()}\n",
    "        self.backbone.load_state_dict(swin_fine_tuned_weight)\n",
    "        if fixed_feature_extractor:\n",
    "            for param in self.backbone.parameters():\n",
    "                param.requires_grad = False\n",
    "        in_features = self.backbone.num_features\n",
    "\n",
    "        self.backbone.head = nn.Identity()\n",
    "        self.head = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features, out_features),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        return self.head(x)\n",
    "\n",
    "class TabularBackbone(nn.Module):\n",
    "    def __init__(self, n_features, out_features):\n",
    "        super().__init__()\n",
    "        self.out_features = out_features\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(n_features, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(128, out_features),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)    \n",
    "\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# # Combine the image feature extraction model with tabular feature extraction model \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#backbone_name, weight_path, out_features, fixed_feature_extractor=False\n",
    "# %%\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self,model_name , fine_tuned_img_weights , img_out_features , fixed_feature_extractor , traits_target_feature):\n",
    "        super().__init__()\n",
    "        self.img_backbone =  ImageBackbone_swinV2(backbone_name = model_name,weight_path = fine_tuned_img_weights ,out_features =  img_out_features ,fixed_feature_extractor=fixed_feature_extractor)\n",
    "        self.extra_features_model = TabularBackbone(n_features  = len(CONFIG.EXTRA_COLOUMN) , out_features=64)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.extra_features_model.out_features + self.img_backbone.out_features, 256),  #1024\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(256, 128), #256\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.GELU(),\n",
    "            #nn.Dropout(0.1),\n",
    "            nn.Linear(128, traits_target_feature),\n",
    "        )        \n",
    "    def forward(self,image,x):\n",
    "        output_image = self.img_backbone(image) \n",
    "        z = self.extra_features_model(x) \n",
    "        inputs  = torch.cat((output_image,z), 1 )\n",
    "        output = self.fc(inputs)\n",
    "        return output\n",
    "\n",
    "\n",
    "# to save model \n",
    "class BestModelSaveCallback:\n",
    "    def __init__(self, save_path):\n",
    "        self.save_path = save_path\n",
    "        self.best_accuracy = -1\n",
    "\n",
    "    def __call__(self, accuracy,model):\n",
    "        if accuracy > self.best_accuracy:\n",
    "            self.best_accuracy = accuracy\n",
    "            model.to(device = \"cpu\")\n",
    "            torch.save(model, self.save_path)\n",
    "            model.to(device=DEVICE)\n",
    "\n",
    "\n",
    "\n",
    "# input_channels = len(CONFIG.EXTRA_COLOUMN) ,out_channels =CONFIG.TABULAR_NN_OUTPUT, target_features_num= len(CONFIG.TRAITS_NAME), tim_num_class=CONFIG.TIM_NUM_CLASS , model_name=CONFIG.TIM_MODEL_NAME\n",
    "# %%\n",
    "model = CustomModel(model_name=CONFIG.IMG_MODEL_NAME , fine_tuned_img_weights= CONFIG.IMG_FINED_TUNED_WEIGHT,img_out_features = CONFIG.IMG_OUT_FEATURES, fixed_feature_extractor=True,traits_target_feature = CONFIG.N_TARGETS )\n",
    "model.to(DEVICE)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 6])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "img = torch.ones(4,3,256,256).to(DEVICE)\n",
    "features = torch.ones(4,len(CONFIG.EXTRA_COLOUMN)).to(DEVICE)\n",
    "model(img,features).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# # Define Loss Metric for the Model and MISC\n",
    "\n",
    "# %%\n",
    "# optimizer\n",
    "import torcheval.metrics\n",
    "import torcheval.metrics.regression\n",
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    params=model.parameters(),\n",
    "    lr=CONFIG.LR_MAX,\n",
    "    weight_decay=CONFIG.WEIGHT_DECAY,\n",
    ")\n",
    "\n",
    "# lr scheduler\n",
    "def get_lr_scheduler(optimizer):\n",
    "    return torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer=optimizer,\n",
    "        max_lr=CONFIG.LR_MAX,\n",
    "        total_steps=CONFIG.N_STEPS,\n",
    "        pct_start=0.2,\n",
    "        anneal_strategy='cos',\n",
    "        div_factor=1e1,\n",
    "        final_div_factor=1e1,\n",
    "    )\n",
    "    \n",
    "    \n",
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val):\n",
    "        self.sum += val.sum()\n",
    "        self.count += val.numel()\n",
    "        self.avg = self.sum / self.count\n",
    "        \n",
    "MSE = torcheval.metrics.regression.MeanSquaredError().to(DEVICE)\n",
    "R2sc = torcheval.metrics.regression.R2Score(num_regressors=len(CONFIG.TRAITS_NAME) , multioutput=\"uniform_average\").to(DEVICE)\n",
    "R2sc_val = torcheval.metrics.regression.R2Score(num_regressors=len(CONFIG.TRAITS_NAME) , multioutput=\"uniform_average\").to(DEVICE)\n",
    "MSE_val = torcheval.metrics.regression.MeanSquaredError().to(DEVICE)\n",
    "LOSS = AverageMeter()\n",
    "LOSS_val = AverageMeter()\n",
    "TARGET_TRAITS_MEAN = torch.tensor(train_df[CONFIG.TRAITS_NAME].mean().values).to(DEVICE)        # target mean accross the training dataset\n",
    "EPS = torch.tensor([1e-6]).to('cuda')\n",
    "\n",
    "\n",
    "# just to check if r2 loss is also decreasing \n",
    "def r2_loss(y_pred, y_true):\n",
    "    ss_res = torch.sum((y_true - y_pred)**2, dim=0)\n",
    "    ss_total = torch.sum((y_true - TARGET_TRAITS_MEAN)**2, dim=0)\n",
    "    ss_total = torch.maximum(ss_total, EPS)\n",
    "    r2 = torch.mean(ss_res / ss_total)\n",
    "    return r2\n",
    "\n",
    "LOSS_FN = nn.SmoothL1Loss() # r2_loss\n",
    "LR_SCHEDULER = get_lr_scheduler(optimizer)\n",
    "\n",
    "# %%\n",
    "def train_batch(inputs,model):\n",
    "    model.train()  \n",
    "    #X_image, X_tabular, y_true\n",
    "    if CONFIG.INCLUDE_EXTRA_FEATURES :\n",
    "        x,z,y = inputs\n",
    "        x = x.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "        z = z.to(DEVICE)\n",
    "        y_pred = model(x,z)        \n",
    "        \n",
    "    else:\n",
    "        x,y = inputs\n",
    "        x = x.to(DEVICE)\n",
    "        y = y.to(DEVICE)    \n",
    "        y_pred = model(x)\n",
    "    \n",
    "    \n",
    "    #loss_func = nn.MSELoss()\n",
    "    #loss_val = loss_func(prediction,y)\n",
    "    loss = LOSS_FN(y_pred,y) \n",
    "    LOSS.update(loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    LR_SCHEDULER.step()\n",
    "    MSE.update(y_pred,y)\n",
    "    R2sc.update(y_pred , y )\n",
    "    return LOSS.avg.detach().cpu().numpy() ,MSE.compute().item() ,R2sc.compute().item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def validation_loss_batch(inputs,model):\n",
    "    global Train_std_tensor , Train_mean_tensor\n",
    "    model.eval()\n",
    "    if CONFIG.INCLUDE_EXTRA_FEATURES:\n",
    "        x,z,y = inputs\n",
    "        x = x.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "        z = z.to(DEVICE)\n",
    "        prediction = model(x,z)\n",
    "    else:\n",
    "        x,y = inputs\n",
    "        x = x.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "        prediction = model(x)\n",
    "    prediction =prediction\n",
    "    loss = LOSS_FN(prediction, y)\n",
    "    LOSS_val.update(loss)\n",
    "    MSE_val.update(prediction,y)\n",
    "    R2sc_val.update(prediction , y )\n",
    "    return LOSS_val.avg.detach().cpu().numpy() ,MSE_val.compute().item() ,R2sc_val.compute().item()\n",
    "\n",
    "def train(trainLoader,valLoader,model,num_epochs,best_model_callback):\n",
    "    #wandb.watch(model,loss_function,log = \"all\",log_freq=50)\n",
    "    \n",
    "    train_epoch_loss , train_epoch_r2 , train_epoch_mse =[] , [] , []\n",
    "    val_epoch_loss , val_epoch_r2 , val_epoch_mse = [],[],[]\n",
    "    \n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        if CONFIG.WANDB_INIT :\n",
    "            wandb.log({\"epoch\":epoch })\n",
    "        # print(f\"epoch: {epoch} , lr is { LR_SCHEDULER.get_last_lr()}\" )\n",
    "        train_loss_current_epoch ,train_mse_current_epoch, train_r2_current_epoch = [] , [] , []\n",
    "        MSE.reset()\n",
    "        R2sc.reset()\n",
    "        LOSS.reset()\n",
    "        # batch training loss\n",
    "        with tqdm.tqdm(total=len(trainLoader)) as trainingLoop:\n",
    "            \n",
    "            for index,batch in enumerate(iter(trainLoader)): \n",
    "        \n",
    "                loss,mse_ , r2_ = train_batch(batch,model)\n",
    "                train_loss_current_epoch.append(loss)\n",
    "                train_mse_current_epoch.append(mse_)\n",
    "                train_r2_current_epoch.append(r2_)\n",
    "                \n",
    "                #trainingLoop.set_description(f\"Epoch:{epoch} , Batch: {index}/{len(trainLoader)} \")\n",
    "                #print(loss , mse_,  r2_ ,LR_SCHEDULER.get_last_lr())\n",
    "                #trainingLoop.set_postfix({ \"Training batch\" : index , \"loss is\" : loss , \"MSE\" :  mse_ , \"R2\":  r2_, \"lr was\":  LR_SCHEDULER.get_last_lr()[0] })\n",
    "                #trainingLoop.update(1)\n",
    "                if CONFIG.WANDB_INIT:\n",
    "                    wandb.log({\"Training-Loss\":loss  , \"Training-MSE\" :  mse_ , \"Training-R2\":  r2_ })\n",
    "        \n",
    "        # train_epoch_loss.append(np.array(train_loss_current_epoch).mean() )\n",
    "        # train_epoch_r2.append(np.array(train_r2_current_epoch).mean())\n",
    "        # train_epoch_mse.append(np.array(train_mse_current_epoch).mean())\n",
    "\n",
    "        MSE_val.reset()\n",
    "        R2sc_val.reset()\n",
    "        LOSS_val.reset()\n",
    "                \n",
    "        # validation set loss & accuracy  \n",
    "        # val_loss_current_epoch ,val_mse_current_epoch, val_r2_current_epoch = [] , [] , []\n",
    "        val_r2 = 0\n",
    "        with tqdm.tqdm(total = len(valLoader)) as validationLoop:\n",
    "            for index,batch in enumerate(iter(valLoader)):\n",
    "                loss,mse_ , val_r2 = validation_loss_batch(batch,model)\n",
    "                #val_loss_current_epoch.append(loss)\n",
    "                #val_mse_current_epoch.append(mse_) \n",
    "                #val_r2_current_epoch.append(r2_)\n",
    "                #validationLoop.set_description(f\"Batch: {index}/{len(valLoader)}\")\n",
    "                #validationLoop.set_postfix({ \"Validation batch\" : index , \"loss is\" : loss , \"MSE\" :  mse_ , \"R2\":  val_r2 })\n",
    "                ##wandb.log({\"Vlaidation loss\" : loss})\n",
    "                #validationLoop.update(1)\n",
    "            if CONFIG.WANDB_INIT:\n",
    "                wandb.log({\"Validation-Loss\":loss  , \"Validation-MSE\" :  mse_ , \"Validation-R2\":  val_r2 })\n",
    "       \n",
    "        best_model_callback(val_r2,model)        # save the best model according to the validation accuracy\n",
    "        \n",
    "        \n",
    "    return train_epoch_loss,val_epoch_loss,train_epoch_r2 , val_epoch_r2\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "MODEL_NAME_SAVE = 'swinV2_large_self_fine_tuned.pth'\n",
    "best_model_callback = BestModelSaveCallback(save_path=os.path.join(CONFIG.BASE_DIR,MODEL_NAME_SAVE))\n",
    "train_losses, val_losses , train_accuracies,val_accuracies = train(train_dataloader,validation_dataloader,model,CONFIG.NUM_EPOCHS,best_model_callback)\n",
    "\n",
    "# %%\n",
    "submission_df = pd.DataFrame(columns=CONFIG.TRAITS_NAME)\n",
    "for index , batch in tqdm.tqdm(enumerate(iter(test_dataloader))):\n",
    "    X_img_test = batch[0] \n",
    "    X_features  = batch[1]\n",
    "    test_id  = batch[2]\n",
    "    #print(batch) \n",
    "    with torch.no_grad():\n",
    "        #print(X_img_test.shape, X_features.shape)\n",
    "        y_pred = model(X_img_test.to(DEVICE),X_features.to(DEVICE)).detach().cpu().numpy()  #,X_features.to(DEVICE)\n",
    "    \n",
    "        pred_pd = pd.DataFrame(columns=CONFIG.EXTRA_COLOUMN + CONFIG.TRAITS_NAME)\n",
    "        pred_pd[CONFIG.EXTRA_COLOUMN] =-1\n",
    "        pred_pd[CONFIG.TRAITS_NAME] = y_pred \n",
    "\n",
    "        temp1 =   scaling_pipeline['std_scale']['scale'].inverse_transform(pred_pd)\n",
    "        temp2=    pd.DataFrame(temp1, columns=CONFIG.EXTRA_COLOUMN + CONFIG.TRAITS_NAME)\n",
    "        pred_final =   scaling_pipeline['log']['log'].inverse_transform(temp2[CONFIG.TRAITS_NAME])\n",
    "        #pred_final[\"id\"] = test_id.cpu().detach().numpy()\n",
    "        submission_df = pd.concat([submission_df, pred_final.assign(id=test_id.cpu().detach().numpy())], ignore_index=True)\n",
    "# submission_df.to_csv('submission_self_tuning.csv', index=False)\n",
    "submission_df[[\"id\"]  + CONFIG.TRAITS_NAME ].to_csv('submission_swinV2_with_tabular.csv', index=False)\n",
    "print(\"Submit!\")\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
