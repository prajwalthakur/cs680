{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from catboost import Pool, CatBoostRegressor\n",
    "from torchvision import transforms\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Config():\n",
    "    TARGET_COLUMNS = ['X4_mean', 'X11_mean', 'X18_mean', 'X26_mean' ,'X50_mean', 'X3112_mean']\n",
    "    # Dataset\n",
    "    RECOMPUTE_DATAFRAMES_TRAIN = True\n",
    "    RECOMPUTE_DATAFRAMES_TEST = True\n",
    "    RECOMPUTE_IMAGE_EMBEDDINGS = False\n",
    "    N_VAL_SAMPLES0 = 4096\n",
    "    # Others\n",
    "    SEED = 42\n",
    "    DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "def seed_everything(seed: int):    \n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "        \n",
    "CONFIG = Config()\n",
    "seed_everything(CONFIG.SEED)\n",
    "CONFIG.DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BASE_DIR = os.path.join(os.getcwd() , 'data')\n",
    "train_df = pd.read_csv(BASE_DIR  +  '/train.csv')\n",
    "# load pickled dataframes from a public dataset; split to train-val\n",
    "if CONFIG.RECOMPUTE_DATAFRAMES_TRAIN:\n",
    "    train0 = pd.read_csv(BASE_DIR + '/train.csv')\n",
    "    train0['file_path'] = train0['id'].apply(lambda s: f'{BASE_DIR}/train_images/{s}.jpeg')\n",
    "else:\n",
    "    train0 = pd.read_pickle('/kaggle/input/planttraits2024-eda-training-pub-dataset/train.pkl')\n",
    "    \n",
    "if CONFIG.RECOMPUTE_DATAFRAMES_TEST:\n",
    "    test = pd.read_csv(BASE_DIR + '/test.csv')\n",
    "    test['file_path'] = test['id'].apply(lambda s: f'{BASE_DIR}/test_images/{s}.jpeg')\n",
    "else:\n",
    "    test = pd.read_pickle('/kaggle/input/planttraits2024-eda-training-pub-dataset/test.pkl')\n",
    "CONFIG.FEATURE_COLUMNS = test.columns.values[1:-2]\n",
    "\n",
    "train, val = train_test_split(train0, test_size=CONFIG.N_VAL_SAMPLES0, shuffle=True, random_state=CONFIG.SEED)\n",
    "train = train.reset_index(drop=True)\n",
    "val = val.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== train shape: (34884, 171) =====\n",
      "train \t| # Masked Samples: 4383\n",
      "train \t| % Masked Samples: 11.162%\n",
      "===== val shape: (3623, 171) =====\n",
      "val \t| # Masked Samples: 473\n",
      "val \t| % Masked Samples: 11.548%\n"
     ]
    }
   ],
   "source": [
    "def get_mask(df, labels_describe_df):\n",
    "    lower = []\n",
    "    higher = []\n",
    "    mask = np.empty(shape=df[CONFIG.TARGET_COLUMNS].shape, dtype=bool)\n",
    "    for idx, t in enumerate(CONFIG.TARGET_COLUMNS):\n",
    "        labels = df[t].values\n",
    "        v_min, v_max = labels_describe_df.loc[t]['0.1%'], labels_describe_df.loc[t]['98%']\n",
    "        mask[:,idx] = ((labels > v_min) & (labels < v_max))\n",
    "    return mask.min(axis=1)\n",
    "\n",
    "labels_describe_df = train[CONFIG.TARGET_COLUMNS].describe(percentiles=[0.001, 0.98]).round(3).T\n",
    "# Masks\n",
    "mask_train = get_mask(train, labels_describe_df)\n",
    "mask_val = get_mask(val, labels_describe_df)\n",
    "# Masked DataFrames\n",
    "train_mask = train[mask_train].reset_index(drop=True)\n",
    "val_mask = val[mask_val].reset_index(drop=True)\n",
    "\n",
    "for m, subset, full in zip([train_mask, val_mask], ['train', 'val'], [train, val]):\n",
    "    print(f'===== {subset} shape: {m.shape} =====')\n",
    "    n_masked = len(full) - len(m)\n",
    "    perc_masked = (n_masked / len(full)) * 100\n",
    "    print(f'{subset} \\t| # Masked Samples: {n_masked}')\n",
    "    print(f'{subset} \\t| % Masked Samples: {perc_masked:.3f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Scaler for Features\n",
    "FEATURE_SCALER = StandardScaler()\n",
    "# Fit and transform on training features\n",
    "train_features_mask = FEATURE_SCALER.fit_transform(train_mask[CONFIG.FEATURE_COLUMNS].values.astype(np.float32))\n",
    "# Transform val/test features using scaler fitted on train data\n",
    "val_features_mask = FEATURE_SCALER.transform(val_mask[CONFIG.FEATURE_COLUMNS].values.astype(np.float32))\n",
    "test_features = FEATURE_SCALER.transform(test[CONFIG.FEATURE_COLUMNS].values.astype(np.float32))\n",
    "\n",
    "y_train_mask = train_mask[CONFIG.TARGET_COLUMNS].values\n",
    "y_val_mask = val_mask[CONFIG.TARGET_COLUMNS].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_embeddings_dino(model, preprocess, batch_size, df):\n",
    "    image_embeddings = []\n",
    "    for i in tqdm(range(0, len(df), batch_size)):\n",
    "        paths = df['file_path'][i:i + batch_size]\n",
    "        image_tensor = torch.stack([preprocess(Image.open(path)) for path in paths]).to(CONFIG.DEVICE)\n",
    "        with torch.no_grad():\n",
    "            curr_image_embeddings = model(image_tensor)\n",
    "        image_embeddings.extend(curr_image_embeddings.cpu().numpy())\n",
    "    return image_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings image_embs_dinov2_vitg14_reg loaded from dataset.\n"
     ]
    }
   ],
   "source": [
    "if CONFIG.RECOMPUTE_IMAGE_EMBEDDINGS:\n",
    "    model = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitg14_reg').to(CONFIG.DEVICE)\n",
    "    model.eval()\n",
    "    # the preprocessing differs from the original code, originally it was resize + crop\n",
    "    # but we lose info while cropping, so here we use only resize to 224\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(224, interpolation=3),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    ])\n",
    "    \n",
    "    batch_size = 64\n",
    "    suffix = 'image_embs_dinov2_vitg14_reg'\n",
    "    train_image_embeddings = get_image_embeddings_dino(model, preprocess, batch_size, train_mask)\n",
    "    np.save(f'train_{suffix}', np.array(train_image_embeddings))\n",
    "    val_image_embeddings = get_image_embeddings_dino(model, preprocess, batch_size, val_mask)\n",
    "    np.save(f'val_{suffix}', np.array(val_image_embeddings))\n",
    "    test_image_embeddings = get_image_embeddings_dino(model, preprocess, batch_size, test)\n",
    "    np.save(f'test_{suffix}', np.array(test_image_embeddings))\n",
    "else:\n",
    "    suffix = 'image_embs_dinov2_vitg14_reg'\n",
    "    train_image_embeddings = np.load(f'{BASE_DIR}/train_{suffix}.npy')\n",
    "    val_image_embeddings = np.load(f'{BASE_DIR}/val_{suffix}.npy')\n",
    "    test_image_embeddings = np.load(f'{BASE_DIR}/test_{suffix}.npy')\n",
    "    print(f'Embeddings {suffix} loaded from dataset.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can potentially use all the polynomial features but it would take an etenriny to train the models\n",
    "first_n_poly_feats = 1000\n",
    "train_features_mask_all = np.concatenate(\n",
    "    (PolynomialFeatures(2).fit_transform(train_features_mask)[:, :first_n_poly_feats], train_image_embeddings), axis=1\n",
    ")\n",
    "val_features_mask_all = np.concatenate(\n",
    "    (PolynomialFeatures(2).fit_transform(val_features_mask)[:, :first_n_poly_feats], val_image_embeddings), axis=1\n",
    ")\n",
    "test_features_all = np.concatenate(\n",
    "    (PolynomialFeatures(2).fit_transform(test_features)[:, :first_n_poly_feats], test_image_embeddings), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_mask_df = pd.DataFrame(train_features_mask_all)\n",
    "train_features_mask_df['emb'] = list(train_image_embeddings)\n",
    "\n",
    "val_features_mask_df = pd.DataFrame(val_features_mask_all)\n",
    "val_features_mask_df['emb'] = list(val_image_embeddings)\n",
    "\n",
    "test_features_mask_df = pd.DataFrame(test_features_all)\n",
    "test_features_mask_df['emb'] = list(test_image_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 109 μs, sys: 15 μs, total: 124 μs\n",
      "Wall time: 130 μs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "models = {}\n",
    "scores = {}\n",
    "# for i, col in tqdm(enumerate(CONFIG.TARGET_COLUMNS), total=len(CONFIG.TARGET_COLUMNS)):\n",
    "#     y_curr = y_train_mask[:, i]\n",
    "#     y_curr_val = y_val_mask[:, i]\n",
    "#     train_pool = Pool(train_features_mask_df, y_curr, embedding_features=['emb'])\n",
    "#     val_pool = Pool(val_features_mask_df, y_curr_val, embedding_features=['emb'])\n",
    "    \n",
    "    # tried to tune these parameters but without real success \n",
    "model = CatBoostRegressor(iterations=1500, learning_rate=0.06, loss_function='RMSE', verbose=0, random_state=CONFIG.SEED)\n",
    "#     model.fit(train_pool)\n",
    "#     models[col] = model\n",
    "    \n",
    "#     y_curr_val_pred = model.predict(val_pool)\n",
    "    \n",
    "#     r2_col = r2_score(y_curr_val, y_curr_val_pred)\n",
    "#     scores[col] = r2_col\n",
    "#     print(f'Target: {col}, R2: {r2_col:.3f}')\n",
    "# # this val score somewhat correlates with submission score bit I didn't really bother\n",
    "# print(f'Mean R2: {np.mean(list(scores.values())):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from_file = CatBoostRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CatBoostRegressor' object has no attribute 'load'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBASE_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/dino_model.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CatBoostRegressor' object has no attribute 'load'"
     ]
    }
   ],
   "source": [
    "model.load(f\"{BASE_DIR}/dino_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CatBoostRegressor' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBASE_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/dinoV2.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CatBoostRegressor' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "model.to(device = \"cpu\")\n",
    "torch.save(model.state_dict(), f\"{BASE_DIR}/dinoV2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test['id']})\n",
    "submission[CONFIG.TARGET_COLUMNS] = 0\n",
    "submission.columns = submission.columns.str.replace('_mean', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>X4</th>\n",
       "      <th>X11</th>\n",
       "      <th>X18</th>\n",
       "      <th>X26</th>\n",
       "      <th>X50</th>\n",
       "      <th>X3112</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>154220505</td>\n",
       "      <td>1.150634</td>\n",
       "      <td>145.307883</td>\n",
       "      <td>19707.700772</td>\n",
       "      <td>3490.907981</td>\n",
       "      <td>15.133894</td>\n",
       "      <td>400094.893415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>195736552</td>\n",
       "      <td>0.984673</td>\n",
       "      <td>152.914871</td>\n",
       "      <td>19699.674946</td>\n",
       "      <td>3461.206384</td>\n",
       "      <td>14.976181</td>\n",
       "      <td>398848.975075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>182701773</td>\n",
       "      <td>0.976492</td>\n",
       "      <td>149.251464</td>\n",
       "      <td>19699.565957</td>\n",
       "      <td>3459.253743</td>\n",
       "      <td>15.040446</td>\n",
       "      <td>398182.331739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27688500</td>\n",
       "      <td>0.957770</td>\n",
       "      <td>139.824763</td>\n",
       "      <td>19699.918337</td>\n",
       "      <td>3478.239522</td>\n",
       "      <td>15.942455</td>\n",
       "      <td>398248.174168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>195825045</td>\n",
       "      <td>0.891497</td>\n",
       "      <td>153.176586</td>\n",
       "      <td>19699.167833</td>\n",
       "      <td>3460.367853</td>\n",
       "      <td>14.839305</td>\n",
       "      <td>398791.282423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id        X4         X11           X18          X26        X50  \\\n",
       "0  154220505  1.150634  145.307883  19707.700772  3490.907981  15.133894   \n",
       "1  195736552  0.984673  152.914871  19699.674946  3461.206384  14.976181   \n",
       "2  182701773  0.976492  149.251464  19699.565957  3459.253743  15.040446   \n",
       "3   27688500  0.957770  139.824763  19699.918337  3478.239522  15.942455   \n",
       "4  195825045  0.891497  153.176586  19699.167833  3460.367853  14.839305   \n",
       "\n",
       "           X3112  \n",
       "0  400094.893415  \n",
       "1  398848.975075  \n",
       "2  398182.331739  \n",
       "3  398248.174168  \n",
       "4  398791.282423  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, col in enumerate(CONFIG.TARGET_COLUMNS):\n",
    "    test_pool = Pool(test_features_mask_df, embedding_features=['emb'])\n",
    "    col_pred = models[col].predict(test_pool)\n",
    "    submission[col.replace('_mean', '')] = col_pred\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
