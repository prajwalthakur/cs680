{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import imageio.v3 as imageio\n",
    "import albumentations as A\n",
    "\n",
    "# import torch_xla as xla\n",
    "# import torch_xla.core.xla_model as xm\n",
    "# import torch_xla.distributed.xla_multiprocessing as xmp\n",
    "# import torch_xla.distributed.xla_backend\n",
    "\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch import nn\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "\n",
    "import torch\n",
    "import timm\n",
    "import torchmetrics\n",
    "import time\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "device = 'cuda:1' #xla.device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config():\n",
    "    IMAGE_SIZE = 384\n",
    "    BACKBONE = 'swin_large_patch4_window12_384.ms_in22k_ft_in1k'\n",
    "    TARGET_COLUMNS = ['X4_mean', 'X11_mean', 'X18_mean', 'X50_mean', 'X26_mean', 'X3112_mean']\n",
    "    N_TARGETS = len(TARGET_COLUMNS)\n",
    "    BATCH_SIZE = 4\n",
    "    LR_MAX = 1e-4\n",
    "    WEIGHT_DECAY = 0.01\n",
    "    N_EPOCHS = 5\n",
    "    TRAIN_MODEL = True\n",
    "    IS_INTERACTIVE = True  # os.environ['KAGGLE_KERNEL_RUN_TYPE'] == 'Interactive'\n",
    "    tpu_ids = range(8)\n",
    "    Lower_Quantile = 0.005\n",
    "    Upper_Quantile = 0.985\n",
    "    SHRINK_SAMPLES = False\n",
    "\n",
    "CONFIG = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, X_jpeg_bytes, X_tabular, y, transforms=None):\n",
    "        self.X_jpeg_bytes = X_jpeg_bytes\n",
    "        self.X_tabular = X_tabular\n",
    "        self.y = y\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X_sample = self.transforms(\n",
    "            image=imageio.imread(self.X_jpeg_bytes[index]),\n",
    "        )['image']\n",
    "        X_tabular_sample = self.X_tabular[index]\n",
    "        y_sample = self.y[index]\n",
    "\n",
    "        return X_sample, X_tabular_sample, y_sample\n",
    "class TabularBackbone(nn.Module):\n",
    "    def __init__(self, n_features, out_features):\n",
    "        super().__init__()\n",
    "        self.out_features = out_features\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(n_features, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.GELU(),\n",
    "            # nn.Dropout(0.1),\n",
    "            nn.Linear(512, out_features),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "    \n",
    "class ImageBackbone(nn.Module):\n",
    "    def __init__(self, backbone_name, weight_path, out_features, fixed_feature_extractor=False):\n",
    "        super().__init__()\n",
    "        self.out_features = out_features\n",
    "        self.backbone = timm.create_model(backbone_name, pretrained=False, num_classes=CONFIG.N_TARGETS)\n",
    "        #self.backbone.load_state_dict(torch.load(weight_path))\n",
    "        if fixed_feature_extractor:\n",
    "            for param in self.backbone.parameters():\n",
    "                param.requires_grad = False\n",
    "        in_features = self.backbone.num_features\n",
    "        \n",
    "        self.backbone.head = nn.Identity()\n",
    "        self.head = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features, out_features),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        return self.head(x)\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, img_backbone, tab_backbone, out_features:int):\n",
    "        super().__init__()\n",
    "        self.img_backbone = img_backbone\n",
    "        self.tab_backbone = tab_backbone\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.tab_backbone.out_features + self.img_backbone.out_features, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.GELU(),\n",
    "            # nn.Dropout(0.1),\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.GELU(),\n",
    "            # nn.Dropout(0.1),\n",
    "            nn.Linear(256, out_features),\n",
    "        )\n",
    "\n",
    "    def forward(self, img, tab):\n",
    "        img_features = self.img_backbone(img)\n",
    "        tab_features = self.tab_backbone(tab)\n",
    "        features = torch.cat([img_features, tab_features], dim=1)\n",
    "        return self.fc(features)\n",
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val):\n",
    "        self.sum += val.sum()\n",
    "        self.count += val.numel()\n",
    "        self.avg = self.sum / self.count\n",
    "def get_lr_scheduler(optimizer):\n",
    "    return torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer=optimizer,\n",
    "    max_lr=CONFIG.LR_MAX,\n",
    "    total_steps=CONFIG.N_STEPS,\n",
    "    pct_start=0.1,\n",
    "    anneal_strategy='cos',\n",
    "    div_factor=1e1,\n",
    "    final_div_factor=1e1,\n",
    "    )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "BASE_DIR = os.path.join(os.getcwd() , 'data')\n",
    "train_df = pd.read_csv(BASE_DIR  +  '/train.csv')\n",
    "\n",
    "train = pd.read_csv(BASE_DIR  +  '/train.csv')\n",
    "test =  pd.read_csv(BASE_DIR  +  '/test.csv')\n",
    "\n",
    "for column in CONFIG.TARGET_COLUMNS:\n",
    "    lower_quantile = train[column].quantile(CONFIG.Lower_Quantile)\n",
    "    upper_quantile = train[column].quantile(CONFIG.Upper_Quantile)\n",
    "    train = train[(train[column] >= lower_quantile) & (train[column] <= upper_quantile)]\n",
    "    \n",
    "tabular = train.drop(columns = ['id'] + CONFIG.TARGET_COLUMNS)\n",
    "test_tabular = test.drop(columns = ['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WORLDCLIM_BIO1_annual_mean_temperature</th>\n",
       "      <th>WORLDCLIM_BIO12_annual_precipitation</th>\n",
       "      <th>WORLDCLIM_BIO13.BIO14_delta_precipitation_of_wettest_and_dryest_month</th>\n",
       "      <th>WORLDCLIM_BIO15_precipitation_seasonality</th>\n",
       "      <th>WORLDCLIM_BIO4_temperature_seasonality</th>\n",
       "      <th>WORLDCLIM_BIO7_temperature_annual_range</th>\n",
       "      <th>SOIL_bdod_0.5cm_mean_0.01_deg</th>\n",
       "      <th>SOIL_bdod_100.200cm_mean_0.01_deg</th>\n",
       "      <th>SOIL_bdod_15.30cm_mean_0.01_deg</th>\n",
       "      <th>SOIL_bdod_30.60cm_mean_0.01_deg</th>\n",
       "      <th>...</th>\n",
       "      <th>VOD_X_1997_2018_multiyear_mean_m03</th>\n",
       "      <th>VOD_X_1997_2018_multiyear_mean_m04</th>\n",
       "      <th>VOD_X_1997_2018_multiyear_mean_m05</th>\n",
       "      <th>VOD_X_1997_2018_multiyear_mean_m06</th>\n",
       "      <th>VOD_X_1997_2018_multiyear_mean_m07</th>\n",
       "      <th>VOD_X_1997_2018_multiyear_mean_m08</th>\n",
       "      <th>VOD_X_1997_2018_multiyear_mean_m09</th>\n",
       "      <th>VOD_X_1997_2018_multiyear_mean_m10</th>\n",
       "      <th>VOD_X_1997_2018_multiyear_mean_m11</th>\n",
       "      <th>VOD_X_1997_2018_multiyear_mean_m12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.478968</td>\n",
       "      <td>772.404785</td>\n",
       "      <td>110.047623</td>\n",
       "      <td>56.210766</td>\n",
       "      <td>161.457764</td>\n",
       "      <td>13.886666</td>\n",
       "      <td>129</td>\n",
       "      <td>141</td>\n",
       "      <td>134</td>\n",
       "      <td>137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.452674</td>\n",
       "      <td>0.469246</td>\n",
       "      <td>0.479971</td>\n",
       "      <td>0.488434</td>\n",
       "      <td>0.495728</td>\n",
       "      <td>0.482645</td>\n",
       "      <td>0.448959</td>\n",
       "      <td>0.419139</td>\n",
       "      <td>0.404626</td>\n",
       "      <td>0.403707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26.927639</td>\n",
       "      <td>1456.733276</td>\n",
       "      <td>329.366669</td>\n",
       "      <td>109.906487</td>\n",
       "      <td>178.745422</td>\n",
       "      <td>19.846668</td>\n",
       "      <td>139</td>\n",
       "      <td>140</td>\n",
       "      <td>140</td>\n",
       "      <td>137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.448251</td>\n",
       "      <td>0.470133</td>\n",
       "      <td>0.448403</td>\n",
       "      <td>0.405665</td>\n",
       "      <td>0.382672</td>\n",
       "      <td>0.364023</td>\n",
       "      <td>0.362919</td>\n",
       "      <td>0.368997</td>\n",
       "      <td>0.391109</td>\n",
       "      <td>0.407680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.558649</td>\n",
       "      <td>2246.017822</td>\n",
       "      <td>329.342224</td>\n",
       "      <td>56.563957</td>\n",
       "      <td>211.065521</td>\n",
       "      <td>16.768000</td>\n",
       "      <td>116</td>\n",
       "      <td>132</td>\n",
       "      <td>122</td>\n",
       "      <td>129</td>\n",
       "      <td>...</td>\n",
       "      <td>0.548350</td>\n",
       "      <td>0.551841</td>\n",
       "      <td>0.515061</td>\n",
       "      <td>0.555757</td>\n",
       "      <td>0.525224</td>\n",
       "      <td>0.571438</td>\n",
       "      <td>0.572420</td>\n",
       "      <td>0.566320</td>\n",
       "      <td>0.556564</td>\n",
       "      <td>0.512105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.204723</td>\n",
       "      <td>2309.776123</td>\n",
       "      <td>284.576202</td>\n",
       "      <td>39.409706</td>\n",
       "      <td>36.499138</td>\n",
       "      <td>10.257143</td>\n",
       "      <td>100</td>\n",
       "      <td>113</td>\n",
       "      <td>105</td>\n",
       "      <td>111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.645712</td>\n",
       "      <td>0.641703</td>\n",
       "      <td>0.638654</td>\n",
       "      <td>0.647840</td>\n",
       "      <td>0.647654</td>\n",
       "      <td>0.639092</td>\n",
       "      <td>0.634200</td>\n",
       "      <td>0.628594</td>\n",
       "      <td>0.644814</td>\n",
       "      <td>0.654979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17.526487</td>\n",
       "      <td>408.637756</td>\n",
       "      <td>101.841835</td>\n",
       "      <td>110.660789</td>\n",
       "      <td>591.169128</td>\n",
       "      <td>25.035715</td>\n",
       "      <td>141</td>\n",
       "      <td>152</td>\n",
       "      <td>146</td>\n",
       "      <td>149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.295938</td>\n",
       "      <td>0.289349</td>\n",
       "      <td>0.275169</td>\n",
       "      <td>0.268171</td>\n",
       "      <td>0.264103</td>\n",
       "      <td>0.265927</td>\n",
       "      <td>0.265918</td>\n",
       "      <td>0.267588</td>\n",
       "      <td>0.263034</td>\n",
       "      <td>0.265842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43358</th>\n",
       "      <td>25.551382</td>\n",
       "      <td>3294.408203</td>\n",
       "      <td>353.204071</td>\n",
       "      <td>47.970898</td>\n",
       "      <td>75.369301</td>\n",
       "      <td>12.087244</td>\n",
       "      <td>105</td>\n",
       "      <td>114</td>\n",
       "      <td>108</td>\n",
       "      <td>110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.509698</td>\n",
       "      <td>0.516254</td>\n",
       "      <td>0.509183</td>\n",
       "      <td>0.504985</td>\n",
       "      <td>0.502834</td>\n",
       "      <td>0.504981</td>\n",
       "      <td>0.510419</td>\n",
       "      <td>0.502823</td>\n",
       "      <td>0.497064</td>\n",
       "      <td>0.487178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43359</th>\n",
       "      <td>24.163185</td>\n",
       "      <td>908.924438</td>\n",
       "      <td>238.119995</td>\n",
       "      <td>110.597702</td>\n",
       "      <td>120.009247</td>\n",
       "      <td>14.226222</td>\n",
       "      <td>132</td>\n",
       "      <td>141</td>\n",
       "      <td>137</td>\n",
       "      <td>139</td>\n",
       "      <td>...</td>\n",
       "      <td>0.513163</td>\n",
       "      <td>0.544969</td>\n",
       "      <td>0.541757</td>\n",
       "      <td>0.519996</td>\n",
       "      <td>0.488227</td>\n",
       "      <td>0.452186</td>\n",
       "      <td>0.428144</td>\n",
       "      <td>0.417601</td>\n",
       "      <td>0.417884</td>\n",
       "      <td>0.424877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43360</th>\n",
       "      <td>23.165426</td>\n",
       "      <td>57.146667</td>\n",
       "      <td>10.146667</td>\n",
       "      <td>52.789906</td>\n",
       "      <td>473.979675</td>\n",
       "      <td>26.604889</td>\n",
       "      <td>138</td>\n",
       "      <td>143</td>\n",
       "      <td>138</td>\n",
       "      <td>140</td>\n",
       "      <td>...</td>\n",
       "      <td>0.183251</td>\n",
       "      <td>0.195377</td>\n",
       "      <td>0.205470</td>\n",
       "      <td>0.212486</td>\n",
       "      <td>0.213125</td>\n",
       "      <td>0.212327</td>\n",
       "      <td>0.200607</td>\n",
       "      <td>0.187665</td>\n",
       "      <td>0.178380</td>\n",
       "      <td>0.170875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43361</th>\n",
       "      <td>15.147365</td>\n",
       "      <td>804.086731</td>\n",
       "      <td>163.000000</td>\n",
       "      <td>92.718536</td>\n",
       "      <td>182.917358</td>\n",
       "      <td>22.998470</td>\n",
       "      <td>122</td>\n",
       "      <td>128</td>\n",
       "      <td>129</td>\n",
       "      <td>126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.335833</td>\n",
       "      <td>0.335149</td>\n",
       "      <td>0.336188</td>\n",
       "      <td>0.353980</td>\n",
       "      <td>0.388565</td>\n",
       "      <td>0.408230</td>\n",
       "      <td>0.417128</td>\n",
       "      <td>0.424777</td>\n",
       "      <td>0.395074</td>\n",
       "      <td>0.371460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43362</th>\n",
       "      <td>4.789425</td>\n",
       "      <td>1108.376221</td>\n",
       "      <td>66.976189</td>\n",
       "      <td>21.389532</td>\n",
       "      <td>1090.754761</td>\n",
       "      <td>41.099998</td>\n",
       "      <td>108</td>\n",
       "      <td>171</td>\n",
       "      <td>130</td>\n",
       "      <td>151</td>\n",
       "      <td>...</td>\n",
       "      <td>0.399040</td>\n",
       "      <td>0.449095</td>\n",
       "      <td>0.466197</td>\n",
       "      <td>0.513145</td>\n",
       "      <td>0.554956</td>\n",
       "      <td>0.566788</td>\n",
       "      <td>0.566342</td>\n",
       "      <td>0.499203</td>\n",
       "      <td>0.448192</td>\n",
       "      <td>0.419320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38422 rows × 163 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       WORLDCLIM_BIO1_annual_mean_temperature  \\\n",
       "0                                   21.478968   \n",
       "1                                   26.927639   \n",
       "3                                   25.558649   \n",
       "4                                   25.204723   \n",
       "5                                   17.526487   \n",
       "...                                       ...   \n",
       "43358                               25.551382   \n",
       "43359                               24.163185   \n",
       "43360                               23.165426   \n",
       "43361                               15.147365   \n",
       "43362                                4.789425   \n",
       "\n",
       "       WORLDCLIM_BIO12_annual_precipitation  \\\n",
       "0                                772.404785   \n",
       "1                               1456.733276   \n",
       "3                               2246.017822   \n",
       "4                               2309.776123   \n",
       "5                                408.637756   \n",
       "...                                     ...   \n",
       "43358                           3294.408203   \n",
       "43359                            908.924438   \n",
       "43360                             57.146667   \n",
       "43361                            804.086731   \n",
       "43362                           1108.376221   \n",
       "\n",
       "       WORLDCLIM_BIO13.BIO14_delta_precipitation_of_wettest_and_dryest_month  \\\n",
       "0                                             110.047623                       \n",
       "1                                             329.366669                       \n",
       "3                                             329.342224                       \n",
       "4                                             284.576202                       \n",
       "5                                             101.841835                       \n",
       "...                                                  ...                       \n",
       "43358                                         353.204071                       \n",
       "43359                                         238.119995                       \n",
       "43360                                          10.146667                       \n",
       "43361                                         163.000000                       \n",
       "43362                                          66.976189                       \n",
       "\n",
       "       WORLDCLIM_BIO15_precipitation_seasonality  \\\n",
       "0                                      56.210766   \n",
       "1                                     109.906487   \n",
       "3                                      56.563957   \n",
       "4                                      39.409706   \n",
       "5                                     110.660789   \n",
       "...                                          ...   \n",
       "43358                                  47.970898   \n",
       "43359                                 110.597702   \n",
       "43360                                  52.789906   \n",
       "43361                                  92.718536   \n",
       "43362                                  21.389532   \n",
       "\n",
       "       WORLDCLIM_BIO4_temperature_seasonality  \\\n",
       "0                                  161.457764   \n",
       "1                                  178.745422   \n",
       "3                                  211.065521   \n",
       "4                                   36.499138   \n",
       "5                                  591.169128   \n",
       "...                                       ...   \n",
       "43358                               75.369301   \n",
       "43359                              120.009247   \n",
       "43360                              473.979675   \n",
       "43361                              182.917358   \n",
       "43362                             1090.754761   \n",
       "\n",
       "       WORLDCLIM_BIO7_temperature_annual_range  SOIL_bdod_0.5cm_mean_0.01_deg  \\\n",
       "0                                    13.886666                            129   \n",
       "1                                    19.846668                            139   \n",
       "3                                    16.768000                            116   \n",
       "4                                    10.257143                            100   \n",
       "5                                    25.035715                            141   \n",
       "...                                        ...                            ...   \n",
       "43358                                12.087244                            105   \n",
       "43359                                14.226222                            132   \n",
       "43360                                26.604889                            138   \n",
       "43361                                22.998470                            122   \n",
       "43362                                41.099998                            108   \n",
       "\n",
       "       SOIL_bdod_100.200cm_mean_0.01_deg  SOIL_bdod_15.30cm_mean_0.01_deg  \\\n",
       "0                                    141                              134   \n",
       "1                                    140                              140   \n",
       "3                                    132                              122   \n",
       "4                                    113                              105   \n",
       "5                                    152                              146   \n",
       "...                                  ...                              ...   \n",
       "43358                                114                              108   \n",
       "43359                                141                              137   \n",
       "43360                                143                              138   \n",
       "43361                                128                              129   \n",
       "43362                                171                              130   \n",
       "\n",
       "       SOIL_bdod_30.60cm_mean_0.01_deg  ...  \\\n",
       "0                                  137  ...   \n",
       "1                                  137  ...   \n",
       "3                                  129  ...   \n",
       "4                                  111  ...   \n",
       "5                                  149  ...   \n",
       "...                                ...  ...   \n",
       "43358                              110  ...   \n",
       "43359                              139  ...   \n",
       "43360                              140  ...   \n",
       "43361                              126  ...   \n",
       "43362                              151  ...   \n",
       "\n",
       "       VOD_X_1997_2018_multiyear_mean_m03  VOD_X_1997_2018_multiyear_mean_m04  \\\n",
       "0                                0.452674                            0.469246   \n",
       "1                                0.448251                            0.470133   \n",
       "3                                0.548350                            0.551841   \n",
       "4                                0.645712                            0.641703   \n",
       "5                                0.295938                            0.289349   \n",
       "...                                   ...                                 ...   \n",
       "43358                            0.509698                            0.516254   \n",
       "43359                            0.513163                            0.544969   \n",
       "43360                            0.183251                            0.195377   \n",
       "43361                            0.335833                            0.335149   \n",
       "43362                            0.399040                            0.449095   \n",
       "\n",
       "       VOD_X_1997_2018_multiyear_mean_m05  VOD_X_1997_2018_multiyear_mean_m06  \\\n",
       "0                                0.479971                            0.488434   \n",
       "1                                0.448403                            0.405665   \n",
       "3                                0.515061                            0.555757   \n",
       "4                                0.638654                            0.647840   \n",
       "5                                0.275169                            0.268171   \n",
       "...                                   ...                                 ...   \n",
       "43358                            0.509183                            0.504985   \n",
       "43359                            0.541757                            0.519996   \n",
       "43360                            0.205470                            0.212486   \n",
       "43361                            0.336188                            0.353980   \n",
       "43362                            0.466197                            0.513145   \n",
       "\n",
       "       VOD_X_1997_2018_multiyear_mean_m07  VOD_X_1997_2018_multiyear_mean_m08  \\\n",
       "0                                0.495728                            0.482645   \n",
       "1                                0.382672                            0.364023   \n",
       "3                                0.525224                            0.571438   \n",
       "4                                0.647654                            0.639092   \n",
       "5                                0.264103                            0.265927   \n",
       "...                                   ...                                 ...   \n",
       "43358                            0.502834                            0.504981   \n",
       "43359                            0.488227                            0.452186   \n",
       "43360                            0.213125                            0.212327   \n",
       "43361                            0.388565                            0.408230   \n",
       "43362                            0.554956                            0.566788   \n",
       "\n",
       "       VOD_X_1997_2018_multiyear_mean_m09  VOD_X_1997_2018_multiyear_mean_m10  \\\n",
       "0                                0.448959                            0.419139   \n",
       "1                                0.362919                            0.368997   \n",
       "3                                0.572420                            0.566320   \n",
       "4                                0.634200                            0.628594   \n",
       "5                                0.265918                            0.267588   \n",
       "...                                   ...                                 ...   \n",
       "43358                            0.510419                            0.502823   \n",
       "43359                            0.428144                            0.417601   \n",
       "43360                            0.200607                            0.187665   \n",
       "43361                            0.417128                            0.424777   \n",
       "43362                            0.566342                            0.499203   \n",
       "\n",
       "       VOD_X_1997_2018_multiyear_mean_m11  VOD_X_1997_2018_multiyear_mean_m12  \n",
       "0                                0.404626                            0.403707  \n",
       "1                                0.391109                            0.407680  \n",
       "3                                0.556564                            0.512105  \n",
       "4                                0.644814                            0.654979  \n",
       "5                                0.263034                            0.265842  \n",
       "...                                   ...                                 ...  \n",
       "43358                            0.497064                            0.487178  \n",
       "43359                            0.417884                            0.424877  \n",
       "43360                            0.178380                            0.170875  \n",
       "43361                            0.395074                            0.371460  \n",
       "43362                            0.448192                            0.419320  \n",
       "\n",
       "[38422 rows x 163 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JPEG Files Processing:\n",
      "JPEG Files Processing End\n"
     ]
    }
   ],
   "source": [
    "if CONFIG.SHRINK_SAMPLES: #this one's destructive\n",
    "    # construct correlation matrix\n",
    "    corr_matrix = tabular.corr(method='spearman')\n",
    "    \n",
    "    # hierarchical cluster based on the correlations\n",
    "    dissimilarity = 1 - abs(corr_matrix.values)\n",
    "    \n",
    "    linkage_matrix = hierarchy.linkage(squareform(dissimilarity), method='complete')\n",
    "    \n",
    "    # get the cluster labels\n",
    "    threshold = 0.15\n",
    "    cluster_labels = hierarchy.fcluster(linkage_matrix, threshold, criterion='distance')\n",
    "    n_clusters = np.unique(cluster_labels).shape[0]\n",
    "    print(f'Number of clusters: {n_clusters}\\n')\n",
    "    \n",
    "    \n",
    "    cluster_features = {}\n",
    "    # show features within each cluster\n",
    "    for label in range(1, n_clusters + 1):\n",
    "        leaves_in_cluster = cluster_labels == label\n",
    "        cluster_features[label] = corr_matrix.columns[leaves_in_cluster].tolist()\n",
    "        \n",
    "    final_features = []\n",
    "    for cols_in_cluster in cluster_features.values():\n",
    "        final_features.append(cols_in_cluster[0])\n",
    "        \n",
    "    tabular = tabular[final_features]\n",
    "    test_tabular = test_tabular[final_features]\n",
    "    # normalize tabular inputs\n",
    "\n",
    "LOG_FEATURES = ['X4_mean', 'X11_mean', 'X18_mean', 'X50_mean', 'X26_mean', 'X3112_mean']\n",
    "\n",
    "y_train = np.zeros_like(train[CONFIG.TARGET_COLUMNS], dtype=np.float32)\n",
    "for target_idx, target in enumerate(CONFIG.TARGET_COLUMNS):\n",
    "    v = train[target].values\n",
    "    if target in LOG_FEATURES:\n",
    "        v = np.log10(v)\n",
    "    y_train[:, target_idx] = v\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_SCALER = StandardScaler()\n",
    "tabular_scaled = X_SCALER.fit_transform(tabular).astype(np.float32)\n",
    "test_tabular_scaled = X_SCALER.transform(test_tabular).astype(np.float32)\n",
    "\n",
    "Y_SCALER = StandardScaler()\n",
    "y_train_scaled = Y_SCALER.fit_transform(y_train).astype(np.float32)\n",
    "\n",
    "\n",
    "print('JPEG Files Processing:')\n",
    "train['file_path'] = train['id'].apply(lambda s: f'{BASE_DIR}/train_images/{s}.jpeg')\n",
    "train['jpeg_bytes'] = train['file_path'].apply(lambda fp: open(fp, 'rb').read())\n",
    "\n",
    "test['file_path'] = test['id'].apply(lambda s: f'{BASE_DIR}/test_images/{s}.jpeg')\n",
    "test['jpeg_bytes'] = test['file_path'].apply(lambda fp: open(fp, 'rb').read())\n",
    "print('JPEG Files Processing End')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG.N_TRAIN_SAMPLES = len(tabular_scaled)\n",
    "CONFIG.N_STEPS_PER_EPOCH = (CONFIG.N_TRAIN_SAMPLES // CONFIG.BATCH_SIZE)\n",
    "CONFIG.N_STEPS = CONFIG.N_STEPS_PER_EPOCH * CONFIG.N_EPOCHS + 1\n",
    "MEAN = [0.485, 0.456, 0.406]\n",
    "STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "TRAIN_TRANSFORMS = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomSizedCrop(\n",
    "        [50,50],\n",
    "        CONFIG.IMAGE_SIZE, CONFIG.IMAGE_SIZE, w2h_ratio=1.0, p=0.75),\n",
    "    A.Resize(CONFIG.IMAGE_SIZE, CONFIG.IMAGE_SIZE),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.25),\n",
    "    A.ImageCompression(quality_lower=85, quality_upper=100, p=0.25),\n",
    "    A.ToFloat(),\n",
    "    A.Normalize(mean=MEAN, std=STD, max_pixel_value=1),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "TEST_TRANSFORMS = A.Compose([\n",
    "    A.Resize(CONFIG.IMAGE_SIZE, CONFIG.IMAGE_SIZE),\n",
    "    A.ToFloat(),\n",
    "    A.Normalize(mean=MEAN, std=STD, max_pixel_value=1),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "# train / test split\n",
    "train_idx = np.random.choice(len(train), int(1 * len(train)), replace=False)\n",
    "test_idx = np.setdiff1d(np.arange(len(train)), train_idx)\n",
    "\n",
    "train_images = train['jpeg_bytes'].values[train_idx]\n",
    "train_tabular = tabular_scaled[train_idx]\n",
    "train_y = y_train_scaled[train_idx]\n",
    "\n",
    "val_images = train['jpeg_bytes'].values[test_idx]\n",
    "val_tabular = tabular_scaled[test_idx]\n",
    "val_y = y_train_scaled[test_idx]\n",
    "\n",
    "test_images = test['jpeg_bytes'].values\n",
    "test_tabular = test_tabular_scaled\n",
    "\n",
    "train_dataset = TrainDataset(\n",
    "    train_images,\n",
    "    train_tabular,\n",
    "    train_y,\n",
    "    TRAIN_TRANSFORMS\n",
    ")\n",
    "\n",
    "validation_dataset = TrainDataset(\n",
    "    val_images,\n",
    "    val_tabular,\n",
    "    val_y,\n",
    "    TEST_TRANSFORMS\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=CONFIG.BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=0#psutil.cpu_count(),\n",
    ")\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "    validation_dataset,\n",
    "    batch_size=CONFIG.BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=0#psutil.cpu_count(),\n",
    ")\n",
    "\n",
    "test_dataset = TrainDataset(\n",
    "    test['jpeg_bytes'].values,\n",
    "    test_tabular,\n",
    "    test['id'].values,\n",
    "    TEST_TRANSFORMS,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=2,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=0#psutil.cpu_count(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_backbone = ImageBackbone('swin_large_patch4_window12_384.ms_in22k_ft_in1k', f'{BASE_DIR}/model_08_ensemble.pth', 384, fixed_feature_extractor=True)\n",
    "tab_backbone = TabularBackbone(n_features=tabular_scaled.shape[1], out_features=128)\n",
    "\n",
    "model = Model(img_backbone, tab_backbone, CONFIG.N_TARGETS)\n",
    "model = model.to(device)\n",
    "#model.load_state_dict(torch.load( f'{BASE_DIR}/model_08_ensemble.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # load model\n",
    "# # model.to(device)\n",
    "\n",
    "# # SUBMISSION_ROWS = []\n",
    "# # model.eval()\n",
    "\n",
    "# for X_image, X_tabular, test_id in tqdm(test_dataloader):\n",
    "#     with torch.no_grad():\n",
    "#         y_pred = model(X_image.to(device), X_tabular.to(device)).detach().cpu().numpy()\n",
    "#     print(y_pred.shape)\n",
    "#     y_pred = Y_SCALER.inverse_transform(y_pred).squeeze()\n",
    "#     row = {'id': int(test_id)}\n",
    "\n",
    "\n",
    "#     for k, v in zip(CONFIG.TARGET_COLUMNS, y_pred):\n",
    "#         if k in LOG_FEATURES:\n",
    "#             row[k.replace('_mean', '')] = 10 ** v\n",
    "#         else:\n",
    "#             row[k.replace('_mean', '')] = v\n",
    "\n",
    "#     SUBMISSION_ROWS.append(row)\n",
    "\n",
    "\n",
    "# TARGET_ORDER  = ['id','X4', 'X11', 'X18','X26', 'X50', 'X3112']    \n",
    "# submission_df = pd.DataFrame(SUBMISSION_ROWS)[TARGET_ORDER]\n",
    "# #[TARGET_ORDER]\n",
    "# submission_df.to_csv('efficient_net_submission.csv', index=False)\n",
    "# print(\"Submit!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "validation_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training:\n",
      "torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0001/9605 | loss: 0.2809, mae: 0.6548, r2: -0.5478, step: 0.102s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0002/9605 | loss: 0.3327, mae: 0.6930, r2: -0.4403, step: 0.097s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0003/9605 | loss: 0.4126, mae: 0.7825, r2: -0.2295, step: 0.098s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0004/9605 | loss: 0.4582, mae: 0.8463, r2: -0.3824, step: 0.098s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0005/9605 | loss: 0.4203, mae: 0.8024, r2: -0.4467, step: 0.098s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0006/9605 | loss: 0.3848, mae: 0.7554, r2: -0.4643, step: 0.098s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0007/9605 | loss: 0.4325, mae: 0.8100, r2: -0.3533, step: 0.098s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0008/9605 | loss: 0.4585, mae: 0.8424, r2: -0.4318, step: 0.097s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0009/9605 | loss: 0.4402, mae: 0.8197, r2: -0.2699, step: 0.097s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0010/9605 | loss: 0.4220, mae: 0.7994, r2: -0.2866, step: 0.098s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0011/9605 | loss: 0.4059, mae: 0.7747, r2: -0.3278, step: 0.098s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0012/9605 | loss: 0.4036, mae: 0.7751, r2: -0.3664, step: 0.098s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0013/9605 | loss: 0.4003, mae: 0.7711, r2: -0.2927, step: 0.098s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0014/9605 | loss: 0.3870, mae: 0.7576, r2: -0.3096, step: 0.098s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0015/9605 | loss: 0.3884, mae: 0.7562, r2: -0.3018, step: 0.098s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0016/9605 | loss: 0.3942, mae: 0.7647, r2: -0.3047, step: 0.098s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0017/9605 | loss: 0.3980, mae: 0.7708, r2: -0.3153, step: 0.098s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0018/9605 | loss: 0.4070, mae: 0.7796, r2: -0.1675, step: 0.097s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0019/9605 | loss: 0.4061, mae: 0.7772, r2: -0.1713, step: 0.098s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0020/9605 | loss: 0.4020, mae: 0.7744, r2: -0.1858, step: 0.098s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0021/9605 | loss: 0.3980, mae: 0.7678, r2: -0.1837, step: 0.098s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0022/9605 | loss: 0.4089, mae: 0.7802, r2: -0.1717, step: 0.098s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0023/9605 | loss: 0.4179, mae: 0.7916, r2: -0.1423, step: 0.098s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0024/9605 | loss: 0.4216, mae: 0.7943, r2: -0.1196, step: 0.098s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0025/9605 | loss: 0.4247, mae: 0.7966, r2: -0.0998, step: 0.098s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0026/9605 | loss: 0.4260, mae: 0.7982, r2: -0.1007, step: 0.098s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0027/9605 | loss: 0.4246, mae: 0.7959, r2: -0.0959, step: 0.098s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0028/9605 | loss: 0.4434, mae: 0.8150, r2: -0.0964, step: 0.098s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0029/9605 | loss: 0.4371, mae: 0.8082, r2: -0.0955, step: 0.098s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0030/9605 | loss: 0.4336, mae: 0.8044, r2: -0.0989, step: 0.098s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0031/9605 | loss: 0.4336, mae: 0.8052, r2: -0.0963, step: 0.098s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0032/9605 | loss: 0.4383, mae: 0.8107, r2: -0.1052, step: 0.098s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0033/9605 | loss: 0.4319, mae: 0.8041, r2: -0.1086, step: 0.098s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0034/9605 | loss: 0.4340, mae: 0.8074, r2: -0.1031, step: 0.098s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0035/9605 | loss: 0.4320, mae: 0.8046, r2: -0.1022, step: 0.098s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0036/9605 | loss: 0.4286, mae: 0.8021, r2: -0.1042, step: 0.098s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0037/9605 | loss: 0.4337, mae: 0.8073, r2: -0.0999, step: 0.098s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0038/9605 | loss: 0.4337, mae: 0.8077, r2: -0.0951, step: 0.098s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0039/9605 | loss: 0.4300, mae: 0.8035, r2: -0.0986, step: 0.098s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0040/9605 | loss: 0.4262, mae: 0.8000, r2: -0.1018, step: 0.098s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0041/9605 | loss: 0.4262, mae: 0.7990, r2: -0.1001, step: 0.098s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0042/9605 | loss: 0.4343, mae: 0.8071, r2: -0.0976, step: 0.099s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0043/9605 | loss: 0.4329, mae: 0.8066, r2: -0.1026, step: 0.098s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0044/9605 | loss: 0.4323, mae: 0.8070, r2: -0.1071, step: 0.099s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0045/9605 | loss: 0.4270, mae: 0.8004, r2: -0.1032, step: 0.098s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0046/9605 | loss: 0.4221, mae: 0.7935, r2: -0.1038, step: 0.098s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0047/9605 | loss: 0.4264, mae: 0.7968, r2: -0.0897, step: 0.098s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0048/9605 | loss: 0.4258, mae: 0.7962, r2: -0.0875, step: 0.098s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0049/9605 | loss: 0.4243, mae: 0.7951, r2: -0.0886, step: 0.098s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0050/9605 | loss: 0.4240, mae: 0.7951, r2: -0.0921, step: 0.098s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0051/9605 | loss: 0.4284, mae: 0.7999, r2: -0.0894, step: 0.098s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0052/9605 | loss: 0.4338, mae: 0.8065, r2: -0.0905, step: 0.098s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0053/9605 | loss: 0.4367, mae: 0.8094, r2: -0.0904, step: 0.098s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0054/9605 | loss: 0.4334, mae: 0.8061, r2: -0.0898, step: 0.098s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0055/9605 | loss: 0.4322, mae: 0.8046, r2: -0.0919, step: 0.098s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0056/9605 | loss: 0.4325, mae: 0.8047, r2: -0.0875, step: 0.098s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0057/9605 | loss: 0.4317, mae: 0.8034, r2: -0.0878, step: 0.098s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0058/9605 | loss: 0.4327, mae: 0.8052, r2: -0.0882, step: 0.098s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0059/9605 | loss: 0.4331, mae: 0.8054, r2: -0.0845, step: 0.098s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n",
      "EPOCH 01, 0060/9605 | loss: 0.4351, mae: 0.8076, r2: -0.0839, step: 0.098s, lr: 1.00e-05torch.Size([4, 6]) torch.Size([4, 6])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 53\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     46\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEPOCH \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m04d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCONFIG\u001b[38;5;241m.\u001b[39mN_STEPS_PER_EPOCH\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m     47\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mLOSS\u001b[38;5;241m.\u001b[39mavg\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, mae: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMAE\u001b[38;5;241m.\u001b[39mcompute()\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, r2: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mR2\u001b[38;5;241m.\u001b[39mcompute()\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m     48\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(time\u001b[38;5;241m.\u001b[39mperf_counter_ns()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mt_start)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1e-9\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms, lr: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mLR_SCHEDULER\u001b[38;5;241m.\u001b[39mget_last_lr()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2e\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     49\u001b[0m         )\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m CONFIG\u001b[38;5;241m.\u001b[39mIS_INTERACTIVE:\n\u001b[1;32m     51\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     52\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124mEPOCH \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m04d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCONFIG\u001b[38;5;241m.\u001b[39mN_STEPS_PER_EPOCH\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m---> 53\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mLOSS\u001b[38;5;241m.\u001b[39mavg\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, mae: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMAE\u001b[38;5;241m.\u001b[39mcompute()\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, r2: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mR2\u001b[38;5;241m.\u001b[39mcompute()\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m     54\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(time\u001b[38;5;241m.\u001b[39mperf_counter_ns()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mt_start)\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1e-9\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms, lr: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mLR_SCHEDULER\u001b[38;5;241m.\u001b[39mget_last_lr()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2e\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     55\u001b[0m             end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m CONFIG\u001b[38;5;241m.\u001b[39mN_STEPS_PER_EPOCH \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     56\u001b[0m         )\n\u001b[1;32m     57\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     58\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_gpu/lib/python3.12/site-packages/torch/_tensor.py:986\u001b[0m, in \u001b[0;36mTensor.__format__\u001b[0;34m(self, format_spec)\u001b[0m\n\u001b[1;32m    984\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__format__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, format_spec)\n\u001b[1;32m    985\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_meta \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m Tensor:\n\u001b[0;32m--> 986\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__format__\u001b[39m(format_spec)\n\u001b[1;32m    987\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__format__\u001b[39m(\u001b[38;5;28mself\u001b[39m, format_spec)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "MAE = torchmetrics.regression.MeanAbsoluteError().to(device)\n",
    "R2 = torchmetrics.regression.R2Score(num_outputs=CONFIG.N_TARGETS, multioutput='uniform_average').to(device)\n",
    "LOSS = AverageMeter()\n",
    "\n",
    "Y_MEAN = torch.tensor(y_train).mean(dim=0).to(device)\n",
    "EPS = torch.tensor([1e-6]).to(device)\n",
    "\n",
    "LOSS_FN = nn.SmoothL1Loss()  # r2_loss\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    params=model.parameters(),\n",
    "    lr=CONFIG.LR_MAX,\n",
    "    weight_decay=CONFIG.WEIGHT_DECAY,\n",
    ")\n",
    "\n",
    "LR_SCHEDULER = get_lr_scheduler(optimizer)\n",
    "\n",
    "\n",
    "print(\"Start Training:\")\n",
    "for epoch in range(CONFIG.N_EPOCHS):\n",
    "    MAE.reset()\n",
    "    R2.reset()\n",
    "    LOSS.reset()\n",
    "    model.train()\n",
    "\n",
    "    for step, (X_image, X_tabular, y_true) in enumerate(train_dataloader):\n",
    "        X_image = X_image.to(device)\n",
    "        X_tabular = X_tabular.to(device)\n",
    "        y_true = y_true.to(device)\n",
    "        model = model.to(device)\n",
    "        t_start = time.perf_counter_ns()\n",
    "        y_pred = model(X_image, X_tabular)\n",
    "        loss = LOSS_FN(y_pred, y_true)\n",
    "        LOSS.update(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # xm.optimizer_step(optimizer, barrier=True)\n",
    "        optimizer.zero_grad()\n",
    "        LR_SCHEDULER.step()\n",
    "        print(y_pred.shape , y_true.shape)\n",
    "        MAE.update(y_pred, y_true)\n",
    "        R2.update(y_pred, y_true)\n",
    "\n",
    "        if not CONFIG.IS_INTERACTIVE and (step + 1) == CONFIG.N_STEPS_PER_EPOCH:\n",
    "            print(\n",
    "                f'EPOCH {epoch + 1:02d}, {step + 1:04d}/{CONFIG.N_STEPS_PER_EPOCH} | ' +\n",
    "                f'loss: {LOSS.avg:.4f}, mae: {MAE.compute().item():.4f}, r2: {R2.compute().item():.4f}, ' +\n",
    "                f'step: {(time.perf_counter_ns() - t_start) * 1e-9:.3f}s, lr: {LR_SCHEDULER.get_last_lr()[0]:.2e}',\n",
    "            )\n",
    "        elif CONFIG.IS_INTERACTIVE:\n",
    "            print(\n",
    "                f'\\rEPOCH {epoch + 1:02d}, {step + 1:04d}/{CONFIG.N_STEPS_PER_EPOCH} | ' +\n",
    "                f'loss: {LOSS.avg:.4f}, mae: {MAE.compute().item():.4f}, r2: {R2.compute().item():.4f}, ' +\n",
    "                f'step: {(time.perf_counter_ns() - t_start) * 1e-9:.3f}s, lr: {LR_SCHEDULER.get_last_lr()[0]:.2e}',\n",
    "                end='\\n' if (step + 1) == CONFIG.N_STEPS_PER_EPOCH else '', flush=True,\n",
    "            )\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    MAE.reset()\n",
    "    R2.reset()\n",
    "    LOSS.reset()\n",
    "\n",
    "    print('IN  Validation:')\n",
    "    with torch.no_grad():\n",
    "        for X_image, X_tabular, y_true in (validation_dataloader):\n",
    "            X_image = X_image.to(device)\n",
    "            y_true = y_true.to(device)\n",
    "            y_pred = model(X_image, X_tabular)\n",
    "            loss = LOSS_FN(y_pred, y_true)\n",
    "            LOSS.update(loss)\n",
    "            MAE.update(y_pred, y_true)\n",
    "            R2.update(y_pred, y_true)\n",
    "\n",
    "            if not CONFIG.IS_INTERACTIVE:\n",
    "                print(\n",
    "                    f'EPOCH {epoch + 1:02d}, VALIDATION | ' +\n",
    "                    f'loss: {LOSS.avg:.4f}, mae: {MAE.compute().item():.4f}, r2: {R2.compute().item():.4f}',\n",
    "                )\n",
    "            elif CONFIG.IS_INTERACTIVE:\n",
    "                print(\n",
    "                    f'\\rEPOCH {epoch + 1:02d}, VALIDATION | ' +\n",
    "                    f'loss: {LOSS.avg:.4f}, mae: {MAE.compute().item():.4f}, r2: {R2.compute().item():.4f}',\n",
    "                    end='\\n',\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2 = torchmetrics.regression.R2Score(num_outputs=CONFIG.N_TARGETS, multioutput='uniform_average').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "CONFIG.N_TARGETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R2sc = torchmetrics.regression.R2Score(num_outputs= CONFIG.N_TARGETS , multioutput=\"uniform_average\").to(device)\n",
    "\n",
    "t1 = torch.ones((2,6)).to(device)\n",
    "t2 = torch.ones((2,6)).to(device)\n",
    "R2sc.update(t1 , t2 )\n",
    "R2sc.compute().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
