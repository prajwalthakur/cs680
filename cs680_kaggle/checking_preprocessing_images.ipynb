{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from urllib.request import urlopen\n",
    "# from PIL import Image\n",
    "# img = Image.open(urlopen(\n",
    "#     'https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png'\n",
    "# ))\n",
    "\n",
    "# def Show_Image(Image, Picture_Name):\n",
    "#     plt.imshow(Image)\n",
    "#     plt.title(Picture_Name)\n",
    "#     plt.show()\n",
    "# train_transform =A.Compose([\n",
    "#         A.RandomRotate90(),\n",
    "#         A.Flip(),\n",
    "#         A.Transpose(),\n",
    "#         A.GaussNoise(),\n",
    "#         A.OneOf([\n",
    "#             A.MotionBlur(p=.2),\n",
    "#             A.MedianBlur(blur_limit=3, p=0.1),\n",
    "#             A.Blur(blur_limit=3, p=0.1),\n",
    "#         ], p=0.2),\n",
    "#         A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=45, p=0.2),\n",
    "#         A.OneOf([\n",
    "#             A.OpticalDistortion(p=0.3),\n",
    "#             A.GridDistortion(p=.1),\n",
    "#         ], p=0.2),\n",
    "#         A.OneOf([\n",
    "#             A.CLAHE(clip_limit=2),\n",
    "#             A.RandomBrightnessContrast(),\n",
    "#         ], p=0.3),\n",
    "#         A.HueSaturationValue(p=0.3),\n",
    "#         A.Resize(CONFIG.TARGET_IMAGE_SIZE, CONFIG.TARGET_IMAGE_SIZE,interpolation= cv2.INTER_LINEAR,p=0.5),\n",
    "#         A.ToFloat(),\n",
    "#         A.Normalize([0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225], max_pixel_value=1),\n",
    "#         ToTensorV2(),\n",
    "#     ])\n",
    "# img = plt.imread(train_df.iloc[200][\"image_path\"])\n",
    "# img2 = train_transform(image = img)[\"image\"]\n",
    "# Show_Image( img, 'cat')\n",
    "# Show_Image( img2, 'cat')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
