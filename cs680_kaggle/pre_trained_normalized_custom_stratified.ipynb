{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import cv2 \n",
    "import IPython\n",
    "from glob import glob\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tqdm\n",
    "#import seaborn as sns\n",
    "import albumentations as A\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "from torcheval.metrics import R2Score\n",
    "import wandb\n",
    "import torchvision\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BASE_DIR = os.path.join(os.getcwd() , 'data')\n",
    "train_df = pd.read_csv(BASE_DIR  +  '/train.csv')\n",
    "TRAIN_VAL_SPLIT_SIZE = 0.2\n",
    "TRAIN_BATCH_SIZE =128\n",
    "VAL_BATCH_SIZE = 128\n",
    "\n",
    "LEARNING_RATE =   1e-4\n",
    "EPOCHS = 10\n",
    "TIM_NUM_CLASS = 128\n",
    "Normalize_transform_type = \"log_transform\"\n",
    "RANDOM_NUMBER = 42\n",
    "NUM_FLODS  = 5\n",
    "NUM_CLASSES = 6\n",
    "TRAITS_NAME = ['X4_mean', 'X11_mean', 'X18_mean', 'X26_mean', 'X50_mean', 'X3112_mean' ]\n",
    "FOLD = 0 # Which fold to set as validation data\n",
    "torch.manual_seed(RANDOM_NUMBER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wandb.login()\n",
    "\n",
    "# wandb.init(project=\"cs680v2_normalized\",\n",
    "#     config={\n",
    "#        \"learning_rate\": LEARNING_RATE,\n",
    "#         \"epochs\": EPOCHS,\n",
    "#         \"batch_size\" : TRAIN_BATCH_SIZE,\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DATA_DIRECTORY = os.path.join(os.getcwd(),\"data\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXTRA_COLOUMN = ['WORLDCLIM_BIO1_annual_mean_temperature',\n",
    "       'WORLDCLIM_BIO12_annual_precipitation',\n",
    "       'WORLDCLIM_BIO13.BIO14_delta_precipitation_of_wettest_and_dryest_month',\n",
    "       'WORLDCLIM_BIO15_precipitation_seasonality',\n",
    "       'WORLDCLIM_BIO4_temperature_seasonality',\n",
    "       'WORLDCLIM_BIO7_temperature_annual_range',\n",
    "       'SOIL_bdod_0.5cm_mean_0.01_deg',\n",
    "       'SOIL_bdod_100.200cm_mean_0.01_deg',\n",
    "       'SOIL_bdod_15.30cm_mean_0.01_deg',\n",
    "       'SOIL_bdod_30.60cm_mean_0.01_deg',\n",
    "       'SOIL_bdod_5.15cm_mean_0.01_deg',\n",
    "       'SOIL_bdod_60.100cm_mean_0.01_deg', 'SOIL_cec_0.5cm_mean_0.01_deg',\n",
    "       'SOIL_cec_100.200cm_mean_0.01_deg',\n",
    "       'SOIL_cec_15.30cm_mean_0.01_deg', 'SOIL_cec_30.60cm_mean_0.01_deg',\n",
    "       'SOIL_cec_5.15cm_mean_0.01_deg', 'SOIL_cec_60.100cm_mean_0.01_deg',\n",
    "       'SOIL_cfvo_0.5cm_mean_0.01_deg',\n",
    "       'SOIL_cfvo_100.200cm_mean_0.01_deg',\n",
    "       'SOIL_cfvo_15.30cm_mean_0.01_deg',\n",
    "       'SOIL_cfvo_30.60cm_mean_0.01_deg',\n",
    "       'SOIL_cfvo_5.15cm_mean_0.01_deg',\n",
    "       'SOIL_cfvo_60.100cm_mean_0.01_deg',\n",
    "       'SOIL_clay_0.5cm_mean_0.01_deg',\n",
    "       'SOIL_clay_100.200cm_mean_0.01_deg',\n",
    "       'SOIL_clay_15.30cm_mean_0.01_deg',\n",
    "       'SOIL_clay_30.60cm_mean_0.01_deg',\n",
    "       'SOIL_clay_5.15cm_mean_0.01_deg',\n",
    "       'SOIL_clay_60.100cm_mean_0.01_deg',\n",
    "       'SOIL_nitrogen_0.5cm_mean_0.01_deg',\n",
    "       'SOIL_nitrogen_100.200cm_mean_0.01_deg',\n",
    "       'SOIL_nitrogen_15.30cm_mean_0.01_deg',\n",
    "       'SOIL_nitrogen_30.60cm_mean_0.01_deg',\n",
    "       'SOIL_nitrogen_5.15cm_mean_0.01_deg',\n",
    "       'SOIL_nitrogen_60.100cm_mean_0.01_deg',\n",
    "       'SOIL_ocd_0.5cm_mean_0.01_deg', 'SOIL_ocd_100.200cm_mean_0.01_deg',\n",
    "       'SOIL_ocd_15.30cm_mean_0.01_deg', 'SOIL_ocd_30.60cm_mean_0.01_deg',\n",
    "       'SOIL_ocd_5.15cm_mean_0.01_deg', 'SOIL_ocd_60.100cm_mean_0.01_deg',\n",
    "       'SOIL_ocs_0.30cm_mean_0.01_deg', 'SOIL_phh2o_0.5cm_mean_0.01_deg',\n",
    "       'SOIL_phh2o_100.200cm_mean_0.01_deg',\n",
    "       'SOIL_phh2o_15.30cm_mean_0.01_deg',\n",
    "       'SOIL_phh2o_30.60cm_mean_0.01_deg',\n",
    "       'SOIL_phh2o_5.15cm_mean_0.01_deg',\n",
    "       'SOIL_phh2o_60.100cm_mean_0.01_deg',\n",
    "       'SOIL_sand_0.5cm_mean_0.01_deg',\n",
    "       'SOIL_sand_100.200cm_mean_0.01_deg',\n",
    "       'SOIL_sand_15.30cm_mean_0.01_deg',\n",
    "       'SOIL_sand_30.60cm_mean_0.01_deg',\n",
    "       'SOIL_sand_5.15cm_mean_0.01_deg',\n",
    "       'SOIL_sand_60.100cm_mean_0.01_deg',\n",
    "       'SOIL_silt_0.5cm_mean_0.01_deg',\n",
    "       'SOIL_silt_100.200cm_mean_0.01_deg',\n",
    "       'SOIL_silt_15.30cm_mean_0.01_deg',\n",
    "       'SOIL_silt_30.60cm_mean_0.01_deg',\n",
    "       'SOIL_silt_5.15cm_mean_0.01_deg',\n",
    "       'SOIL_silt_60.100cm_mean_0.01_deg', 'SOIL_soc_0.5cm_mean_0.01_deg',\n",
    "       'SOIL_soc_100.200cm_mean_0.01_deg',\n",
    "       'SOIL_soc_15.30cm_mean_0.01_deg', 'SOIL_soc_30.60cm_mean_0.01_deg',\n",
    "       'SOIL_soc_5.15cm_mean_0.01_deg', 'SOIL_soc_60.100cm_mean_0.01_deg',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_01_._month_m1',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_02_._month_m1',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_03_._month_m1',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_04_._month_m1',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_05_._month_m1',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_01_._month_m10',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_02_._month_m10',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_03_._month_m10',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_04_._month_m10',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_05_._month_m10',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_01_._month_m11',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_02_._month_m11',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_03_._month_m11',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_04_._month_m11',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_05_._month_m11',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_01_._month_m12',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_02_._month_m12',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_03_._month_m12',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_04_._month_m12',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_05_._month_m12',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_01_._month_m2',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_02_._month_m2',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_03_._month_m2',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_04_._month_m2',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_05_._month_m2',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_01_._month_m3',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_02_._month_m3',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_03_._month_m3',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_04_._month_m3',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_05_._month_m3',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_01_._month_m4',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_02_._month_m4',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_03_._month_m4',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_04_._month_m4',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_05_._month_m4',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_01_._month_m5',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_02_._month_m5',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_03_._month_m5',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_04_._month_m5',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_05_._month_m5',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_01_._month_m6',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_02_._month_m6',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_03_._month_m6',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_04_._month_m6',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_05_._month_m6',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_01_._month_m7',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_02_._month_m7',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_03_._month_m7',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_04_._month_m7',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_05_._month_m7',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_01_._month_m8',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_02_._month_m8',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_03_._month_m8',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_04_._month_m8',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_05_._month_m8',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_01_._month_m9',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_02_._month_m9',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_03_._month_m9',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_04_._month_m9',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_05_._month_m9',\n",
    "       'VOD_C_2002_2018_multiyear_mean_m01',\n",
    "       'VOD_C_2002_2018_multiyear_mean_m02',\n",
    "       'VOD_C_2002_2018_multiyear_mean_m03',\n",
    "       'VOD_C_2002_2018_multiyear_mean_m04',\n",
    "       'VOD_C_2002_2018_multiyear_mean_m05',\n",
    "       'VOD_C_2002_2018_multiyear_mean_m06',\n",
    "       'VOD_C_2002_2018_multiyear_mean_m07',\n",
    "       'VOD_C_2002_2018_multiyear_mean_m08',\n",
    "       'VOD_C_2002_2018_multiyear_mean_m09',\n",
    "       'VOD_C_2002_2018_multiyear_mean_m10',\n",
    "       'VOD_C_2002_2018_multiyear_mean_m11',\n",
    "       'VOD_C_2002_2018_multiyear_mean_m12',\n",
    "       'VOD_Ku_1987_2017_multiyear_mean_m01',\n",
    "       'VOD_Ku_1987_2017_multiyear_mean_m02',\n",
    "       'VOD_Ku_1987_2017_multiyear_mean_m03',\n",
    "       'VOD_Ku_1987_2017_multiyear_mean_m04',\n",
    "       'VOD_Ku_1987_2017_multiyear_mean_m05',\n",
    "       'VOD_Ku_1987_2017_multiyear_mean_m06',\n",
    "       'VOD_Ku_1987_2017_multiyear_mean_m07',\n",
    "       'VOD_Ku_1987_2017_multiyear_mean_m08',\n",
    "       'VOD_Ku_1987_2017_multiyear_mean_m09',\n",
    "       'VOD_Ku_1987_2017_multiyear_mean_m10',\n",
    "       'VOD_Ku_1987_2017_multiyear_mean_m11',\n",
    "       'VOD_Ku_1987_2017_multiyear_mean_m12',\n",
    "       'VOD_X_1997_2018_multiyear_mean_m01',\n",
    "       'VOD_X_1997_2018_multiyear_mean_m02',\n",
    "       'VOD_X_1997_2018_multiyear_mean_m03',\n",
    "       'VOD_X_1997_2018_multiyear_mean_m04',\n",
    "       'VOD_X_1997_2018_multiyear_mean_m05',\n",
    "       'VOD_X_1997_2018_multiyear_mean_m06',\n",
    "       'VOD_X_1997_2018_multiyear_mean_m07',\n",
    "       'VOD_X_1997_2018_multiyear_mean_m08',\n",
    "       'VOD_X_1997_2018_multiyear_mean_m09',\n",
    "       'VOD_X_1997_2018_multiyear_mean_m10',\n",
    "       'VOD_X_1997_2018_multiyear_mean_m11',\n",
    "       'VOD_X_1997_2018_multiyear_mean_m12']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "SCALAR = StandardScaler()\n",
    "\n",
    "def create_val_train_dataset(BASE_DIR,train_split_size,scalar:StandardScaler):\n",
    "    df = pd.read_csv(BASE_DIR  +  '/train.csv')\n",
    "    df[\"image_path\"] = BASE_DIR + \"/train_images/\" + df[\"id\"].astype(str) + \".jpeg\"   # add images in the training dataframe\n",
    "    \n",
    "    # standardize the dataset\n",
    "    scalar.fit(df[EXTRA_COLOUMN])\n",
    "    df[EXTRA_COLOUMN] = scalar.transform(df[EXTRA_COLOUMN])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=NUM_FLODS, shuffle=True, random_state=42)\n",
    "\n",
    "    # Create separate bin for each traits\n",
    "    for i, trait in enumerate(TRAITS_NAME):\n",
    "\n",
    "        # Determine the bin edges dynamically based on the distribution of traits\n",
    "        bin_edges = np.percentile(df[trait], np.linspace(0, 100, NUM_FLODS + 1))\n",
    "        df[f\"bin_{i}\"] = np.digitize(df[trait], bin_edges)\n",
    "\n",
    "    # Concatenate the bins into a final bin\n",
    "    df[\"final_bin\"] = (\n",
    "        df[[f\"bin_{i}\" for i in range(NUM_CLASSES)]]\n",
    "        .astype(str)\n",
    "        .agg(\"\".join, axis=1)\n",
    "    )\n",
    "\n",
    "    # Perform the stratified split using final bin\n",
    "    df = df.reset_index(drop=True)\n",
    "    for fold, (train_idx, valid_idx) in enumerate(skf.split(df, df[\"final_bin\"])):\n",
    "        df.loc[valid_idx, \"fold\"] = fold\n",
    "    sample_df = df.copy()\n",
    "    train_df = sample_df[sample_df.fold != FOLD]\n",
    "    val_df = sample_df[sample_df.fold == FOLD]\n",
    "    print(f\"# Num Train: {len(train_df)} | Num Valid: {len(val_df)}\")\n",
    "    \n",
    "    \n",
    "    #train_df , val_df = train_test_split(df,test_size=train_split_size,shuffle=True)\n",
    "    \n",
    "    train_df.reset_index(drop=True , inplace  = True)\n",
    "    val_df.reset_index(drop = True , inplace = True)\n",
    "    return  train_df , val_df\n",
    "def create_test_dataset(BASE_DIR,scalar):\n",
    "    df = pd.read_csv(BASE_DIR  +  '/test.csv')\n",
    "    df[\"image_path\"] = BASE_DIR + \"/test_images/\" + df[\"id\"].astype(str) + \".jpeg\"   # add images in the training dataframe\n",
    "    df[EXTRA_COLOUMN] = scalar.transform(df[EXTRA_COLOUMN])\n",
    "    return df\n",
    "\n",
    "train_df , val_df = create_val_train_dataset(BASE_DIR,TRAIN_VAL_SPLIT_SIZE,scalar = SCALAR)\n",
    "test_df = create_test_dataset(BASE_DIR,scalar=SCALAR)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalizeOutput():\n",
    "    def __init__(self,type_transform ):\n",
    "        self.transform = type_transform\n",
    "        self.mean = 0\n",
    "        self.std = 0\n",
    "        self.mean_tensor = 0\n",
    "        self.std_tensor = 0\n",
    "        \n",
    "        pass\n",
    "    def normalize(self,df):\n",
    "        if self.transform == \"log_transform\":\n",
    "            mean = np.log10(df).mean()\n",
    "            std = np.log10(df).std()\n",
    "            self.mean = mean\n",
    "            self.std = std\n",
    "            self.mean_tensor = torch.Tensor(self.mean.values).to(DEVICE)\n",
    "            self.std_tensor = torch.Tensor(self.std.values).to(DEVICE)\n",
    "            return (np.log10(df) - self.mean)/self.std\n",
    "    def denormalize(self,df):\n",
    "        if self.mean is None or self.std is None :\n",
    "            raise Exception(\"mean and/std is not defined \")\n",
    "        if self.normalize == \"log_transform\":\n",
    "            df_denormalize =10**((df*self.std) + self.mean )\n",
    "            return df_denormalize\n",
    "    def denormalize_tensor(self,batch) :\n",
    "        if self.mean_tensor is None or self.std_tensor is None :\n",
    "            raise Exception(\"mean and/std is not defined \")\n",
    "        if self.transform == \"log_transform\":\n",
    "            df_denormalize =10**((batch*self.std_tensor) + self.mean_tensor )\n",
    "            return df_denormalize\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = plt.imread(val_df[\"image_path\"].iloc[0])\n",
    "# plt.imshow(img)\n",
    "# img.shape\n",
    "#train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to avoid overfitting : 1) try diffferent transformations 2) batch norm 3)  dropout  4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations.pytorch import ToTensorV2\n",
    "IMAGE_SIZE =128\n",
    "class data_loader(Dataset ):\n",
    "    def __init__(self,df , is_val = False,normalizedOutput=None, extra_params = False ):\n",
    "        global EXTRA_COLOUMN\n",
    "        self.df = df.copy()\n",
    "        if normalizedOutput == None:\n",
    "            pass\n",
    "        else :\n",
    "            if not is_val :\n",
    "                self.df[['X4_mean', 'X11_mean', 'X18_mean', 'X26_mean', 'X50_mean', 'X3112_mean' ]] = normalizedOutput.normalize(self.df[['X4_mean', 'X11_mean', 'X18_mean', 'X26_mean', 'X50_mean', 'X3112_mean' ]])\n",
    "\n",
    "        # self.transform =torchvision.transforms.Compose([\n",
    "        #                        torchvision.transforms.ToTensor(),\n",
    "        #                          #torchvision.transforms.Resize((384,384)),\n",
    "        #                           torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225]),\n",
    "        #                             torchvision.transforms.RandomVerticalFlip(p=0.5),\n",
    "        #                             torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "        #                             torchvision.transforms.RandomChoice([\n",
    "        #                                 torchvision.transforms.Lambda(lambda x : x + np.sqrt(0.1)*torch.randn_like(x)),\n",
    "        #                                 torchvision.transforms.Lambda(lambda x : x + 0.1*torch.randn_like(x)),\n",
    "        #                                 torchvision.transforms.Lambda(lambda x : x + torch.randn_like(x))])\n",
    "        #                      ])\n",
    "        self.transform = A.Compose( \n",
    "                                   [\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.RandomSizedCrop(\n",
    "                [64, 64],\n",
    "                IMAGE_SIZE, IMAGE_SIZE, w2h_ratio=1.0, p=0.75),\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.25),\n",
    "            A.ImageCompression(quality_lower=85, quality_upper=100, p=0.25),\n",
    "            A.ToFloat(),\n",
    "            A.Normalize([0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225], max_pixel_value=1),\n",
    "            ToTensorV2()] )\n",
    "    \n",
    "        self.extra_params = extra_params\n",
    "        self.extra_coloumns = EXTRA_COLOUMN\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self , index):\n",
    "        row = self.df.iloc[index]\n",
    "        image = plt.imread(row[\"image_path\"])\n",
    "        #image = np.copy(image)\n",
    "        traits = row[['X4_mean', 'X11_mean', 'X18_mean', 'X26_mean', 'X50_mean', 'X3112_mean' ]].values.astype(np.float32)\n",
    "        traits = torch.tensor(traits,dtype=torch.float32)\n",
    "        if self.transform :\n",
    "            image = self.transform(image = image)[\"image\"]\n",
    "            #image = torch.permute(image  )\n",
    "        if self.extra_params:\n",
    "            extras = row[self.extra_coloumns].values.astype(np.float32)\n",
    "            return image , traits  , torch.tensor(extras,dtype=torch.float32)\n",
    "        return  image , traits\n",
    "normalize_function = NormalizeOutput(Normalize_transform_type)\n",
    "train_dataset = data_loader(train_df, is_val = False,normalizedOutput=normalize_function ,extra_params=True)\n",
    "val_dataset  = data_loader(val_df,   is_val = True,normalizedOutput=normalize_function , extra_params=True)    \n",
    "\n",
    "train_dataloader = DataLoader(train_dataset , batch_size = TRAIN_BATCH_SIZE , shuffle=True )\n",
    "val_dataloader = DataLoader(val_dataset , batch_size =  VAL_BATCH_SIZE , shuffle=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader(next(iter(train_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class R2Loss(nn.Module):\n",
    "#     def __init__(self, num_classes=6):\n",
    "#         super(R2Loss, self).__init__()\n",
    "#         # Initialize learnable weights for each class, one weight per class\n",
    "#         # self.class_weights = nn.Parameter(torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 1.0], dtype=torch.float32))\n",
    "#         # Increase weight for X_26_mean\n",
    "\n",
    "#     def forward(self, y_pred, y_true):\n",
    "#         # Calculate residual sum of squares per class\n",
    "#         SS_res = torch.sum((y_true - y_pred) ** 2, dim=0)  # (B, C) -> (C,)\n",
    "#         # Calculate total sum of squares per class\n",
    "#         SS_tot = torch.sum(\n",
    "#             (y_true - torch.mean(y_true, dim=0)) ** 2, dim=0\n",
    "#         )  # (B, C) -> (C,)\n",
    "#         # Calculate R2 loss per class, avoiding division by zero\n",
    "#         r2_loss =SS_res / (SS_tot + 1e-6)  # (C,)\n",
    "#         # Weight the R2 loss by the learnable class weights\n",
    "#         # weighted_r2_loss = self.class_weights * r2_loss\n",
    "#         # Return the mean of the weighted R2 loss\n",
    "#         return torch.mean(r2_loss)\n",
    "# def initialize_timm_model( model_name   , num_class):\n",
    "#     model_ft  = None\n",
    "#     if model_name == \"resnet34\" :\n",
    "#         \"\"\" Resnet34 \"\"\"\n",
    "#         model = timm.create_model('resnet34' , num_classes=num_class )\n",
    "#         return model\n",
    "#     # if model_name == \"Swin_Transformer\":\n",
    "#     #     model = timm.create_model('swin_large_patch4_window12_384.ms_in22k_ft_in1k' , num_classes = 6 , pretrained=True)\n",
    "#     #     return model \n",
    "#     if model_name ==\"convnextv2\":\n",
    "#         model = timm.create_model('convnext_tiny.in12k_ft_in1k_384',num_classes=num_class)\n",
    "#         return model \n",
    "    \n",
    "#     if model_name == \"efficientnet\":\n",
    "#         model = timm.create_model(\"efficientnet_b0\",pretrained = True)\n",
    "#         # for param in model.parameters():\n",
    "#         #         param.requires_grad = False\n",
    "#         # model.conv_head.trainable = True\n",
    "#         # model.blocks[-1].trainable = True\n",
    "#         # model.bn2.trainable = True\n",
    "#         model.classifier = nn.Sequential(\n",
    "#             nn.Linear(in_features=1280, out_features=768, bias=True),\n",
    "#             nn.BatchNorm1d(num_features=768),\n",
    "#             nn.Dropout(p=0.0, inplace=False),\n",
    "#             nn.Linear(in_features=768, out_features=256, bias=True),\n",
    "#             nn.BatchNorm1d(num_features=256),\n",
    "#             nn.Dropout(p=0.0, inplace=False),\n",
    "#             nn.Linear(in_features=256, out_features=num_class, bias=True),\n",
    "#             # nn.Dropout(p=0.0, inplace=False),\n",
    "#             # nn.Linear(in_features=128, out_features=64, bias=True),\n",
    "#             # nn.Dropout(p=0.0, inplace=False),\n",
    "#             # nn.Linear(in_features=64, out_features=32, bias=True),\n",
    "#             # nn.Dropout(p=0.0, inplace=False),\n",
    "#             # nn.Linear(in_features=32, out_features=num_class, bias=True),\n",
    "#         )\n",
    "#         return model\n",
    "\n",
    "# class CustomModel(nn.Module):\n",
    "    \n",
    "#     def __init__(self,input_channels,tim_num_class , model):\n",
    "#         super().__init__()\n",
    "#         # if model ==\"resnet34\":\n",
    "#         self.backbone = initialize_timm_model(model_name=model ,num_class=tim_num_class)\n",
    "#         self.extra_parameters_models = nn.Sequential(\n",
    "#             nn.Linear(input_channels,256),\n",
    "#             nn.BatchNorm1d(num_features=256),\n",
    "#             nn.ReLU(),\n",
    "#             #nn.Dropout1d()\n",
    "#             nn.Linear(256,512),\n",
    "#             nn.BatchNorm1d(num_features=512),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(512,256),\n",
    "#             nn.BatchNorm1d(num_features=256),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(256,128),\n",
    "#             nn.BatchNorm1d(num_features=128),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(128,64),\n",
    "#         )\n",
    "#         self.output = nn.Sequential(\n",
    "#             nn.Linear(tim_num_class+64,64),\n",
    "#             nn.BatchNorm1d(num_features=64),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(64,32),\n",
    "#             nn.BatchNorm1d(num_features=32),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(32,16),\n",
    "#             nn.BatchNorm1d(num_features=16),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(16,6)\n",
    "#         )\n",
    "        \n",
    "#     def forward(self,image,x):\n",
    "#         output_image = self.backbone(image) # bach * (hight*col)\n",
    "#         z = self.extra_parameters_models(x) # batch * 16\n",
    "#         inputs  = torch.cat((output_image,z), 1 )\n",
    "#         output = self.output(inputs)\n",
    "#         return output\n",
    "\n",
    "# def get_model_optimizer_lossFunction(model_name,learning_rate,extra_params = False):\n",
    "#     global DEVICE\n",
    "#     if extra_params:\n",
    "#         model = CustomModel(input_channels=len(EXTRA_COLOUMN),tim_num_class= TIM_NUM_CLASS, model=model_name)\n",
    "#     else:\n",
    "#         model = initialize_timm_model(model_name=model_name , TIM_NUM_CLASS = 6)    \n",
    "#     model.to(device = DEVICE)\n",
    "#     loss_function = R2Loss()\n",
    "#     loss_function.to(device=DEVICE)\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-08, weight_decay= 0.01)\n",
    "#     #scheduler  = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = 0.1 , patience=1 , verbose = True )\n",
    "#     scheduler  = torch.optim.lr_scheduler.CosineAnnealingLR( optimizer , T_max = 10 , eta_min= 1e-6  )\n",
    "#     # optimizer.to(device = DEVICE)\n",
    "#     return model,optimizer,loss_function , scheduler\n",
    "# class BestModelSaveCallback:\n",
    "#     def __init__(self, save_path):\n",
    "#         self.save_path = save_path\n",
    "#         self.best_accuracy = -1\n",
    "\n",
    "#     def __call__(self, accuracy,model):\n",
    "#         if accuracy > self.best_accuracy:\n",
    "#             self.best_accuracy = accuracy\n",
    "#             model.to(device = \"cpu\")\n",
    "#             torch.save(model.state_dict(), self.save_path)\n",
    "#             model.to(device=DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class R2Loss(nn.Module):\n",
    "    def __init__(self, num_classes=6):\n",
    "        super(R2Loss, self).__init__()\n",
    "        # Initialize learnable weights for each class, one weight per class\n",
    "        # self.class_weights = nn.Parameter(torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 1.0], dtype=torch.float32))\n",
    "        # Increase weight for X_26_mean\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        # Calculate residual sum of squares per class\n",
    "        SS_res = torch.sum((y_true - y_pred) ** 2, dim=0)  # (B, C) -> (C,)\n",
    "        # Calculate total sum of squares per class\n",
    "        SS_tot = torch.sum(\n",
    "            (y_true - torch.mean(y_true, dim=0)) ** 2, dim=0\n",
    "        )  # (B, C) -> (C,)\n",
    "        # Calculate R2 loss per class, avoiding division by zero\n",
    "        r2_loss =SS_res / (SS_tot + 1e-6)  # (C,)\n",
    "        # Weight the R2 loss by the learnable class weights\n",
    "        # weighted_r2_loss = self.class_weights * r2_loss\n",
    "        # Return the mean of the weighted R2 loss\n",
    "        return torch.mean(r2_loss)\n",
    "def initialize_timm_model( model_name   , num_class):\n",
    "    model_ft  = None\n",
    "    if model_name == \"resnet34\" :\n",
    "        \"\"\" Resnet34 \"\"\"\n",
    "        model = timm.create_model('resnet34' , num_classes=num_class )\n",
    "        return model\n",
    "    # if model_name == \"Swin_Transformer\":\n",
    "    #     model = timm.create_model('swin_large_patch4_window12_384.ms_in22k_ft_in1k' , num_classes = 6 , pretrained=True)\n",
    "    #     return model \n",
    "    if model_name ==\"convnextv2\":\n",
    "        model = timm.create_model('convnext_tiny.in12k_ft_in1k_384',num_classes=num_class)\n",
    "        return model \n",
    "    \n",
    "    if model_name == \"efficientnet_v2\":\n",
    "        model = timm.create_model(\"efficientnetv2_rw_m.agc_in1k\",pretrained = True)\n",
    "        model.global_pool = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(None),\n",
    "            nn.Dropout(p=0.2, inplace=False))\n",
    "            #nn.Linear(in_features=2152, out_features=2152/2, bias=True))\n",
    "        return model\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_channels,tim_num_class , model):\n",
    "        super().__init__()\n",
    "        # if model ==\"resnet34\":\n",
    "        self.backbone = initialize_timm_model(model_name=model ,num_class=tim_num_class)\n",
    "        self.extra_parameters_models = nn.Sequential(\n",
    "            nn.Linear(input_channels,input_channels*2),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(input_channels*2,64),\n",
    "            nn.SELU(),\n",
    "            nn.Dropout(p=0.1,inplace=False)\n",
    "            \n",
    "        )\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Linear(2152+64,6),\n",
    "        )\n",
    "        \n",
    "    def forward(self,image,x):\n",
    "        output_image = self.backbone(image) # bach * (hight*col)\n",
    "        z = self.extra_parameters_models(x) # batch * 16\n",
    "        inputs  = torch.cat((output_image,z), 1 )\n",
    "        output = self.output(inputs)\n",
    "        return output\n",
    "\n",
    "def get_model_optimizer_lossFunction(model_name,learning_rate,extra_params = False):\n",
    "    global DEVICE\n",
    "    if extra_params:\n",
    "        model = CustomModel(input_channels=len(EXTRA_COLOUMN),tim_num_class= TIM_NUM_CLASS, model=model_name)\n",
    "    else:\n",
    "        model = initialize_timm_model(model_name=model_name , TIM_NUM_CLASS = 6)    \n",
    "    model.to(device = DEVICE)\n",
    "    loss_function = R2Loss()\n",
    "    loss_function.to(device=DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-08, weight_decay= 0.01)\n",
    "    #scheduler  = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = 0.1 , patience=1 , verbose = True )\n",
    "    scheduler  = torch.optim.lr_scheduler.CosineAnnealingLR( optimizer , T_max = 10 , eta_min= 1e-6  )\n",
    "    # optimizer.to(device = DEVICE)\n",
    "    return model,optimizer,loss_function , scheduler\n",
    "class BestModelSaveCallback:\n",
    "    def __init__(self, save_path):\n",
    "        self.save_path = save_path\n",
    "        self.best_accuracy = -1\n",
    "\n",
    "    def __call__(self, accuracy,model):\n",
    "        if accuracy > self.best_accuracy:\n",
    "            self.best_accuracy = accuracy\n",
    "            model.to(device = \"cpu\")\n",
    "            torch.save(model.state_dict(), self.save_path)\n",
    "            model.to(device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(inputs,model,loss_function,optimizer,extra_params = False):\n",
    "    model.train()  \n",
    "    if extra_params :\n",
    "        x,y,z = inputs\n",
    "        x = x.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "        z = z.to(DEVICE)\n",
    "        prediction = model(x,z)        \n",
    "        \n",
    "    else:\n",
    "        x,y = inputs\n",
    "        x = x.to(DEVICE)\n",
    "        y = y.to(DEVICE)    \n",
    "        prediction = model(x)\n",
    "    \n",
    "    \n",
    "    loss = loss_function(prediction,y)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    return loss.detach().cpu().numpy()\n",
    "\n",
    "@torch.no_grad\n",
    "def do_prediction(inputs,model, is_val=False , extra_params = False):\n",
    "    global Train_std_tensor , Train_mean_tensor\n",
    "    model.eval()\n",
    "    if extra_params:\n",
    "        x,y,z = inputs\n",
    "        x = x.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "        z = z.to(DEVICE)\n",
    "        \n",
    "        prediction = model(x,z)\n",
    "    else:\n",
    "        x,y = inputs\n",
    "        x = x.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "        prediction = model(x)\n",
    "    if is_val :\n",
    "        prediction = normalize_function.denormalize_tensor(batch=prediction)\n",
    "    return prediction.detach().cpu().numpy()\n",
    "\n",
    "@torch.no_grad()\n",
    "def validation_loss_batch(inputs,model,loss_function,extra_params=False):\n",
    "    global Train_std_tensor , Train_mean_tensor\n",
    "    model.eval()\n",
    "    if extra_params:\n",
    "        x,y,z = inputs\n",
    "        x = x.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "        z = z.to(DEVICE)\n",
    "        prediction = model(x,z)\n",
    "    else:\n",
    "        x,y = inputs\n",
    "        x = x.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "        prediction = model(x)\n",
    "    prediction = normalize_function.denormalize_tensor(batch=prediction)\n",
    "    loss = loss_function(prediction, y)\n",
    "    return loss.detach().cpu().numpy()\n",
    "\n",
    "def utils_convert_to_2d_tensors(predictions,targets):\n",
    "    predictions  = np.array(predictions)\n",
    "    targets = np.array(targets)\n",
    "    predictions  = np.reshape(predictions , (-1, predictions.shape[-1]))\n",
    "    targets  = np.reshape(targets  , (-1 , targets.shape[-1]))\n",
    "    return torch.Tensor(predictions), torch.Tensor(targets)\n",
    "\n",
    "def train(trainLoader,valLoader,model,optimizer,loss_function,epochs,best_model_callback,extra_params=False):\n",
    "    #wandb.watch(model,loss_function,log = \"all\",log_freq=50)\n",
    "    \n",
    "    train_epoch_loss , train_epoch_accuracy =[] , []\n",
    "    val_epoch_loss , val_epoch_accuracy = [],[]\n",
    "    \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f\"epoch: {epoch} , lr is { scheduler.get_last_lr()}\" )\n",
    "        train_loss  = [] \n",
    "        val_loss ,val_accuracy = [] , []\n",
    "        \n",
    "        # batch training loss\n",
    "        with tqdm.tqdm(total=len(trainLoader)) as trainingLoop:\n",
    "            for index,batch in enumerate(iter(trainLoader)): \n",
    "        \n",
    "                loss = train_batch(batch,model,loss_function,optimizer,extra_params=extra_params)\n",
    "                train_loss.append(loss)\n",
    "\n",
    "                trainingLoop.set_description(f\"Batch: {index}/{len(trainLoader)}\")\n",
    "                trainingLoop.set_postfix({\"training Loss \" : loss})\n",
    "                trainingLoop.update(1)\n",
    "                ##wandb.log({\"Training Loss\":loss })\n",
    "        train_loss  = np.array(train_loss).mean() \n",
    "        train_epoch_loss.append(train_loss)\n",
    "        \n",
    "        # find training accuracy \n",
    "        predictions,targets = [],[]\n",
    "        for index,batch in enumerate(iter(trainLoader)): \n",
    "        \n",
    "            prediction = do_prediction(batch,model,extra_params=extra_params)\n",
    "            predictions.extend(prediction)\n",
    "            targets.extend(batch[1].detach().cpu().numpy())\n",
    "           \n",
    "        \n",
    "        predictions = np.array(predictions)\n",
    "        targets = np.array(targets)\n",
    "        predictions , targets = utils_convert_to_2d_tensors(predictions , targets)\n",
    "        # print(\"predictions=\", predictions[0:2])\n",
    "        # print(\"targets=\",targets[0:2])\n",
    "        metric = R2Score()\n",
    "        metric.update(predictions , targets)\n",
    "        train_epoch_accuracy.append(metric.compute().detach().cpu().numpy())\n",
    "                \n",
    "        \n",
    "        # validation set loss & accuracy  \n",
    "        predictions,targets = [],[]\n",
    "        with tqdm.tqdm(total = len(valLoader)) as validationLoop:\n",
    "            for index,batch in enumerate(iter(valLoader)):\n",
    "                \n",
    "                loss = validation_loss_batch(batch,model,loss_function,extra_params=extra_params)\n",
    "                val_loss.append(loss)\n",
    "                prediction = do_prediction(batch,model,is_val=True,extra_params=extra_params)\n",
    "                predictions.extend(prediction)\n",
    "                targets.extend(batch[1].detach().cpu().numpy())\n",
    "                \n",
    "                validationLoop.set_description(f\"Batch: {index}/{len(valLoader)}\")\n",
    "                validationLoop.set_postfix({\"Validation loss \" : loss}) \n",
    "                ##wandb.log({\"Vlaidation loss\" : loss})\n",
    "                #wandb.log({\"Validation Loss \": val_loss.item()})\n",
    "                validationLoop.update(1)\n",
    "        \n",
    "        \n",
    "        val_loss  = np.array(val_loss).mean() \n",
    "        val_epoch_loss.append(val_loss)\n",
    "        \n",
    "        predictions = np.array(predictions)\n",
    "        targets = np.array(targets)\n",
    "        # print(\"predictions-val=\", predictions[0:2])\n",
    "        # print(\"targets-val=\",targets[0:2])\n",
    "        metric = R2Score()\n",
    "        predictions , targets = utils_convert_to_2d_tensors(predictions , targets)\n",
    "        metric.update(predictions , targets)\n",
    "        val_epoch_accuracy.append(metric.compute().detach().cpu().numpy().item())\n",
    "        \n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        print(f\"epoch:{epoch}, Training (avg) loss : {train_loss} , Validation loss (avg) = {val_loss}\")\n",
    "        best_model_callback(metric.compute().detach().cpu().numpy().item(),model)        # save the best model according to the validation accuracy\n",
    "        \n",
    "        \n",
    "    return train_epoch_loss,val_epoch_loss,train_epoch_accuracy , val_epoch_accuracy\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = CustomModel(len(EXTRA_COLOUMN),6 , \"resnet34\")\n",
    "# image = torch.ones(10,3,128,128)\n",
    "\n",
    "# # x-shape= torch.Size([10, 3, 128, 128]) z-shape= torch.Size([10, 163]\n",
    "# x = torch.ones(10,len(EXTRA_COLOUMN))\n",
    "# model(image,x).shape\n",
    "# model = initialize_timm_model(model_name=\"efficientnet_v2\",num_class=6)\n",
    "model,optimizer,loss_function,scheduler = get_model_optimizer_lossFunction(model_name = \"efficientnet_v2\",learning_rate = LEARNING_RATE,extra_params=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model,optimizer,loss_function,scheduler = get_model_optimizer_lossFunction(model_name = \"efficientnet_v2\",learning_rate = LEARNING_RATE,extra_params=True)\n",
    "best_model_callback = BestModelSaveCallback(save_path=os.path.join(BASE_DIR,'best_model_transformation_efficientnet_v2.pth'))\n",
    "train_losses, val_losses , train_accuracies,val_accuracies = train(train_dataloader,val_dataloader,model,optimizer,loss_function,EPOCHS,best_model_callback,extra_params=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model.load_state_dict(torch.load(\"/home/prajwal/cs680/cs680_kaggle/data/best_model_transformation_convnextv2.pth\"))\n",
    "TEST_BATCH_SIZE  = 10\n",
    "torch.cuda.empty_cache()\n",
    "class data_loader_test(Dataset ):\n",
    "    def __init__(self,df ,extra_params = False ):\n",
    "        global EXTRA_COLOUMN\n",
    "        self.df = df.copy()\n",
    "        self.transform =torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                                 #torchvision.transforms.Resize((384,384)),\n",
    "                                  torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "                                  ])\n",
    "    \n",
    "        self.extra_params = extra_params\n",
    "        self.extra_coloumns = EXTRA_COLOUMN\n",
    "    def __len__(self):\n",
    "        return len(self.df)    \n",
    "    def __getitem__(self , index):\n",
    "        row = self.df.iloc[index]\n",
    "        image = plt.imread(row[\"image_path\"])\n",
    "        image = np.copy(image)\n",
    "        if self.transform :\n",
    "            image = self.transform(image)\n",
    "        if self.extra_params:\n",
    "            extras = row[self.extra_coloumns].values.astype(np.float64)\n",
    "            return image  , torch.Tensor(extras)\n",
    "        return  image \n",
    "test_dataset = data_loader_test(test_df,extra_params = True)\n",
    "test_dataloader = DataLoader(test_dataset,batch_size =TEST_BATCH_SIZE,shuffle=False)\n",
    "\n",
    "def predict_test(test_dataloader , model):\n",
    "    predictions = []\n",
    "    for i in test_dataloader:\n",
    "        #print(i[0].shape , i[1].shape)\n",
    "        model.eval()\n",
    "        prediction = model(i[0].to(DEVICE),i[1].to(DEVICE))\n",
    "        prediction  = normalize_function.denormalize_tensor(prediction)\n",
    "        predictions.extend(prediction.detach().cpu().numpy())\n",
    "    predictions = np.array(predictions)\n",
    "    output = np.reshape(predictions,(-1,predictions.shape[-1]))\n",
    "    return pd.DataFrame(output , columns=['X4', 'X11', 'X18', 'X26', 'X50', 'X3112' ])\n",
    "output = predict_test(test_dataloader , model)\n",
    "output = pd.concat([test_df[\"id\"],output],axis=1 )\n",
    "#output.to_csv()\n",
    "output.to_csv(\"stratfied_ancillary.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# predictions= torch.tensor([[ 1.2391, 30.3367, 30.3599, 29.7099, 20.0526, 31.2610],\n",
    "#         [ 1.2679, 30.3845, 30.3134, 29.7083, 20.3929, 31.2463]])\n",
    "# targets= torch.tensor([[1.1125e+00, 1.4686e+02, 1.9699e+04, 3.4597e+03, 1.5282e+01, 3.9792e+05],\n",
    "#         [9.7378e-01, 1.5390e+02, 1.9702e+04, 3.4673e+03, 1.4737e+01, 3.9847e+05]])\n",
    "# metric = R2Score()\n",
    "# metric.update(predictions , targets)\n",
    "# metric.compute()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# from sklearn.metrics import r2_score\n",
    "# predictions= np.array([[ 1.2391, 30.3367, 30.3599, 29.7099, 20.0526, 31.2610],\n",
    "#         [ 1.2679, 30.3845, 30.3134, 29.7083, 20.3929, 31.2463]])\n",
    "# targets= np.array([[1.1125e+00, 1.4686e+02, 1.9699e+04, 3.4597e+03, 1.5282e+01, 3.9792e+05],\n",
    "#         [9.7378e-01, 1.5390e+02, 1.9702e+04, 3.4673e+03, 1.4737e+01, 3.9847e+05]])\n",
    "# r2_score(y_true = targets , y_pred =predictions)\n",
    "\n",
    "\n",
    "\n",
    "# targets = torch.tensor([[0.0, 2.0], [1.0, 6.0]])\n",
    "# predictions = torch.tensor([[0.0, 1.0], [2.0, 5.0]])\n",
    "# torch.mean(1- (torch.sum((targets - predictions)**2,axis=0)/torch.sum((targets - targets.mean())**2,axis=0)))\n",
    "\n",
    "\n",
    "# metric = R2Score()\n",
    "# # input = torch.tensor([[0, 2], [1, 6]])\n",
    "# # target = torch.tensor([[0, 1], [2, 5]])\n",
    "# input = torch.tensor([[ 1.2391, 30.3367, 30.3599, 29.7099, 20.0526, 31.2610],\n",
    "#         [ 1.2679, 30.3845, 30.3134, 29.7083, 20.3929, 31.2463]])\n",
    "# target= torch.tensor([[1.1125e+00, 1.4686e+02, 1.9699e+04, 3.4597e+03, 1.5282e+01, 3.9792e+05],\n",
    "#         [9.7378e-01, 1.5390e+02, 1.9702e+04, 3.4673e+03, 1.4737e+01, 3.9847e+05]])\n",
    "# metric.update(input, target)\n",
    "# metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plot(train_losses,train_accuracies,val_losses,val_accuracies,path):\n",
    "    plt.plot(train_losses,label = \"train loss\")\n",
    "    plt.plot(val_losses,label = \"validation loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    #plt.savefig(os.path.join(path,\"Loss.png\"))\n",
    "    #wandb.log({\"Loss\": plt})\n",
    "\n",
    "    plt.plot(val_accuracies,label = \"validation accuracy\")\n",
    "    plt.plot(train_accuracies,label = \"train accuracy\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend() \n",
    "    #plt.savefig(os.path.join(path,\"Accuracy.png\"))\n",
    "    #wandb.log({\"Accuracy\": plt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plot(train_losses,train_accuracies,val_losses,val_accuracies,path = BASE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(val_accuracies,label = \"validation accuracy\")\n",
    "plt.plot(train_accuracies,label = \"train accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
