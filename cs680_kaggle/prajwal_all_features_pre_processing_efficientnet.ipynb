{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 \n",
    "import IPython\n",
    "from glob import glob\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tqdm\n",
    "#import seaborn as sns\n",
    "import albumentations as A\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "from torcheval.metrics import R2Score\n",
    "import wandb\n",
    "import torchvision\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr =R2Score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x719d41d2a330>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "BASE_DIR = os.path.join(os.getcwd() , 'data')\n",
    "train_df = pd.read_csv(BASE_DIR  +  '/train.csv')\n",
    "TRAIN_VAL_SPLIT_SIZE = 0.2\n",
    "TRAIN_BATCH_SIZE = 128\n",
    "VAL_BATCH_SIZE = 128\n",
    "\n",
    "LEARNING_RATE =  1e-4\n",
    "EPOCHS = 18\n",
    "TIM_NUM_CLASS = 1408\n",
    "Normalize_transform_type = \"min_max\" #\"log_transform\"\n",
    "RANDOM_NUMBER = 42\n",
    "NUM_FLODS  = 5\n",
    "NUM_CLASSES = 6\n",
    "TRAITS_NAME = ['X4_mean', 'X11_mean', 'X18_mean', 'X26_mean', 'X50_mean', 'X3112_mean' ]\n",
    "FOLD = 0 # Which fold to set as validation data\n",
    "TARGET_IMAGE_SIZE  = 128\n",
    "T_MAX =        9\n",
    "LR_MODE = \"step\" # LR scheduler mode from one of \"cos\", \"step\", \"exp\"\n",
    "torch.manual_seed(RANDOM_NUMBER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wandb.login()\n",
    "\n",
    "# wandb.init(project=\"cs680v2_normalized\",\n",
    "#     config={\n",
    "#        \"learning_rate\": LEARNING_RATE,\n",
    "#         \"epochs\": EPOCHS,\n",
    "#         \"batch_size\" : TRAIN_BATCH_SIZE,\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "DATA_DIRECTORY = os.path.join(os.getcwd(),\"data\")\n",
    "torch.cuda.empty_cache()\n",
    "# torch.cuda.set_per_process_memory_fraction(0.99, device=0)\n",
    "# os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"caching_allocator\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXTRA_COLOUMN = ['WORLDCLIM_BIO1_annual_mean_temperature',\n",
    "       'WORLDCLIM_BIO12_annual_precipitation',\n",
    "       'WORLDCLIM_BIO13.BIO14_delta_precipitation_of_wettest_and_dryest_month',\n",
    "       'WORLDCLIM_BIO15_precipitation_seasonality',\n",
    "       'WORLDCLIM_BIO4_temperature_seasonality',\n",
    "       'WORLDCLIM_BIO7_temperature_annual_range',\n",
    "       'SOIL_bdod_0.5cm_mean_0.01_deg',\n",
    "       'SOIL_bdod_100.200cm_mean_0.01_deg',\n",
    "       'SOIL_bdod_15.30cm_mean_0.01_deg',\n",
    "       'SOIL_bdod_30.60cm_mean_0.01_deg',\n",
    "       'SOIL_bdod_5.15cm_mean_0.01_deg',\n",
    "       'SOIL_bdod_60.100cm_mean_0.01_deg', 'SOIL_cec_0.5cm_mean_0.01_deg',\n",
    "       'SOIL_cec_100.200cm_mean_0.01_deg',\n",
    "       'SOIL_cec_15.30cm_mean_0.01_deg', 'SOIL_cec_30.60cm_mean_0.01_deg',\n",
    "       'SOIL_cec_5.15cm_mean_0.01_deg', 'SOIL_cec_60.100cm_mean_0.01_deg',\n",
    "       'SOIL_cfvo_0.5cm_mean_0.01_deg',\n",
    "       'SOIL_cfvo_100.200cm_mean_0.01_deg',\n",
    "       'SOIL_cfvo_15.30cm_mean_0.01_deg',\n",
    "       'SOIL_cfvo_30.60cm_mean_0.01_deg',\n",
    "       'SOIL_cfvo_5.15cm_mean_0.01_deg',\n",
    "       'SOIL_cfvo_60.100cm_mean_0.01_deg',\n",
    "       'SOIL_clay_0.5cm_mean_0.01_deg',\n",
    "       'SOIL_clay_100.200cm_mean_0.01_deg',\n",
    "       'SOIL_clay_15.30cm_mean_0.01_deg',\n",
    "       'SOIL_clay_30.60cm_mean_0.01_deg',\n",
    "       'SOIL_clay_5.15cm_mean_0.01_deg',\n",
    "       'SOIL_clay_60.100cm_mean_0.01_deg',\n",
    "       'SOIL_nitrogen_0.5cm_mean_0.01_deg',\n",
    "       'SOIL_nitrogen_100.200cm_mean_0.01_deg',\n",
    "       'SOIL_nitrogen_15.30cm_mean_0.01_deg',\n",
    "       'SOIL_nitrogen_30.60cm_mean_0.01_deg',\n",
    "       'SOIL_nitrogen_5.15cm_mean_0.01_deg',\n",
    "       'SOIL_nitrogen_60.100cm_mean_0.01_deg',\n",
    "       'SOIL_ocd_0.5cm_mean_0.01_deg', 'SOIL_ocd_100.200cm_mean_0.01_deg',\n",
    "       'SOIL_ocd_15.30cm_mean_0.01_deg', 'SOIL_ocd_30.60cm_mean_0.01_deg',\n",
    "       'SOIL_ocd_5.15cm_mean_0.01_deg', 'SOIL_ocd_60.100cm_mean_0.01_deg',\n",
    "       'SOIL_ocs_0.30cm_mean_0.01_deg', 'SOIL_phh2o_0.5cm_mean_0.01_deg',\n",
    "       'SOIL_phh2o_100.200cm_mean_0.01_deg',\n",
    "       'SOIL_phh2o_15.30cm_mean_0.01_deg',\n",
    "       'SOIL_phh2o_30.60cm_mean_0.01_deg',\n",
    "       'SOIL_phh2o_5.15cm_mean_0.01_deg',\n",
    "       'SOIL_phh2o_60.100cm_mean_0.01_deg',\n",
    "       'SOIL_sand_0.5cm_mean_0.01_deg',\n",
    "       'SOIL_sand_100.200cm_mean_0.01_deg',\n",
    "       'SOIL_sand_15.30cm_mean_0.01_deg',\n",
    "       'SOIL_sand_30.60cm_mean_0.01_deg',\n",
    "       'SOIL_sand_5.15cm_mean_0.01_deg',\n",
    "       'SOIL_sand_60.100cm_mean_0.01_deg',\n",
    "       'SOIL_silt_0.5cm_mean_0.01_deg',\n",
    "       'SOIL_silt_100.200cm_mean_0.01_deg',\n",
    "       'SOIL_silt_15.30cm_mean_0.01_deg',\n",
    "       'SOIL_silt_30.60cm_mean_0.01_deg',\n",
    "       'SOIL_silt_5.15cm_mean_0.01_deg',\n",
    "       'SOIL_silt_60.100cm_mean_0.01_deg', 'SOIL_soc_0.5cm_mean_0.01_deg',\n",
    "       'SOIL_soc_100.200cm_mean_0.01_deg',\n",
    "       'SOIL_soc_15.30cm_mean_0.01_deg', 'SOIL_soc_30.60cm_mean_0.01_deg',\n",
    "       'SOIL_soc_5.15cm_mean_0.01_deg', 'SOIL_soc_60.100cm_mean_0.01_deg',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_01_._month_m1',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_02_._month_m1',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_03_._month_m1',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_04_._month_m1',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_05_._month_m1',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_01_._month_m10',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_02_._month_m10',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_03_._month_m10',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_04_._month_m10',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_05_._month_m10',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_01_._month_m11',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_02_._month_m11',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_03_._month_m11',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_04_._month_m11',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_05_._month_m11',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_01_._month_m12',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_02_._month_m12',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_03_._month_m12',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_04_._month_m12',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_05_._month_m12',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_01_._month_m2',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_02_._month_m2',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_03_._month_m2',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_04_._month_m2',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_05_._month_m2',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_01_._month_m3',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_02_._month_m3',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_03_._month_m3',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_04_._month_m3',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_05_._month_m3',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_01_._month_m4',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_02_._month_m4',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_03_._month_m4',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_04_._month_m4',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_05_._month_m4',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_01_._month_m5',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_02_._month_m5',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_03_._month_m5',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_04_._month_m5',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_05_._month_m5',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_01_._month_m6',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_02_._month_m6',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_03_._month_m6',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_04_._month_m6',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_05_._month_m6',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_01_._month_m7',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_02_._month_m7',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_03_._month_m7',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_04_._month_m7',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_05_._month_m7',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_01_._month_m8',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_02_._month_m8',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_03_._month_m8',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_04_._month_m8',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_05_._month_m8',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_01_._month_m9',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_02_._month_m9',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_03_._month_m9',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_04_._month_m9',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_05_._month_m9',\n",
    "       'VOD_C_2002_2018_multiyear_mean_m01',\n",
    "       'VOD_C_2002_2018_multiyear_mean_m02',\n",
    "       'VOD_C_2002_2018_multiyear_mean_m03',\n",
    "       'VOD_C_2002_2018_multiyear_mean_m04',\n",
    "       'VOD_C_2002_2018_multiyear_mean_m05',\n",
    "       'VOD_C_2002_2018_multiyear_mean_m06',\n",
    "       'VOD_C_2002_2018_multiyear_mean_m07',\n",
    "       'VOD_C_2002_2018_multiyear_mean_m08',\n",
    "       'VOD_C_2002_2018_multiyear_mean_m09',\n",
    "       'VOD_C_2002_2018_multiyear_mean_m10',\n",
    "       'VOD_C_2002_2018_multiyear_mean_m11',\n",
    "       'VOD_C_2002_2018_multiyear_mean_m12',\n",
    "       'VOD_Ku_1987_2017_multiyear_mean_m01',\n",
    "       'VOD_Ku_1987_2017_multiyear_mean_m02',\n",
    "       'VOD_Ku_1987_2017_multiyear_mean_m03',\n",
    "       'VOD_Ku_1987_2017_multiyear_mean_m04',\n",
    "       'VOD_Ku_1987_2017_multiyear_mean_m05',\n",
    "       'VOD_Ku_1987_2017_multiyear_mean_m06',\n",
    "       'VOD_Ku_1987_2017_multiyear_mean_m07',\n",
    "       'VOD_Ku_1987_2017_multiyear_mean_m08',\n",
    "       'VOD_Ku_1987_2017_multiyear_mean_m09',\n",
    "       'VOD_Ku_1987_2017_multiyear_mean_m10',\n",
    "       'VOD_Ku_1987_2017_multiyear_mean_m11',\n",
    "       'VOD_Ku_1987_2017_multiyear_mean_m12',\n",
    "       'VOD_X_1997_2018_multiyear_mean_m01',\n",
    "       'VOD_X_1997_2018_multiyear_mean_m02',\n",
    "       'VOD_X_1997_2018_multiyear_mean_m03',\n",
    "       'VOD_X_1997_2018_multiyear_mean_m04',\n",
    "       'VOD_X_1997_2018_multiyear_mean_m05',\n",
    "       'VOD_X_1997_2018_multiyear_mean_m06',\n",
    "       'VOD_X_1997_2018_multiyear_mean_m07',\n",
    "       'VOD_X_1997_2018_multiyear_mean_m08',\n",
    "       'VOD_X_1997_2018_multiyear_mean_m09',\n",
    "       'VOD_X_1997_2018_multiyear_mean_m10',\n",
    "       'VOD_X_1997_2018_multiyear_mean_m11',\n",
    "       'VOD_X_1997_2018_multiyear_mean_m12']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32498/45617669.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"bin_{i}\"] = np.digitize(df[trait], bin_edges)\n",
      "/tmp/ipykernel_32498/45617669.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"bin_{i}\"] = np.digitize(df[trait], bin_edges)\n",
      "/tmp/ipykernel_32498/45617669.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"bin_{i}\"] = np.digitize(df[trait], bin_edges)\n",
      "/tmp/ipykernel_32498/45617669.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"bin_{i}\"] = np.digitize(df[trait], bin_edges)\n",
      "/tmp/ipykernel_32498/45617669.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"bin_{i}\"] = np.digitize(df[trait], bin_edges)\n",
      "/tmp/ipykernel_32498/45617669.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f\"bin_{i}\"] = np.digitize(df[trait], bin_edges)\n",
      "/tmp/ipykernel_32498/45617669.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"final_bin\"] = (\n",
      "/home/prajwal/anaconda3/envs/pytorch_gpu/lib/python3.12/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before # Num Train: 34690 | Num Valid: 8673\n",
      "# Num Train: 31670 | Num Valid: 8673\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "SCALAR = StandardScaler()\n",
    "\n",
    "def create_val_train_dataset(BASE_DIR,train_split_size,scalar:StandardScaler):\n",
    "    df = pd.read_csv(BASE_DIR  +  '/train.csv')\n",
    "    df[\"image_path\"] = BASE_DIR + \"/train_images/\" + df[\"id\"].astype(str) + \".jpeg\"   # add images in the training dataframe\n",
    "\n",
    "    # standardize the dataset\n",
    "    scalar.fit(df[EXTRA_COLOUMN])\n",
    "    df[EXTRA_COLOUMN] = scalar.transform(df[EXTRA_COLOUMN])\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=NUM_FLODS, shuffle=True, random_state=42)\n",
    "\n",
    "    # Create separate bin for each traits\n",
    "    for i, trait in enumerate(TRAITS_NAME):\n",
    "\n",
    "        # Determine the bin edges dynamically based on the distribution of traits\n",
    "        bin_edges = np.percentile(df[trait], np.linspace(0, 100, NUM_FLODS + 1))\n",
    "        df[f\"bin_{i}\"] = np.digitize(df[trait], bin_edges)\n",
    "\n",
    "    # Concatenate the bins into a final bin\n",
    "    df[\"final_bin\"] = (\n",
    "        df[[f\"bin_{i}\" for i in range(NUM_CLASSES)]]\n",
    "        .astype(str)\n",
    "        .agg(\"\".join, axis=1)\n",
    "    )\n",
    "\n",
    "    # Perform the stratified split using final bin\n",
    "    df = df.reset_index(drop=True)\n",
    "    for fold, (train_idx, valid_idx) in enumerate(skf.split(df, df[\"final_bin\"])):\n",
    "        df.loc[valid_idx, \"fold\"] = fold\n",
    "    sample_df = df.copy()\n",
    "    train_df = sample_df[sample_df.fold != FOLD]\n",
    "    val_df = sample_df[sample_df.fold == FOLD]\n",
    " \n",
    "    \n",
    "    #train_df , val_df = train_test_split(df,test_size=train_split_size,shuffle=True)\n",
    "    \n",
    "\n",
    "    print(f\"before # Num Train: {len(train_df)} | Num Valid: {len(val_df)}\")\n",
    "    \n",
    "    # log_mean_traits = np.log10(train_df[TRAITS_NAME]).mean()\n",
    "    # log_std_traits = np.log10(train_df[TRAITS_NAME]).std()\n",
    "    # qt_low = log_mean_traits - 3*log_std_traits\n",
    "    # qt_high = log_mean_traits + 3*log_std_traits\n",
    "    # for column in TRAITS_NAME:\n",
    "    #     lower_quantile = train_df[column].quantile(qt_low[column])\n",
    "    #     upper_quantile = train_df[column].quantile(qt_high[column])  \n",
    "    #     train_df = train_df[(train_df[column] >= lower_quantile) & (train_df[column] <= upper_quantile)]\n",
    "    train_df = train_df[(np.abs(stats.zscore(np.log10(train_df[TRAITS_NAME]))<3).all(axis=1)  )]\n",
    "    train_df.reset_index(drop=True , inplace  = True)\n",
    "    val_df.reset_index(drop = True , inplace = True)\n",
    "    print(f\"# Num Train: {len(train_df)} | Num Valid: {len(val_df)}\")\n",
    "    return  train_df , val_df\n",
    "def create_test_dataset(BASE_DIR,scalar):\n",
    "    df = pd.read_csv(BASE_DIR  +  '/test.csv')\n",
    "    df[\"image_path\"] = BASE_DIR + \"/test_images/\" + df[\"id\"].astype(str) + \".jpeg\"   # add images in the training dataframe\n",
    "    df[EXTRA_COLOUMN] = scalar.transform(df[EXTRA_COLOUMN])\n",
    "    return df\n",
    "\n",
    "train_df , val_df = create_val_train_dataset(BASE_DIR,TRAIN_VAL_SPLIT_SIZE,scalar = SCALAR)\n",
    "test_df = create_test_dataset(BASE_DIR,scalar=SCALAR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df[(np.abs(stats.zscore(np.log10(train_df[TRAITS_NAME]))<3).all(axis=1)  )].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalizeOutput():\n",
    "    def __init__(self,type_transform ):\n",
    "        self.transform = type_transform\n",
    "        self.mean = 0\n",
    "        self.std = 0\n",
    "        self.mean_tensor = 0\n",
    "        self.std_tensor = 0\n",
    "        \n",
    "        pass\n",
    "    def normalize(self,df):\n",
    "        if self.transform == \"log_transform\":\n",
    "            mean = np.log10(df).mean()\n",
    "            std = np.log10(df).std()\n",
    "            min =  np.log10(df).min()\n",
    "            max = np.log10(df).max()\n",
    "            \n",
    "            self.min  = min\n",
    "            self.max = max\n",
    "            \n",
    "            self.mean = mean\n",
    "            self.std = std\n",
    "            \n",
    "            self.min_tensor = torch.Tensor(self.min.values).to(DEVICE)\n",
    "            self.max_tensor = torch.Tensor(self.max.values).to(DEVICE)\n",
    "            \n",
    "            self.mean_tensor = torch.Tensor(self.mean.values).to(DEVICE)\n",
    "            self.std_tensor = torch.Tensor(self.std.values).to(DEVICE)\n",
    "            \n",
    "            tf = (np.log10(df) - self.min)/(self.max - self.min)\n",
    "        elif self.transform == \"log_transform_mean_std\": \n",
    "            tf = (np.log10(df) - self.mean)/(self.std) \n",
    "        elif self.transform == None :\n",
    "            tf = df\n",
    "        elif self.transform == \"min_max\":\n",
    "            print(\"in min max transform\")\n",
    "            max = df.max()\n",
    "            min = df.min()\n",
    "            self.min  = min\n",
    "            self.max = max\n",
    "            \n",
    "            self.min_tensor = torch.Tensor(self.min.values).to(DEVICE)\n",
    "            self.max_tensor = torch.Tensor(self.max.values).to(DEVICE)\n",
    "            \n",
    "            self.mean_tensor = torch.Tensor(self.mean.values).to(DEVICE)\n",
    "            self.std_tensor = torch.Tensor(self.std.values).to(DEVICE)\n",
    "            \n",
    "            tf =( df - self.min)/(self.max - self.min)\n",
    "        return tf \n",
    "    def denormalize(self,df):\n",
    "        if self.mean is None or self.std is None :\n",
    "            raise Exception(\"mean and/std is not defined \")\n",
    "        if self.transform == \"log_transform\":\n",
    "            df_denormalize =10**((df*(self.max - self.min)) + self.min )\n",
    "            return df_denormalize\n",
    "        if self.transform ==\"log_transform_mean_std\":\n",
    "            df_denormalize =10**((df*self.std) + self.mean )\n",
    "        elif self.transform == None :\n",
    "            df_denormalize = df\n",
    "            \n",
    "        elif self.transform == \"min_max\":\n",
    "            df_denormalize = df*(self.max - self.min) + self.min\n",
    "            return df_denormalize\n",
    "        \n",
    "    def denormalize_tensor(self,batch) :\n",
    "        if self.mean_tensor is None or self.std_tensor is None :\n",
    "            raise Exception(\"mean and/std is not defined \")\n",
    "        if self.transform == \"log_transform\":\n",
    "            df_denormalize =10**((batch*(self.max_tensor - self.min_tensor)) + self.min_tensor )\n",
    "        elif self.transform == \"log_transform_mean_std\":\n",
    "            df_denormalize =10**((batch*self.std_tensor) + self.mean_tensor )\n",
    "        elif self.transform == None :\n",
    "            df_denormalize = batch\n",
    "        elif self.transform == \"min_max\":\n",
    "            df_denormalize = batch*(self.max_tensor - self.min_tensor) + self.min_tensor\n",
    "        return df_denormalize\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df[['X4_mean', 'X11_mean', 'X18_mean', 'X26_mean', 'X50_mean', 'X3112_mean' ]].min().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations.pytorch import ToTensorV2\n",
    "IMAGE_SIZE =128\n",
    "class data_loader(Dataset ):\n",
    "    def __init__(self,df , is_val = False,normalizedOutput=None, extra_params = False ):\n",
    "        global EXTRA_COLOUMN\n",
    "        self.df = df.copy()\n",
    "        self.is_val = is_val\n",
    "        if normalizedOutput == None:\n",
    "            pass\n",
    "        else:\n",
    "            if not is_val :\n",
    "                self.df[['X4_mean', 'X11_mean', 'X18_mean', 'X26_mean', 'X50_mean', 'X3112_mean' ]] = normalizedOutput.normalize(self.df[['X4_mean', 'X11_mean', 'X18_mean', 'X26_mean', 'X50_mean', 'X3112_mean' ]])\n",
    "\n",
    "        self.train_transform = A.Compose([  \n",
    "                    A.RandomResizedCrop( height = 100 , width = 100 , p=0.4 , interpolation = cv2.INTER_CUBIC),\n",
    "                    A.Resize(TARGET_IMAGE_SIZE, TARGET_IMAGE_SIZE,interpolation= cv2.INTER_CUBIC),\n",
    "                    A.ISONoise(color_shift=(0.03, 0.07), intensity=(0.3, 0.5), always_apply=None, p=0.3) ,\n",
    "                    A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.3 , p = 0.4),\n",
    "                    A.HorizontalFlip(p=0.6),\n",
    "                    #A.Blur(blur_limit=4, p=0.5),\n",
    "                    # A.VerticalFlip(p=0.1),\n",
    "                    A.ImageCompression(quality_lower=25, quality_upper=100, p=0.5),\n",
    "                    A.ToFloat(),\n",
    "                    A.Normalize([0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225], max_pixel_value=1),\n",
    "                    ToTensorV2(),\n",
    "                    ])\n",
    "        self.val_transform = A.Compose([\n",
    "             A.Resize(TARGET_IMAGE_SIZE, TARGET_IMAGE_SIZE,interpolation= cv2.INTER_CUBIC),\n",
    "                A.ToFloat(),\n",
    "                    A.Normalize([0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225], max_pixel_value=1),\n",
    "                    ToTensorV2(),\n",
    "        ])\n",
    "        self.extra_params = extra_params\n",
    "        self.extra_coloumns = EXTRA_COLOUMN\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self , index):\n",
    "        row = self.df.iloc[index]\n",
    "        image = plt.imread(row[\"image_path\"])\n",
    "        #image = np.copy(image)\n",
    "        traits = row[['X4_mean', 'X11_mean', 'X18_mean', 'X26_mean', 'X50_mean', 'X3112_mean' ]].values.astype(np.float32)\n",
    "        traits = torch.tensor(traits,dtype=torch.float32)\n",
    "        if not self.is_val:\n",
    "            image = self.train_transform(image = image)[\"image\"]\n",
    "            #image = torch.permute(image  )\n",
    "        else:\n",
    "            image = self.val_transform(image = image)[\"image\"]\n",
    "            \n",
    "        if self.extra_params:\n",
    "            extras = row[self.extra_coloumns].values.astype(np.float32)\n",
    "            return image , traits  , torch.tensor(extras,dtype=torch.float32)\n",
    "        return  image , traits\n",
    "normalize_function = NormalizeOutput(Normalize_transform_type)\n",
    "train_dataset = data_loader(train_df, is_val = False,normalizedOutput=None ,extra_params=True)\n",
    "val_dataset  = data_loader(val_df,   is_val = True,normalizedOutput = None , extra_params=True)    \n",
    "\n",
    "train_dataloader = DataLoader(train_dataset , batch_size = TRAIN_BATCH_SIZE , shuffle=True )\n",
    "val_dataloader = DataLoader(val_dataset , batch_size =  VAL_BATCH_SIZE , shuffle=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(iter(train_dataset))[1].min()\n",
    "normalize_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class R2Loss(nn.Module):\n",
    "    def __init__(self, num_classes=6):\n",
    "        super(R2Loss, self).__init__()\n",
    "        # Initialize learnable weights for each class, one weight per class\n",
    "        # self.class_weights = nn.Parameter(torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 1.0], dtype=torch.float32))\n",
    "        # Increase weight for X_26_mean\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        # Calculate residual sum of squares per class\n",
    "        SS_res = torch.sum((y_true - y_pred) ** 2, dim=0)  # (B, C) -> (C,)\n",
    "        # Calculate total sum of squares per class\n",
    "        SS_tot = torch.sum(\n",
    "            (y_true - torch.mean(y_true, dim=0)) ** 2, dim=0\n",
    "        )  # (B, C) -> (C,)\n",
    "        # Calculate R2 loss per class, avoiding division by zero\n",
    "        r2_loss =SS_res / (SS_tot + 1e-6)  # (C,)\n",
    "        return torch.mean(r2_loss)\n",
    "\n",
    "\n",
    "\n",
    "def initialize_timm_model( model_name   , num_class):\n",
    "    model_ft  = None\n",
    "    if model_name == \"resnet34\" :\n",
    "        \"\"\" Resnet34 \"\"\"\n",
    "        model = timm.create_model('resnet34' , num_classes=num_class )\n",
    "        return model\n",
    "    if model_name == \"Swin_Transformer\":\n",
    "        model = timm.create_model('swin_tiny_patch4_window7_224.ms_in22k' , pretrained=True , num_classes = num_class)\n",
    "        return model \n",
    "    if model_name ==\"convnextv2\":\n",
    "        model = timm.create_model('convnext_tiny.in12k_ft_in1k_384',num_classes=num_class)\n",
    "        return model \n",
    "    \n",
    "    if model_name == \"efficientnet_v2\":\n",
    "        model = timm.create_model(\"efficientnet_b2.ra_in1k\",pretrained = True)\n",
    "        model.classifier = nn.Dropout(p=0.2,inplace=False)\n",
    "        return model\n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_channels,tim_num_class , model):\n",
    "        super().__init__()\n",
    "        # if model ==\"resnet34\":\n",
    "        self.backbone = initialize_timm_model(model_name=model ,num_class=tim_num_class)\n",
    "        self.extra_parameters_models = nn.Sequential(\n",
    "            nn.Linear(input_channels,input_channels*2),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(input_channels*2,256),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(256,128),\n",
    "            nn.SELU(),\n",
    "            nn.Dropout(p=0.1,inplace=False), #\n",
    "            # nn.Linear(128,64),\n",
    "            # nn.SELU(),\n",
    "            # nn.Dropout(p=0.3,inplace=False)\n",
    "            \n",
    "        )\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Linear(tim_num_class+128,736),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(736,368)     ,  \n",
    "            nn.SELU(),\n",
    "            nn.Linear(368,184)   , \n",
    "            nn.Dropout(p=0.1,inplace=False),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(184,6),\n",
    "            # nn.Dropout(p=0.4,inplace=False), #\n",
    "            # nn.SELU(),\n",
    "            # nn.Linear(92,6)\n",
    "        )\n",
    "        \n",
    "    def forward(self,image,x):\n",
    "        output_image = self.backbone(image) # bach * (hight*col)\n",
    "        z = self.extra_parameters_models(x) # batch * 16\n",
    "        inputs  = torch.cat((output_image,z), 1 )\n",
    "        output = self.output(inputs)\n",
    "        return output\n",
    "\n",
    "def get_model_optimizer_lossFunction(model_name,learning_rate,extra_params = False):\n",
    "    global DEVICE\n",
    "    if extra_params:\n",
    "        model = CustomModel(input_channels=len(EXTRA_COLOUMN),tim_num_class= TIM_NUM_CLASS, model=model_name)\n",
    "    else:\n",
    "        model = initialize_timm_model(model_name=model_name , TIM_NUM_CLASS = 6)    \n",
    "    model.to(device = DEVICE)\n",
    "    loss_function = R2Loss()\n",
    "    loss_function.to(device=DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-08, weight_decay= 0.001)\n",
    "    # scheduler  = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = 0.1 , patience=1 , verbose = True )\n",
    "    scheduler  = torch.optim.lr_scheduler.CosineAnnealingLR( optimizer , T_max = T_MAX , eta_min= 1e-5 )\n",
    "\n",
    "    return model,optimizer,loss_function , scheduler\n",
    "class BestModelSaveCallback:\n",
    "    def __init__(self, save_path):\n",
    "        self.save_path = save_path\n",
    "        self.best_accuracy = -1\n",
    "\n",
    "    def __call__(self, accuracy,model):\n",
    "        if accuracy > self.best_accuracy:\n",
    "            self.best_accuracy = accuracy\n",
    "            model.to(device = \"cpu\")\n",
    "            torch.save(model.state_dict(), self.save_path)\n",
    "            model.to(device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model  = CustomModel(input_channels=163,tim_num_class=1408 , model=\"efficientnet_v2\")\n",
    "# image = torch.ones(10,3,224,224)\n",
    "# x = torch.ones(10,len(EXTRA_COLOUMN))\n",
    "# model(image,x).shape\n",
    "\n",
    "# model = initialize_timm_model(\"efficientnet_v2\" , 128)\n",
    "# image = torch.ones(10,3,224,224)\n",
    "# model(image).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(inputs,model,loss_function,optimizer,extra_params = False):\n",
    "    model.train()  \n",
    "    if extra_params :\n",
    "        x,y,z = inputs\n",
    "        x = x.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "        z = z.to(DEVICE)\n",
    "        prediction = model(x,z)        \n",
    "        \n",
    "    else:\n",
    "        x,y = inputs\n",
    "        x = x.to(DEVICE)\n",
    "        y = y.to(DEVICE)    \n",
    "        prediction = model(x)\n",
    "    \n",
    "    \n",
    "    #loss_func = nn.MSELoss()\n",
    "    #loss_val = loss_func(prediction,y)\n",
    "    loss_1 = loss_function(prediction,y) \n",
    "    loss = loss_1  #+ 0.5 * loss_val\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    return loss_1.detach().cpu().numpy()\n",
    "\n",
    "@torch.no_grad\n",
    "def do_prediction(inputs,model, is_val=False , extra_params = False):\n",
    "    global Train_std_tensor , Train_mean_tensor\n",
    "    model.eval()\n",
    "    if extra_params:\n",
    "        x,y,z = inputs\n",
    "        x = x.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "        z = z.to(DEVICE)\n",
    "        \n",
    "        prediction = model(x,z)\n",
    "    else:\n",
    "        x,y = inputs\n",
    "        x = x.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "        prediction = model(x)\n",
    "    if is_val :\n",
    "        prediction = normalize_function.denormalize_tensor(batch=prediction)\n",
    "    return prediction.detach().cpu().numpy()\n",
    "\n",
    "@torch.no_grad()\n",
    "def validation_loss_batch(inputs,model,loss_function,extra_params=False):\n",
    "    global Train_std_tensor , Train_mean_tensor\n",
    "    model.eval()\n",
    "    if extra_params:\n",
    "        x,y,z = inputs\n",
    "        x = x.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "        z = z.to(DEVICE)\n",
    "        prediction = model(x,z)\n",
    "    else:\n",
    "        x,y = inputs\n",
    "        x = x.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "        prediction = model(x)\n",
    "    prediction = normalize_function.denormalize_tensor(batch=prediction)\n",
    "    loss = loss_function(prediction, y)\n",
    "    return loss.detach().cpu().numpy()\n",
    "\n",
    "def utils_convert_to_2d_tensors(predictions,targets):\n",
    "    predictions  = np.array(predictions)\n",
    "    targets = np.array(targets)\n",
    "    predictions  = np.reshape(predictions , (-1, predictions.shape[-1]))\n",
    "    targets  = np.reshape(targets  , (-1 , targets.shape[-1]))\n",
    "    return torch.Tensor(predictions), torch.Tensor(targets)\n",
    "\n",
    "def train(trainLoader,valLoader,model,optimizer,loss_function,epochs,best_model_callback,extra_params=False):\n",
    "    #wandb.watch(model,loss_function,log = \"all\",log_freq=50)\n",
    "    \n",
    "    train_epoch_loss , train_epoch_accuracy =[] , []\n",
    "    val_epoch_loss , val_epoch_accuracy = [],[]\n",
    "    \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f\"epoch: {epoch} , lr is { scheduler.get_last_lr()}\" )\n",
    "        train_loss  = [] \n",
    "        val_loss ,val_accuracy = [] , []\n",
    "        \n",
    "        # batch training loss\n",
    "        with tqdm.tqdm(total=len(trainLoader)) as trainingLoop:\n",
    "            for index,batch in enumerate(iter(trainLoader)): \n",
    "        \n",
    "                loss = train_batch(batch,model,loss_function,optimizer,extra_params=extra_params)\n",
    "                train_loss.append(loss)\n",
    "\n",
    "                trainingLoop.set_description(f\"Batch: {index}/{len(trainLoader)}\")\n",
    "                trainingLoop.set_postfix({\"training Loss \" : loss})\n",
    "                trainingLoop.update(1)\n",
    "                ##wandb.log({\"Training Loss\":loss })\n",
    "        train_loss  = np.array(train_loss).mean() \n",
    "        train_epoch_loss.append(train_loss)\n",
    "        \n",
    "        # find training accuracy \n",
    "        predictions,targets = [],[]\n",
    "        for index,batch in enumerate(iter(trainLoader)): \n",
    "        \n",
    "            prediction = do_prediction(batch,model,extra_params=extra_params)\n",
    "            predictions.extend(prediction)\n",
    "            targets.extend(batch[1].detach().cpu().numpy())\n",
    "           \n",
    "        \n",
    "        predictions = np.array(predictions)\n",
    "        targets = np.array(targets)\n",
    "        predictions , targets = utils_convert_to_2d_tensors(predictions , targets)\n",
    "        # print(\"predictions=\", predictions[0:2])\n",
    "        # print(\"targets=\",targets[0:2])\n",
    "        metric = R2Score()\n",
    "        metric.update(predictions , targets)\n",
    "        train_epoch_accuracy.append(metric.compute().detach().cpu().numpy())\n",
    "                \n",
    "        \n",
    "        # validation set loss & accuracy  \n",
    "        predictions,targets = [],[]\n",
    "        with tqdm.tqdm(total = len(valLoader)) as validationLoop:\n",
    "            for index,batch in enumerate(iter(valLoader)):\n",
    "                \n",
    "                loss = validation_loss_batch(batch,model,loss_function,extra_params=extra_params)\n",
    "                val_loss.append(loss)\n",
    "                prediction = do_prediction(batch,model,is_val=True,extra_params=extra_params)\n",
    "                predictions.extend(prediction)\n",
    "                targets.extend(batch[1].detach().cpu().numpy())\n",
    "                \n",
    "                validationLoop.set_description(f\"Batch: {index}/{len(valLoader)}\")\n",
    "                validationLoop.set_postfix({\"Validation loss \" : loss}) \n",
    "                ##wandb.log({\"Vlaidation loss\" : loss})\n",
    "                #wandb.log({\"Validation Loss \": val_loss.item()})\n",
    "                validationLoop.update(1)\n",
    "        \n",
    "        \n",
    "        val_loss  = np.array(val_loss).mean() \n",
    "        val_epoch_loss.append(val_loss)\n",
    "        \n",
    "        predictions = np.array(predictions)\n",
    "        targets = np.array(targets)\n",
    "        # print(\"predictions-val=\", predictions[0:2])\n",
    "        # print(\"targets-val=\",targets[0:2])\n",
    "        metric =R2Score()\n",
    "        predictions , targets = utils_convert_to_2d_tensors(predictions , targets)\n",
    "        metric.update(predictions , targets)\n",
    "        val_epoch_accuracy.append(metric.compute().detach().cpu().numpy().item())\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f\"epoch:{epoch}, Training (avg) loss : {train_loss} , Validation loss (avg) = {val_loss}\")\n",
    "        print(f\"epoch:{epoch}, Training (avg) Accuracy : {train_epoch_accuracy[-1]} , Validation Accuracy (avg) = {val_epoch_accuracy[-1]}\")\n",
    "        best_model_callback(metric.compute().detach().cpu().numpy().item(),model)        # save the best model according to the validation accuracy\n",
    "        \n",
    "        \n",
    "    return train_epoch_loss,val_epoch_loss,train_epoch_accuracy , val_epoch_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = CustomModel(len(EXTRA_COLOUMN),6 , \"resnet34\")\n",
    "# image = torch.ones(10,3,128,128)\n",
    "\n",
    "# # x-shape= torch.Size([10, 3, 128, 128]) z-shape= torch.Size([10, 163]\n",
    "# x = torch.ones(10,len(EXTRA_COLOUMN))\n",
    "# model(image,x).shape\n",
    "# model = initialize_timm_model(model_name=\"efficientnet_v2\",num_class=6)\n",
    "#model,optimizer,loss_function,scheduler = get_model_optimizer_lossFunction(model_name = \"efficientnet_v2\",learning_rate = LEARNING_RATE,extra_params=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/efficientnet_b2.ra_in1k)\n",
      "INFO:timm.models._hub:[timm/efficientnet_b2.ra_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 , lr is [0.0001]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 247/248: 100%|██████████| 248/248 [01:49<00:00,  2.27it/s, training Loss =678490.0] \n",
      "  0%|          | 0/68 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NormalizeOutput' object has no attribute 'max_tensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m model,optimizer,loss_function,scheduler \u001b[38;5;241m=\u001b[39m get_model_optimizer_lossFunction(model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mefficientnet_v2\u001b[39m\u001b[38;5;124m\"\u001b[39m,learning_rate \u001b[38;5;241m=\u001b[39m LEARNING_RATE,extra_params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m best_model_callback \u001b[38;5;241m=\u001b[39m BestModelSaveCallback(save_path\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(BASE_DIR,MODEL_NAME_SAVE))\n\u001b[0;32m----> 4\u001b[0m train_losses, val_losses , train_accuracies,val_accuracies \u001b[38;5;241m=\u001b[39m train(train_dataloader,val_dataloader,model,optimizer,loss_function,EPOCHS,best_model_callback,extra_params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[85], line 122\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(trainLoader, valLoader, model, optimizer, loss_function, epochs, best_model_callback, extra_params)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(valLoader)) \u001b[38;5;28;01mas\u001b[39;00m validationLoop:\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m index,batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28miter\u001b[39m(valLoader)):\n\u001b[0;32m--> 122\u001b[0m         loss \u001b[38;5;241m=\u001b[39m validation_loss_batch(batch,model,loss_function,extra_params\u001b[38;5;241m=\u001b[39mextra_params)\n\u001b[1;32m    123\u001b[0m         val_loss\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[1;32m    124\u001b[0m         prediction \u001b[38;5;241m=\u001b[39m do_prediction(batch,model,is_val\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,extra_params\u001b[38;5;241m=\u001b[39mextra_params)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_gpu/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[0;32mIn[85], line 61\u001b[0m, in \u001b[0;36mvalidation_loss_batch\u001b[0;34m(inputs, model, loss_function, extra_params)\u001b[0m\n\u001b[1;32m     59\u001b[0m     y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m     60\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m model(x)\n\u001b[0;32m---> 61\u001b[0m prediction \u001b[38;5;241m=\u001b[39m normalize_function\u001b[38;5;241m.\u001b[39mdenormalize_tensor(batch\u001b[38;5;241m=\u001b[39mprediction)\n\u001b[1;32m     62\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_function(prediction, y)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "Cell \u001b[0;32mIn[77], line 74\u001b[0m, in \u001b[0;36mNormalizeOutput.denormalize_tensor\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     72\u001b[0m     df_denormalize \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_max\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 74\u001b[0m     df_denormalize \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_tensor \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_tensor) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_tensor\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df_denormalize\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df_denormalize\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NormalizeOutput' object has no attribute 'max_tensor'"
     ]
    }
   ],
   "source": [
    "\n",
    "MODEL_NAME_SAVE = 'best_model_transformation_efficientnet_v2_all_features.pth'\n",
    "model,optimizer,loss_function,scheduler = get_model_optimizer_lossFunction(model_name = \"efficientnet_v2\",learning_rate = LEARNING_RATE,extra_params=True)\n",
    "best_model_callback = BestModelSaveCallback(save_path=os.path.join(BASE_DIR,MODEL_NAME_SAVE))\n",
    "train_losses, val_losses , train_accuracies,val_accuracies = train(train_dataloader,val_dataloader,model,optimizer,loss_function,EPOCHS,best_model_callback,extra_params=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_NAME_SAVE = 'best_model_transformation_efficientnet_no_dropout.pth'\n",
    "# model.load_state_dict(torch.load(f\"/home/prajwal/cs680/cs680_kaggle/data/{MODEL_NAME_SAVE}\"))\n",
    "TEST_BATCH_SIZE  = 10\n",
    "torch.cuda.empty_cache()\n",
    "class data_loader_test(Dataset ):\n",
    "    def __init__(self,df ,extra_params = False ):\n",
    "        global EXTRA_COLOUMN\n",
    "        self.df = df.copy()\n",
    "        self.transform = A.Compose([\n",
    "             A.Resize(TARGET_IMAGE_SIZE, TARGET_IMAGE_SIZE,interpolation= cv2.INTER_CUBIC),\n",
    "                A.ToFloat(),\n",
    "                    A.Normalize([0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225], max_pixel_value=1),\n",
    "                    ToTensorV2(),\n",
    "        ])\n",
    "    \n",
    "        self.extra_params = extra_params\n",
    "        self.extra_coloumns = EXTRA_COLOUMN\n",
    "    def __len__(self):\n",
    "        return len(self.df)    \n",
    "    def __getitem__(self , index):\n",
    "        row = self.df.iloc[index]\n",
    "        image = plt.imread(row[\"image_path\"])\n",
    "        image = np.copy(image)\n",
    "        if self.transform :\n",
    "            image = self.transform(image)\n",
    "        if self.extra_params:\n",
    "            extras = row[self.extra_coloumns].values.astype(np.float64)\n",
    "            return image  , torch.Tensor(extras)\n",
    "        return  image \n",
    "test_dataset = data_loader_test(test_df,extra_params = True)\n",
    "test_dataloader = DataLoader(test_dataset,batch_size =TEST_BATCH_SIZE,shuffle=False)\n",
    "\n",
    "def predict_test(test_dataloader , model):\n",
    "    predictions = []\n",
    "    for i in test_dataloader:\n",
    "        #print(i[0].shape , i[1].shape)\n",
    "        model.eval()\n",
    "        prediction = model(i[0].to(DEVICE),i[1].to(DEVICE))\n",
    "        prediction  = normalize_function.denormalize_tensor(prediction)\n",
    "        predictions.extend(prediction.detach().cpu().numpy())\n",
    "    predictions = np.array(predictions)\n",
    "    output = np.reshape(predictions,(-1,predictions.shape[-1]))\n",
    "    return pd.DataFrame(output , columns=['X4', 'X11', 'X18', 'X26', 'X50', 'X3112' ])\n",
    "output = predict_test(test_dataloader , model)\n",
    "output = pd.concat([test_df[\"id\"],output],axis=1 )\n",
    "#output.to_csv()\n",
    "output.to_csv(\"best_model_transformation_efficientnet_v2_all_features.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# predictions= torch.tensor([[ 1.2391, 30.3367, 30.3599, 29.7099, 20.0526, 31.2610],\n",
    "#         [ 1.2679, 30.3845, 30.3134, 29.7083, 20.3929, 31.2463]])\n",
    "# targets= torch.tensor([[1.1125e+00, 1.4686e+02, 1.9699e+04, 3.4597e+03, 1.5282e+01, 3.9792e+05],\n",
    "#         [9.7378e-01, 1.5390e+02, 1.9702e+04, 3.4673e+03, 1.4737e+01, 3.9847e+05]])\n",
    "# metric = R2Score()\n",
    "# metric.update(predictions , targets)\n",
    "# metric.compute()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# from sklearn.metrics import r2_score\n",
    "# predictions= np.array([[ 1.2391, 30.3367, 30.3599, 29.7099, 20.0526, 31.2610],\n",
    "#         [ 1.2679, 30.3845, 30.3134, 29.7083, 20.3929, 31.2463]])\n",
    "# targets= np.array([[1.1125e+00, 1.4686e+02, 1.9699e+04, 3.4597e+03, 1.5282e+01, 3.9792e+05],\n",
    "#         [9.7378e-01, 1.5390e+02, 1.9702e+04, 3.4673e+03, 1.4737e+01, 3.9847e+05]])\n",
    "# r2_score(y_true = targets , y_pred =predictions)\n",
    "\n",
    "\n",
    "\n",
    "# targets = torch.tensor([[0.0, 2.0], [1.0, 6.0]])\n",
    "# predictions = torch.tensor([[0.0, 1.0], [2.0, 5.0]])\n",
    "# torch.mean(1- (torch.sum((targets - predictions)**2,axis=0)/torch.sum((targets - targets.mean())**2,axis=0)))\n",
    "\n",
    "\n",
    "# metric = R2Score()\n",
    "# # input = torch.tensor([[0, 2], [1, 6]])\n",
    "# # target = torch.tensor([[0, 1], [2, 5]])\n",
    "# input = torch.tensor([[ 1.2391, 30.3367, 30.3599, 29.7099, 20.0526, 31.2610],\n",
    "#         [ 1.2679, 30.3845, 30.3134, 29.7083, 20.3929, 31.2463]])\n",
    "# target= torch.tensor([[1.1125e+00, 1.4686e+02, 1.9699e+04, 3.4597e+03, 1.5282e+01, 3.9792e+05],\n",
    "#         [9.7378e-01, 1.5390e+02, 1.9702e+04, 3.4673e+03, 1.4737e+01, 3.9847e+05]])\n",
    "# metric.update(input, target)\n",
    "# metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plot(train_losses,train_accuracies,val_losses,val_accuracies,path):\n",
    "    plt.plot(train_losses,label = \"train loss\")\n",
    "    plt.plot(val_losses,label = \"validation loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    #plt.savefig(os.path.join(path,\"Loss.png\"))\n",
    "    #wandb.log({\"Loss\": plt})\n",
    "\n",
    "    plt.plot(val_accuracies,label = \"validation accuracy\")\n",
    "    plt.plot(train_accuracies,label = \"train accuracy\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend() \n",
    "    #plt.savefig(os.path.join(path,\"Accuracy.png\"))\n",
    "    #wandb.log({\"Accuracy\": plt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plot(train_losses,train_accuracies,val_losses,val_accuracies,path = BASE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(val_accuracies,label = \"validation accuracy\")\n",
    "plt.plot(train_accuracies,label = \"train accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
