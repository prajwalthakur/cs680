epoch: 0 , lr is [0.01]
Batch: 135/136: 100%|██████████| 136/136 [00:56<00:00,  2.42it/s, training Loss =1.0110457] 
Batch: 33/34: 100%|██████████| 34/34 [00:11<00:00,  2.90it/s, Validation loss =0.97480124]
epoch: 1 , lr is [0.01]
Batch: 135/136: 100%|██████████| 136/136 [00:54<00:00,  2.48it/s, training Loss =0.947596]  
Batch: 33/34: 100%|██████████| 34/34 [00:11<00:00,  2.90it/s, Validation loss =0.95318556]
epoch: 2 , lr is [0.01]
Batch: 135/136: 100%|██████████| 136/136 [00:55<00:00,  2.47it/s, training Loss =0.90630007]
Batch: 33/34: 100%|██████████| 34/34 [00:11<00:00,  2.90it/s, Validation loss =0.94005287]
epoch: 3 , lr is [0.01]
Batch: 135/136: 100%|██████████| 136/136 [00:55<00:00,  2.45it/s, training Loss =0.9344306] 
Batch: 33/34: 100%|██████████| 34/34 [00:11<00:00,  2.91it/s, Validation loss =0.9487002] 
epoch: 4 , lr is [0.01]
Batch: 135/136: 100%|██████████| 136/136 [00:55<00:00,  2.46it/s, training Loss =0.9605527] 
Batch: 33/34: 100%|██████████| 34/34 [00:11<00:00,  2.89it/s, Validation loss =0.9332247] 
epoch: 5 , lr is [0.01]
Batch: 135/136: 100%|██████████| 136/136 [00:55<00:00,  2.46it/s, training Loss =0.88117385]
Batch: 33/34: 100%|██████████| 34/34 [00:11<00:00,  2.89it/s, Validation loss =0.9165022] 
epoch: 6 , lr is [0.01]
Batch: 135/136: 100%|██████████| 136/136 [00:55<00:00,  2.47it/s, training Loss =0.90091485]
Batch: 33/34: 100%|██████████| 34/34 [00:11<00:00,  2.91it/s, Validation loss =0.9313144] 
epoch: 7 , lr is [0.01]
Batch: 135/136: 100%|██████████| 136/136 [00:55<00:00,  2.46it/s, training Loss =0.9069942] 
Batch: 33/34: 100%|██████████| 34/34 [00:11<00:00,  2.90it/s, Validation loss =0.9174921] 
epoch: 8 , lr is [0.01]
Batch: 135/136: 100%|██████████| 136/136 [00:55<00:00,  2.46it/s, training Loss =0.9356658] 
Batch: 33/34: 100%|██████████| 34/34 [00:11<00:00,  2.90it/s, Validation loss =0.9076133] 
epoch: 9 , lr is [0.01]
Batch: 135/136: 100%|██████████| 136/136 [00:55<00:00,  2.46it/s, training Loss =0.909446]  
Batch: 33/34: 100%|██████████| 34/34 [00:11<00:00,  2.92it/s, Validation loss =0.91767466]
epoch: 10 , lr is [0.01]
Batch: 135/136: 100%|██████████| 136/136 [00:55<00:00,  2.47it/s, training Loss =0.9597148] 
Batch: 33/34: 100%|██████████| 34/34 [00:11<00:00,  2.89it/s, Validation loss =0.9076869] 
epoch: 11 , lr is [0.01]
Batch: 135/136: 100%|██████████| 136/136 [00:55<00:00,  2.46it/s, training Loss =0.92861426]
Batch: 33/34: 100%|██████████| 34/34 [00:11<00:00,  2.90it/s, Validation loss =0.89228714]
epoch: 12 , lr is [0.01]
Batch: 135/136: 100%|██████████| 136/136 [00:55<00:00,  2.46it/s, training Loss =0.8459503] 
Batch: 33/34: 100%|██████████| 34/34 [00:11<00:00,  2.92it/s, Validation loss =0.92203057]
epoch: 13 , lr is [0.01]
Batch: 135/136: 100%|██████████| 136/136 [00:55<00:00,  2.46it/s, training Loss =0.97901857]
Batch: 33/34: 100%|██████████| 34/34 [00:11<00:00,  2.88it/s, Validation loss =0.919968]  
epoch: 14 , lr is [0.01]
Batch: 135/136: 100%|██████████| 136/136 [00:55<00:00,  2.46it/s, training Loss =0.87743986]
Batch: 33/34: 100%|██████████| 34/34 [00:11<00:00,  2.88it/s, Validation loss =0.89958847]
epoch: 15 , lr is [0.01]
Batch: 135/136: 100%|██████████| 136/136 [00:55<00:00,  2.46it/s, training Loss =0.938303]  
Batch: 33/34: 100%|██████████| 34/34 [00:11<00:00,  2.89it/s, Validation loss =0.9081044] 
epoch: 16 , lr is [0.001]
Batch: 135/136: 100%|██████████| 136/136 [00:55<00:00,  2.46it/s, training Loss =0.8622594] 
Batch: 33/34: 100%|██████████| 34/34 [00:11<00:00,  2.90it/s, Validation loss =0.90763044]
epoch: 17 , lr is [0.001]
Batch: 135/136: 100%|██████████| 136/136 [00:55<00:00,  2.46it/s, training Loss =0.7942598] 
Batch: 33/34: 100%|██████████| 34/34 [00:11<00:00,  2.92it/s, Validation loss =0.90604556]
epoch: 18 , lr is [0.001]
Batch: 135/136: 100%|██████████| 136/136 [00:55<00:00,  2.45it/s, training Loss =0.84693944]
Batch: 33/34: 100%|██████████| 34/34 [00:11<00:00,  2.89it/s, Validation loss =0.9042546] 
epoch: 19 , lr is [0.001]
Batch: 135/136: 100%|██████████| 136/136 [00:55<00:00,  2.46it/s, training Loss =0.90041584]
Batch: 33/34: 100%|██████████| 34/34 [00:11<00:00,  2.89it/s, Validation loss =0.91129464]
epoch: 20 , lr is [0.001]
Batch: 135/136: 100%|██████████| 136/136 [00:55<00:00,  2.46it/s, training Loss =0.85708636]
Batch: 33/34: 100%|██████████| 34/34 [00:11<00:00,  2.89it/s, Validation loss =0.8795692] 
epoch: 21 , lr is [0.001]
Batch: 135/136: 100%|██████████| 136/136 [00:55<00:00,  2.46it/s, training Loss =0.86033124]
Batch: 33/34: 100%|██████████| 34/34 [00:11<00:00,  2.88it/s, Validation loss =0.9145853] 
epoch: 22 , lr is [0.0001]
Batch: 135/136: 100%|██████████| 136/136 [00:55<00:00,  2.46it/s, training Loss =0.7708699] 
Batch: 33/34: 100%|██████████| 34/34 [00:11<00:00,  2.89it/s, Validation loss =0.902349]  
epoch: 23 , lr is [0.0001]
Batch: 135/136: 100%|██████████| 136/136 [00:55<00:00,  2.46it/s, training Loss =0.7869247] 
Batch: 33/34: 100%|██████████| 34/34 [00:11<00:00,  2.87it/s, Validation loss =0.8966083] 
epoch: 24 , lr is [0.0001]
Batch: 135/136: 100%|██████████| 136/136 [00:55<00:00,  2.46it/s, training Loss =0.85305905]
Batch: 33/34: 100%|██████████| 34/34 [00:11<00:00,  2.88it/s, Validation loss =0.89699924]
epoch: 25 , lr is [0.0001]
Batch: 135/136: 100%|██████████| 136/136 [00:55<00:00,  2.46it/s, training Loss =0.80058205]
Batch: 33/34: 100%|██████████| 34/34 [00:11<00:00,  2.92it/s, Validation loss =0.9037956] 