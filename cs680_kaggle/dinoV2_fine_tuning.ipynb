{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 \n",
    "import IPython\n",
    "from glob import glob\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tqdm\n",
    "#import seaborn as sns\n",
    "import albumentations as A\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "import torcheval \n",
    "import wandb\n",
    "import torchvision\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams.update(**{'figure.dpi':150})\n",
    "import psutil\n",
    "import imageio.v3 as imageio\n",
    "\n",
    "# %%\n",
    "RANDOM_NUMBER = 42\n",
    "torch.manual_seed(RANDOM_NUMBER)\n",
    "\n",
    "# %% [markdown]\n",
    "# # select Device\n",
    "\n",
    "# %%\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else  \"cpu\") #\"cuda:1\" if torch.cuda.is_available() else \n",
    "# torch.cuda.set_per_process_memory_fraction(0.95, device=DEVICE)\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# %%\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler , MinMaxScaler\n",
    "import scipy as sp\n",
    "\n",
    "# %%\n",
    "class Config():\n",
    "\n",
    "    BASE_DIR = os.path.join(os.getcwd() , 'data')\n",
    "    train_df = pd.read_csv(BASE_DIR  +  '/train.csv')\n",
    "    TRAIN_VAL_SPLIT_SIZE = 0.14\n",
    "    TRAIN_BATCH_SIZE = 10\n",
    "    VAL_BATCH_SIZE =  10\n",
    "    TEST_BATCH_SIZE = 10\n",
    "    LR_MAX = 1e-4\n",
    "    NUM_EPOCHS = 8\n",
    "    TIM_NUM_CLASS =6 # \n",
    "    NORMALIZE_TARGET = \"log_transform_mean_std\"   #\"log_transform\" #\n",
    "    RANDOM_NUMBER = 42\n",
    "    NUM_FLODS  = 5\n",
    "    NUM_CLASSES = 6\n",
    "    TRAITS_NAME = ['X4_mean', 'X11_mean', 'X18_mean', 'X26_mean', 'X50_mean', 'X3112_mean' ]\n",
    "    FOLD = 0 # Which fold to set as validation data\n",
    "    IMAGE_SIZE =128\n",
    "    TARGET_IMAGE_SIZE =  518\n",
    "    T_MAX =        9\n",
    "    LR_MODE = \"step\" # LR scheduler mode from one of \"cos\", \"step\", \"exp\"\n",
    "    torch.manual_seed(RANDOM_NUMBER)\n",
    "    INCLUDE_EXTRA_FEATURES = True\n",
    "    EXTRA_FEATURES_NORMALIZATION = \"standard_scalar\"  #\"min_max_normalization\"  #\n",
    "    WEIGHT_DECAY = 0.01\n",
    "    TABULAR_NN_OUTPUT  = 256\n",
    "    TIM_MODEL_NAME = \"dinoV2\" #\"swin_large\" #\"efficientnet_v2\" # \n",
    "    TIMM_FINED_TUNED_WEIGHT = f'{BASE_DIR}/model_08_ensemble.pth'\n",
    "    Lower_Quantile = 0.005\n",
    "    Upper_Quantile = 0.975  #0.985\n",
    "    WANDB_INIT = False\n",
    "    # use XGBBOOST to find prominant features\n",
    "    EXTRA_COLOUMN = ['WORLDCLIM_BIO1_annual_mean_temperature',\n",
    "       'WORLDCLIM_BIO12_annual_precipitation',\n",
    "       'WORLDCLIM_BIO13.BIO14_delta_precipitation_of_wettest_and_dryest_month',\n",
    "       'WORLDCLIM_BIO15_precipitation_seasonality',\n",
    "       'WORLDCLIM_BIO4_temperature_seasonality',\n",
    "       'WORLDCLIM_BIO7_temperature_annual_range',\n",
    "       'SOIL_bdod_0.5cm_mean_0.01_deg',\n",
    "       'SOIL_bdod_100.200cm_mean_0.01_deg',\n",
    "       'SOIL_bdod_15.30cm_mean_0.01_deg',\n",
    "       'SOIL_bdod_30.60cm_mean_0.01_deg',\n",
    "       'SOIL_bdod_5.15cm_mean_0.01_deg',\n",
    "       'SOIL_bdod_60.100cm_mean_0.01_deg', 'SOIL_cec_0.5cm_mean_0.01_deg',\n",
    "       'SOIL_cec_100.200cm_mean_0.01_deg',\n",
    "       'SOIL_cec_15.30cm_mean_0.01_deg', 'SOIL_cec_30.60cm_mean_0.01_deg',\n",
    "       'SOIL_cec_5.15cm_mean_0.01_deg', 'SOIL_cec_60.100cm_mean_0.01_deg',\n",
    "       'SOIL_cfvo_0.5cm_mean_0.01_deg',\n",
    "       'SOIL_cfvo_100.200cm_mean_0.01_deg',\n",
    "       'SOIL_cfvo_15.30cm_mean_0.01_deg',\n",
    "       'SOIL_cfvo_30.60cm_mean_0.01_deg',\n",
    "       'SOIL_cfvo_5.15cm_mean_0.01_deg',\n",
    "       'SOIL_cfvo_60.100cm_mean_0.01_deg',\n",
    "       'SOIL_clay_0.5cm_mean_0.01_deg',\n",
    "       'SOIL_clay_100.200cm_mean_0.01_deg',\n",
    "       'SOIL_clay_15.30cm_mean_0.01_deg',\n",
    "       'SOIL_clay_30.60cm_mean_0.01_deg',\n",
    "       'SOIL_clay_5.15cm_mean_0.01_deg',\n",
    "       'SOIL_clay_60.100cm_mean_0.01_deg',\n",
    "       'SOIL_nitrogen_0.5cm_mean_0.01_deg',\n",
    "       'SOIL_nitrogen_100.200cm_mean_0.01_deg',\n",
    "       'SOIL_nitrogen_15.30cm_mean_0.01_deg',\n",
    "       'SOIL_nitrogen_30.60cm_mean_0.01_deg',\n",
    "       'SOIL_nitrogen_5.15cm_mean_0.01_deg',\n",
    "       'SOIL_nitrogen_60.100cm_mean_0.01_deg',\n",
    "       'SOIL_ocd_0.5cm_mean_0.01_deg', 'SOIL_ocd_100.200cm_mean_0.01_deg',\n",
    "       'SOIL_ocd_15.30cm_mean_0.01_deg', 'SOIL_ocd_30.60cm_mean_0.01_deg',\n",
    "       'SOIL_ocd_5.15cm_mean_0.01_deg', 'SOIL_ocd_60.100cm_mean_0.01_deg',\n",
    "       'SOIL_ocs_0.30cm_mean_0.01_deg', 'SOIL_phh2o_0.5cm_mean_0.01_deg',\n",
    "       'SOIL_phh2o_100.200cm_mean_0.01_deg',\n",
    "       'SOIL_phh2o_15.30cm_mean_0.01_deg',\n",
    "       'SOIL_phh2o_30.60cm_mean_0.01_deg',\n",
    "       'SOIL_phh2o_5.15cm_mean_0.01_deg',\n",
    "       'SOIL_phh2o_60.100cm_mean_0.01_deg',\n",
    "       'SOIL_sand_0.5cm_mean_0.01_deg',\n",
    "       'SOIL_sand_100.200cm_mean_0.01_deg',\n",
    "       'SOIL_sand_15.30cm_mean_0.01_deg',\n",
    "       'SOIL_sand_30.60cm_mean_0.01_deg',\n",
    "       'SOIL_sand_5.15cm_mean_0.01_deg',\n",
    "       'SOIL_sand_60.100cm_mean_0.01_deg',\n",
    "       'SOIL_silt_0.5cm_mean_0.01_deg',\n",
    "       'SOIL_silt_100.200cm_mean_0.01_deg',\n",
    "       'SOIL_silt_15.30cm_mean_0.01_deg',\n",
    "       'SOIL_silt_30.60cm_mean_0.01_deg',\n",
    "       'SOIL_silt_5.15cm_mean_0.01_deg',\n",
    "       'SOIL_silt_60.100cm_mean_0.01_deg', 'SOIL_soc_0.5cm_mean_0.01_deg',\n",
    "       'SOIL_soc_100.200cm_mean_0.01_deg',\n",
    "       'SOIL_soc_15.30cm_mean_0.01_deg', 'SOIL_soc_30.60cm_mean_0.01_deg',\n",
    "       'SOIL_soc_5.15cm_mean_0.01_deg', 'SOIL_soc_60.100cm_mean_0.01_deg',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_01_._month_m1',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_02_._month_m1',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_03_._month_m1',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_04_._month_m1',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_05_._month_m1',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_01_._month_m10',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_02_._month_m10',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_03_._month_m10',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_04_._month_m10',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_05_._month_m10',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_01_._month_m11',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_02_._month_m11',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_03_._month_m11',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_04_._month_m11',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_05_._month_m11',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_01_._month_m12',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_02_._month_m12',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_03_._month_m12',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_04_._month_m12',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_05_._month_m12',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_01_._month_m2',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_02_._month_m2',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_03_._month_m2',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_04_._month_m2',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_05_._month_m2',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_01_._month_m3',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_02_._month_m3',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_03_._month_m3',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_04_._month_m3',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_05_._month_m3',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_01_._month_m4',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_02_._month_m4',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_03_._month_m4',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_04_._month_m4',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_05_._month_m4',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_01_._month_m5',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_02_._month_m5',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_03_._month_m5',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_04_._month_m5',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_05_._month_m5',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_01_._month_m6',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_02_._month_m6',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_03_._month_m6',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_04_._month_m6',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_05_._month_m6',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_01_._month_m7',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_02_._month_m7',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_03_._month_m7',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_04_._month_m7',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_05_._month_m7',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_01_._month_m8',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_02_._month_m8',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_03_._month_m8',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_04_._month_m8',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_05_._month_m8',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_01_._month_m9',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_02_._month_m9',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_03_._month_m9',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_04_._month_m9',\n",
    "       'MODIS_2000.2020_monthly_mean_surface_reflectance_band_05_._month_m9',\n",
    "       'VOD_C_2002_2018_multiyear_mean_m01',\n",
    "       'VOD_C_2002_2018_multiyear_mean_m02',\n",
    "       'VOD_C_2002_2018_multiyear_mean_m03',\n",
    "       'VOD_C_2002_2018_multiyear_mean_m04',\n",
    "       'VOD_C_2002_2018_multiyear_mean_m05',\n",
    "       'VOD_C_2002_2018_multiyear_mean_m06',\n",
    "       'VOD_C_2002_2018_multiyear_mean_m07',\n",
    "       'VOD_C_2002_2018_multiyear_mean_m08',\n",
    "       'VOD_C_2002_2018_multiyear_mean_m09',\n",
    "       'VOD_C_2002_2018_multiyear_mean_m10',\n",
    "       'VOD_C_2002_2018_multiyear_mean_m11',\n",
    "       'VOD_C_2002_2018_multiyear_mean_m12',\n",
    "       'VOD_Ku_1987_2017_multiyear_mean_m01',\n",
    "       'VOD_Ku_1987_2017_multiyear_mean_m02',\n",
    "       'VOD_Ku_1987_2017_multiyear_mean_m03',\n",
    "       'VOD_Ku_1987_2017_multiyear_mean_m04',\n",
    "       'VOD_Ku_1987_2017_multiyear_mean_m05',\n",
    "       'VOD_Ku_1987_2017_multiyear_mean_m06',\n",
    "       'VOD_Ku_1987_2017_multiyear_mean_m07',\n",
    "       'VOD_Ku_1987_2017_multiyear_mean_m08',\n",
    "       'VOD_Ku_1987_2017_multiyear_mean_m09',\n",
    "       'VOD_Ku_1987_2017_multiyear_mean_m10',\n",
    "       'VOD_Ku_1987_2017_multiyear_mean_m11',\n",
    "       'VOD_Ku_1987_2017_multiyear_mean_m12',\n",
    "       'VOD_X_1997_2018_multiyear_mean_m01',\n",
    "       'VOD_X_1997_2018_multiyear_mean_m02',\n",
    "       'VOD_X_1997_2018_multiyear_mean_m03',\n",
    "       'VOD_X_1997_2018_multiyear_mean_m04',\n",
    "       'VOD_X_1997_2018_multiyear_mean_m05',\n",
    "       'VOD_X_1997_2018_multiyear_mean_m06',\n",
    "       'VOD_X_1997_2018_multiyear_mean_m07',\n",
    "       'VOD_X_1997_2018_multiyear_mean_m08',\n",
    "       'VOD_X_1997_2018_multiyear_mean_m09',\n",
    "       'VOD_X_1997_2018_multiyear_mean_m10',\n",
    "       'VOD_X_1997_2018_multiyear_mean_m11',\n",
    "       'VOD_X_1997_2018_multiyear_mean_m12'\n",
    "       ]\n",
    "    N_TARGETS  =len(TRAITS_NAME)  \n",
    "\n",
    "CONFIG = Config()\n",
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "if CONFIG.WANDB_INIT:\n",
    "    wandb.login()\n",
    "    wandb.init(project=\"cs680v3\",group=\"dinoV2_fine_tuning\",name=\"dinoV2_fine_tuning\",\n",
    "        config = {\n",
    "        \"LR_max\": CONFIG.LR_MAX,\n",
    "        \"WEIGHT_DECAY\":CONFIG.WEIGHT_DECAY,\n",
    "        \"train_batch\" : CONFIG.TRAIN_BATCH_SIZE,\n",
    "        \"test_batch\"  : CONFIG.TEST_BATCH_SIZE\n",
    "        })\n",
    "\n",
    "# %% [markdown]\n",
    "# # Preprocessing the Tabular Data And Image Transformation\n",
    "\n",
    "# %%\n",
    "# define_transformation for the tabular data\n",
    "log_tf_col = CONFIG.TRAITS_NAME\n",
    "scale_feature_col =  CONFIG.EXTRA_COLOUMN + CONFIG.TRAITS_NAME\n",
    "log_transform = ColumnTransformer(transformers= [\n",
    "    ('log' , FunctionTransformer( np.log10  , inverse_func=sp.special.exp10, validate=False, check_inverse = True ,feature_names_out='one-to-one') , log_tf_col)\n",
    "        ] , verbose_feature_names_out=False ,remainder= 'passthrough'\n",
    "          )\n",
    "log_transform.set_output(transform='pandas')\n",
    "\n",
    "std_scale =  ColumnTransformer(transformers=[('scale',StandardScaler() ,scale_feature_col )  ],\n",
    "                               verbose_feature_names_out=False,\n",
    "                               remainder='passthrough'\n",
    "                               )\n",
    "std_scale.set_output(transform='pandas')\n",
    "scaling_pipeline = Pipeline(steps=[   \n",
    "                        (\"log\" , log_transform),\n",
    "                        (\"std_scale\" , std_scale )])\n",
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "# preparing the tabular data that has been given \n",
    "BASE_DIR =CONFIG.BASE_DIR\n",
    "Train_DF = pd.read_csv(BASE_DIR  +  '/train.csv')  #.iloc[:-10000]\n",
    "Test_DF =  pd.read_csv(BASE_DIR  +  '/test.csv')\n",
    "Test_DF[log_tf_col] =1\n",
    "\n",
    "train_df , val_df = train_test_split(Train_DF,test_size=CONFIG.TRAIN_VAL_SPLIT_SIZE,shuffle=True)\n",
    "for column in CONFIG.TRAITS_NAME:\n",
    "    lower_quantile = train_df[column].quantile(CONFIG.Lower_Quantile)\n",
    "    upper_quantile = train_df[column].quantile(CONFIG.Upper_Quantile)\n",
    "    train_df = train_df[(train_df[column] >= lower_quantile) & (train_df[column] <= upper_quantile)]\n",
    "\n",
    "\n",
    "\n",
    "print('JPEG Files Processing:')\n",
    "train_df['file_path'] = train_df['id'].apply(lambda s: f'{BASE_DIR}/train_images/{s}.jpeg')\n",
    "train_df['jpeg_bytes'] = train_df['file_path'].apply(lambda fp: open(fp, 'rb').read())\n",
    "\n",
    "val_df['file_path'] = val_df['id'].apply(lambda s: f'{BASE_DIR}/train_images/{s}.jpeg')\n",
    "val_df['jpeg_bytes'] = val_df['file_path'].apply(lambda fp: open(fp, 'rb').read())\n",
    "\n",
    "Test_DF['file_path'] = Test_DF['id'].apply(lambda s: f'{BASE_DIR}/test_images/{s}.jpeg')\n",
    "Test_DF['jpeg_bytes'] = Test_DF['file_path'].apply(lambda fp: open(fp, 'rb').read())\n",
    "print('JPEG Files Processing End')    \n",
    "\n",
    "\n",
    "# train_tabular = train_df.drop(columns = ['id'] + CONFIG.TRAITS_NAME)\n",
    "# val_tabular =    val_df.drop(columns = ['id'] + CONFIG.TRAITS_NAME)\n",
    "# test_tabular = test.drop(columns = ['id'])\n",
    "\n",
    "# scaling of the training data !\n",
    "\n",
    "training_scaling_pipeline = Pipeline(steps=[   \n",
    "                        (\"log\" , log_transform),\n",
    "                        (\"std_scale\" , std_scale )])\n",
    "\n",
    "train_tabular_scaled =  training_scaling_pipeline.fit_transform(train_df)\n",
    "validation_tabular_scaled = training_scaling_pipeline.transform(val_df)\n",
    "\n",
    "test_tabular_scaled = training_scaling_pipeline.transform(Test_DF)\n",
    "Test_DF = Test_DF.drop(columns=log_tf_col)\n",
    "             \n",
    "                \n",
    "\n",
    "# some hyper parameter for lr scheduler\n",
    "CONFIG.N_TRAIN_SAMPLES = len(train_df)\n",
    "CONFIG.N_STEPS_PER_EPOCH = (CONFIG.N_TRAIN_SAMPLES // CONFIG.TRAIN_BATCH_SIZE)\n",
    "CONFIG.N_STEPS = CONFIG.N_STEPS_PER_EPOCH * CONFIG.NUM_EPOCHS + 1   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Image PreProcessing\n",
    "\n",
    "MEAN = [0.485, 0.456, 0.406]\n",
    "STD = [0.229, 0.224, 0.225]\n",
    "TRAIN_TRANSFORMS = A.Compose([\n",
    "    A.RandomResizedCrop(size=(CONFIG.TARGET_IMAGE_SIZE,CONFIG.TARGET_IMAGE_SIZE), interpolation=cv2.INTER_CUBIC),  # Simulate different crops\n",
    "    A.HorizontalFlip(p=0.2),  \n",
    "    A.ToFloat(),\n",
    "    A.Normalize(mean=MEAN, std=STD, max_pixel_value=1),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "TEST_TRANSFORMS = A.Compose([\n",
    "    A.Resize(CONFIG.TARGET_IMAGE_SIZE,CONFIG.TARGET_IMAGE_SIZE),\n",
    "    A.CenterCrop(CONFIG.TARGET_IMAGE_SIZE,CONFIG.TARGET_IMAGE_SIZE),\n",
    "    A.ToFloat(),\n",
    "    A.Normalize(mean=MEAN, std=STD, max_pixel_value=1),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class create_dataset(Dataset):\n",
    "    def __init__(self, X_jpeg_bytes, X_tabular, y, transforms=None):\n",
    "        self.X_jpeg_bytes = X_jpeg_bytes\n",
    "        self.X_tabular = X_tabular\n",
    "        self.y = y\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X_sample = self.transforms(\n",
    "            image=imageio.imread(self.X_jpeg_bytes[index]),\n",
    "        )['image']\n",
    "        X_tabular_sample = self.X_tabular[index]\n",
    "        y_sample = self.y[index]\n",
    "\n",
    "        return X_sample, X_tabular_sample, y_sample\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = create_dataset(\n",
    "    X_jpeg_bytes = train_tabular_scaled['jpeg_bytes'].values,\n",
    "    X_tabular = train_tabular_scaled[CONFIG.EXTRA_COLOUMN].values.astype(np.float32),\n",
    "    y = train_tabular_scaled[CONFIG.TRAITS_NAME].values.astype(np.float32),\n",
    "    transforms= TRAIN_TRANSFORMS\n",
    ")\n",
    "\n",
    "validation_dataset = create_dataset(\n",
    "    X_jpeg_bytes = validation_tabular_scaled['jpeg_bytes'].values,\n",
    "    X_tabular = validation_tabular_scaled[CONFIG.EXTRA_COLOUMN].values.astype(np.float32),\n",
    "    y = validation_tabular_scaled[CONFIG.TRAITS_NAME].values.astype(np.float32),\n",
    "    transforms= TEST_TRANSFORMS\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=CONFIG.TRAIN_BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=  0 #psutil.cpu_count(),\n",
    ")\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "    validation_dataset,\n",
    "    batch_size=CONFIG.VAL_BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers= 0 #psutil.cpu_count(),\n",
    ")\n",
    "\n",
    "test_dataset = create_dataset(\n",
    "    X_jpeg_bytes = test_tabular_scaled['jpeg_bytes'].values,\n",
    "    X_tabular = test_tabular_scaled[CONFIG.EXTRA_COLOUMN].values.astype(np.float32),\n",
    "    y = test_tabular_scaled[\"id\"].values,\n",
    "    transforms= TEST_TRANSFORMS\n",
    "    )\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=CONFIG.TEST_BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers= 0 #psutil.cpu_count(),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ImageBackbone_dinoV2(nn.Module):\n",
    "    def __init__(self, backbone_name, weight_path, out_features, fixed_feature_extractor=None):\n",
    "        super().__init__()\n",
    "        self.out_features = out_features\n",
    "        self.backbone = timm.create_model('vit_small_patch14_dinov2.lvd142m', pretrained=True, num_classes=out_features) #remove classifier nn.Linear\n",
    "        #self.backbone = backbone_.forward_head(backbone_, pre_logits=True)\n",
    "        in_features = self.backbone.num_features\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# %%\n",
    "def initialize_image_model( model_name   , tim_num_class=0.0, fine_tuned_weight = None,fixed_feature_extractor=True):\n",
    "    model_ft  = None\n",
    "    if model_name == \"dinoV2\":\n",
    "        model = ImageBackbone_dinoV2(model_name,weight_path=None , out_features=tim_num_class,fixed_feature_extractor=fixed_feature_extractor)\n",
    "        return model\n",
    "\n",
    "# %%\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self,input_channels,out_channels, target_features_num , tim_num_class , model_name):\n",
    "        super().__init__()\n",
    "        self.img_backbone = initialize_image_model(model_name=model_name ,tim_num_class=tim_num_class , fine_tuned_weight = CONFIG.TIMM_FINED_TUNED_WEIGHT,fixed_feature_extractor=False)       \n",
    "    def forward(self,image,x):\n",
    "        output = self.img_backbone(image) # bach * (hight*col)\n",
    "        return output\n",
    "\n",
    "\n",
    "\n",
    "class BestModelSaveCallback:\n",
    "    def __init__(self, save_path):\n",
    "        self.save_path = save_path\n",
    "        self.best_accuracy = -1\n",
    "\n",
    "    def __call__(self, accuracy,model):\n",
    "        if accuracy > self.best_accuracy:\n",
    "            self.best_accuracy = accuracy\n",
    "            model.to(device = \"cpu\")\n",
    "            torch.save(model.state_dict(), self.save_path)\n",
    "            model.to(device=DEVICE)\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "model = CustomModel(input_channels = len(CONFIG.EXTRA_COLOUMN) ,out_channels =CONFIG.TABULAR_NN_OUTPUT, target_features_num= len(CONFIG.TRAITS_NAME), tim_num_class=CONFIG.TIM_NUM_CLASS , model_name=CONFIG.TIM_MODEL_NAME)\n",
    "model.to(DEVICE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    sample_input = torch.randn(1, 3, 224, 224).to(DEVICE)\n",
    "    sample_output = model.feature_model(sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "# optimizer\n",
    "import torcheval.metrics\n",
    "import torcheval.metrics.regression\n",
    "import torchmetrics\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    params=model.parameters(),\n",
    "    lr=CONFIG.LR_MAX,\n",
    "    weight_decay=CONFIG.WEIGHT_DECAY,\n",
    ")\n",
    "\n",
    "# lr scheduler\n",
    "def get_lr_scheduler(optimizer):\n",
    "    # return torch.optim.lr_scheduler.OneCycleLR(\n",
    "    #     optimizer=optimizer,\n",
    "    #     max_lr=CONFIG.LR_MAX,\n",
    "    #     total_steps=CONFIG.N_STEPS,\n",
    "    #     pct_start=0.1,\n",
    "    #     anneal_strategy='cos',\n",
    "    #     div_factor=1e1,\n",
    "    #     final_div_factor=1e1,\n",
    "    # )\n",
    "    return torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "    \n",
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val):\n",
    "        self.sum += val.sum()\n",
    "        self.count += val.numel()\n",
    "        self.avg = self.sum / self.count\n",
    "        \n",
    "MSE = torcheval.metrics.regression.MeanSquaredError().to(DEVICE)\n",
    "R2sc = torchmetrics.regression.R2Score(num_outputs=len(CONFIG.TRAITS_NAME) , multioutput=\"uniform_average\").to(DEVICE)\n",
    "R2sc_val = torchmetrics.regression.R2Score(num_outputs=len(CONFIG.TRAITS_NAME) , multioutput=\"uniform_average\").to(DEVICE)\n",
    "MSE_val = torcheval.metrics.regression.MeanSquaredError().to(DEVICE)\n",
    "LOSS = AverageMeter()\n",
    "LOSS_val = AverageMeter()\n",
    "TARGET_TRAITS_MEAN = torch.tensor(train_df[CONFIG.TRAITS_NAME].mean().values).to(DEVICE)        # target mean accross the training dataset\n",
    "EPS = torch.tensor([1e-6]).to('cuda')\n",
    "\n",
    "\n",
    "# just to check if r2 loss is also decreasing \n",
    "def r2_loss(y_pred, y_true):\n",
    "    ss_res = torch.sum((y_true - y_pred)**2, dim=0)\n",
    "    ss_total = torch.sum((y_true - TARGET_TRAITS_MEAN)**2, dim=0)\n",
    "    ss_total = torch.maximum(ss_total, EPS)\n",
    "    r2 = torch.mean(ss_res / ss_total)\n",
    "    return r2\n",
    "\n",
    "LOSS_FN = nn.SmoothL1Loss() # r2_loss\n",
    "LR_SCHEDULER = get_lr_scheduler(optimizer)\n",
    "\n",
    "\n",
    "def train_batch(inputs,model):\n",
    "    model.train()  \n",
    "    #X_image, X_tabular, y_true\n",
    "    if CONFIG.INCLUDE_EXTRA_FEATURES :\n",
    "        x,z,y = inputs\n",
    "        x = x.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "        z = z.to(DEVICE)\n",
    "        y_pred = model(x,z)   \n",
    "    else:\n",
    "        x,y = inputs\n",
    "        x = x.to(DEVICE)\n",
    "        y = y.to(DEVICE)    \n",
    "        y_pred = model(x)\n",
    "    \n",
    "    \n",
    "    #loss_func = nn.MSELoss()\n",
    "    #loss_val = loss_func(prediction,y)\n",
    "    loss = LOSS_FN(y_pred,y) \n",
    "    LOSS.update(loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    LR_SCHEDULER.step()\n",
    "    MSE.update(y_pred,y)\n",
    "    R2sc.update(y_pred , y )\n",
    "    return LOSS.avg.detach().cpu().numpy() ,MSE.compute().item() ,R2sc.compute().item()\n",
    "\n",
    "@torch.no_grad\n",
    "def do_prediction(inputs,model, is_val=False):\n",
    "    global Train_std_tensor , Train_mean_tensor\n",
    "    model.eval()\n",
    "    if  CONFIG.INCLUDE_EXTRA_FEATURES:\n",
    "        x,z,y = inputs\n",
    "        x = x.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "        z = z.to(DEVICE)\n",
    "        prediction = model(x,z)\n",
    "    else:\n",
    "        x,y = inputs\n",
    "        x = x.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "        prediction = model(x)\n",
    "    if is_val :\n",
    "        prediction =prediction\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validation_loss_batch(inputs,model):\n",
    "    global Train_std_tensor , Train_mean_tensor\n",
    "    model.eval()\n",
    "    if CONFIG.INCLUDE_EXTRA_FEATURES:\n",
    "        x,z,y = inputs\n",
    "        x = x.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "        z = z.to(DEVICE)\n",
    "        prediction = model(x,z)\n",
    "    else:\n",
    "        x,y = inputs\n",
    "        x = x.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "        prediction = model(x)\n",
    "    prediction =prediction\n",
    "    loss = LOSS_FN(prediction, y)\n",
    "    LOSS_val.update(loss)\n",
    "    MSE_val.update(prediction,y)\n",
    "    R2sc_val.update(prediction , y )\n",
    "    return LOSS_val.avg.detach().cpu().numpy() ,MSE_val.compute().item() ,R2sc_val.compute().item()\n",
    "\n",
    "def utils_convert_to_2d_tensors(predictions,targets):\n",
    "    predictions  = np.array(predictions)\n",
    "    targets = np.array(targets)\n",
    "    predictions  = np.reshape(predictions , (-1, predictions.shape[-1]))\n",
    "    targets  = np.reshape(targets  , (-1 , targets.shape[-1]))\n",
    "    return torch.Tensor(predictions), torch.Tensor(targets)\n",
    "\n",
    "def train(trainLoader,valLoader,model,num_epochs,best_model_callback):\n",
    "    #wandb.watch(model,loss_function,log = \"all\",log_freq=50)\n",
    "    \n",
    "    train_epoch_loss , train_epoch_r2 , train_epoch_mse =[] , [] , []\n",
    "    val_epoch_loss , val_epoch_r2 , val_epoch_mse = [],[],[]\n",
    "    \n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        #wandb.log({\"epoch\":epoch })\n",
    "        # print(f\"epoch: {epoch} , lr is { LR_SCHEDULER.get_last_lr()}\" )\n",
    "        train_loss_current_epoch ,train_mse_current_epoch, train_r2_current_epoch = [] , [] , []\n",
    "        MSE.reset()\n",
    "        R2sc.reset()\n",
    "        LOSS.reset()\n",
    "        # batch training loss\n",
    "        with tqdm.tqdm(total=len(trainLoader)) as trainingLoop:\n",
    "            for index,batch in enumerate(iter(trainLoader)): \n",
    "        \n",
    "                loss,mse_ , r2_ = train_batch(batch,model)\n",
    "                train_loss_current_epoch.append(loss)\n",
    "                train_mse_current_epoch.append(mse_)\n",
    "                train_r2_current_epoch.append(r2_)\n",
    "                \n",
    "                trainingLoop.set_description(f\"Epoch:{epoch} , Batch: {index}/{len(trainLoader)} \")\n",
    "                #print(loss , mse_,  r2_ ,LR_SCHEDULER.get_last_lr())\n",
    "                trainingLoop.set_postfix({ \"Training batch\" : index , \"loss is\" : loss , \"MSE\" :  mse_ , \"R2\":  r2_, \"lr was\":  LR_SCHEDULER.get_last_lr()[0] })\n",
    "                trainingLoop.update(1)\n",
    "                if CONFIG.WANDB_INIT:\n",
    "                    wandb.log({\"Training-Loss\":loss  , \"Training-MSE\" :  mse_ , \"Training-R2\":  r2_ })\n",
    "        \n",
    "        # train_epoch_loss.append(np.array(train_loss_current_epoch).mean() )\n",
    "        # train_epoch_r2.append(np.array(train_r2_current_epoch).mean())\n",
    "        # train_epoch_mse.append(np.array(train_mse_current_epoch).mean())\n",
    "\n",
    "        MSE_val.reset()\n",
    "        R2sc_val.reset()\n",
    "        LOSS_val.reset()\n",
    "                \n",
    "        # validation set loss & accuracy  \n",
    "        # val_loss_current_epoch ,val_mse_current_epoch, val_r2_current_epoch = [] , [] , []\n",
    "        val_r2 = 0\n",
    "        with tqdm.tqdm(total = len(valLoader)) as validationLoop:\n",
    "            for index,batch in enumerate(iter(valLoader)):\n",
    "                loss,mse_ , val_r2 = validation_loss_batch(batch,model)\n",
    "                #val_loss_current_epoch.append(loss)\n",
    "                #val_mse_current_epoch.append(mse_) \n",
    "                #val_r2_current_epoch.append(r2_)\n",
    "                #validationLoop.set_description(f\"Batch: {index}/{len(valLoader)}\")\n",
    "                #validationLoop.set_postfix({ \"Validation batch\" : index , \"loss is\" : loss , \"MSE\" :  mse_ , \"R2\":  val_r2 })\n",
    "                ##wandb.log({\"Vlaidation loss\" : loss})\n",
    "                #validationLoop.update(1)\n",
    "            if CONFIG.WANDB_INIT :\n",
    "                wandb.log({\"Validation-Loss\":loss  , \"Validation-MSE\" :  mse_ , \"Validation-R2\":  val_r2 })\n",
    "        \n",
    "        best_model_callback(val_r2,model)        # save the best model according to the validation accuracy\n",
    "        \n",
    "        \n",
    "    return train_epoch_loss,val_epoch_loss,train_epoch_r2 , val_epoch_r2\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME_SAVE = 'dino_v2_fine_tuning.pth'\n",
    "best_model_callback = BestModelSaveCallback(save_path=os.path.join(CONFIG.BASE_DIR,MODEL_NAME_SAVE))\n",
    "train_losses, val_losses , train_accuracies,val_accuracies = train(train_dataloader,validation_dataloader,model,CONFIG.NUM_EPOCHS,best_model_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame(columns=CONFIG.TRAITS_NAME)\n",
    "for index , batch in tqdm.tqdm(enumerate(iter(test_dataloader))):\n",
    "    X_img_test = batch[0] \n",
    "    X_features  = batch[1]\n",
    "    test_id  = batch[2]\n",
    "    #print(batch) \n",
    "    with torch.no_grad():\n",
    "        #print(X_img_test.shape, X_features.shape)\n",
    "        y_pred = model(X_img_test.to(DEVICE)).detach().cpu().numpy()  #,X_features.to(DEVICE)\n",
    "    \n",
    "        pred_pd = pd.DataFrame(columns=CONFIG.EXTRA_COLOUMN + CONFIG.TRAITS_NAME)\n",
    "        pred_pd[CONFIG.EXTRA_COLOUMN] =-1\n",
    "        pred_pd[CONFIG.TRAITS_NAME] = y_pred \n",
    "\n",
    "        temp1 =   scaling_pipeline['std_scale']['scale'].inverse_transform(pred_pd)\n",
    "        temp2=    pd.DataFrame(temp1, columns=CONFIG.EXTRA_COLOUMN + CONFIG.TRAITS_NAME)\n",
    "        pred_final =   scaling_pipeline['log']['log'].inverse_transform(temp2[CONFIG.TRAITS_NAME])\n",
    "        #pred_final[\"id\"] = test_id.cpu().detach().numpy()\n",
    "        submission_df = pd.concat([submission_df, pred_final.assign(id=test_id.cpu().detach().numpy())], ignore_index=True)\n",
    "# submission_df.to_csv('submission_self_tuning.csv', index=False)\n",
    "submission_df[[\"id\"]  + CONFIG.TRAITS_NAME ].to_csv('submission_tuned_dinoV2.csv', index=False)\n",
    "print(\"Submit!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
