{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prajwal/anaconda3/envs/pytorch_gpu/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.10). Upgrade using: pip install --upgrade albumentations\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import cv2 \n",
    "import IPython\n",
    "from glob import glob\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tqdm\n",
    "#import seaborn as sns\n",
    "import albumentations as A\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "from torcheval.metrics import R2Score\n",
    "import wandb\n",
    "import torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x760b92c3fdb0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "BASE_DIR = os.path.join(os.getcwd() , 'data')\n",
    "train_df = pd.read_csv(BASE_DIR  +  '/train.csv')\n",
    "TRAIN_VAL_SPLIT_SIZE = 0.2\n",
    "TRAIN_BATCH_SIZE = 128\n",
    "VAL_BATCH_SIZE = 128\n",
    "TEST_BATCH_SIZE  = 10\n",
    "LEARNING_RATE = 1e-5\n",
    "EPOCHS = 10\n",
    "\n",
    "Normalize_transform_type = \"log_transform\"\n",
    "RANDOM_NUMBER = 42\n",
    "torch.manual_seed(RANDOM_NUMBER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wandb.login()\n",
    "\n",
    "# wandb.init(project=\"cs680v2_normalized\",\n",
    "#     config={\n",
    "#        \"learning_rate\": LEARNING_RATE,\n",
    "#         \"epochs\": EPOCHS,\n",
    "#         \"batch_size\" : TRAIN_BATCH_SIZE,\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DATA_DIRECTORY = os.path.join(os.getcwd(),\"data\")\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_val_train_dataset(BASE_DIR,train_split_size):\n",
    "    df = pd.read_csv(BASE_DIR  +  '/train.csv')\n",
    "    df[\"image_path\"] = BASE_DIR + \"/train_images/\" + df[\"id\"].astype(str) + \".jpeg\"   # add images in the training dataframe\n",
    "    train_df , val_df = train_test_split(df,test_size=train_split_size,shuffle=True)\n",
    "    train_df.reset_index(drop=True , inplace  = True)\n",
    "    val_df.reset_index(drop = True , inplace = True)\n",
    "    return  train_df , val_df\n",
    "\n",
    "\n",
    "def create_test_dataset(BASE_DIR):\n",
    "    df = pd.read_csv(BASE_DIR  +  '/test.csv')\n",
    "    df[\"image_path\"] = BASE_DIR + \"/test_images/\" + df[\"id\"].astype(str) + \".jpeg\"   # add images in the training dataframe\n",
    "    return df\n",
    "\n",
    "train_df , val_df = create_val_train_dataset(BASE_DIR,TRAIN_VAL_SPLIT_SIZE)\n",
    "test_df = create_test_dataset(BASE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalizeOutput():\n",
    "    def __init__(self,type_transform ):\n",
    "        self.transform = type_transform\n",
    "        self.mean = 0\n",
    "        self.std = 0\n",
    "        self.mean_tensor = 0\n",
    "        self.std_tensor = 0\n",
    "        \n",
    "        pass\n",
    "    def normalize(self,df):\n",
    "        if self.transform == \"log_transform\":\n",
    "            mean = np.log10(df).mean()\n",
    "            std = np.log10(df).std()\n",
    "            self.mean = mean\n",
    "            self.std = std\n",
    "            self.mean_tensor = torch.Tensor(self.mean.values).to(DEVICE)\n",
    "            self.std_tensor = torch.Tensor(self.std.values).to(DEVICE)\n",
    "            return (np.log10(df) - self.mean)/self.std\n",
    "    def denormalize(self,df):\n",
    "        if self.mean is None or self.std is None :\n",
    "            raise Exception(\"mean and/std is not defined \")\n",
    "        if self.normalize == \"log_transform\":\n",
    "            df_denormalize =10**((df*self.std) + self.mean )\n",
    "            return df_denormalize\n",
    "    def denormalize_tensor(self,batch) :\n",
    "        if self.mean_tensor is None or self.std_tensor is None :\n",
    "            raise Exception(\"mean and/std is not defined \")\n",
    "        if self.transform == \"log_transform\":\n",
    "            df_denormalize =10**((batch*self.std_tensor) + self.mean_tensor )\n",
    "            return df_denormalize\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = plt.imread(val_df[\"image_path\"].iloc[0])\n",
    "# plt.imshow(img)\n",
    "# img.shape\n",
    "#train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to avoid overfitting : 1) try diffferent transformations 2) batch norm 3)  dropout  4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outside pass\n",
      "outside pass\n"
     ]
    }
   ],
   "source": [
    "class data_loader(Dataset ):\n",
    "    def __init__(self,df , is_val = False,normalizedOutput=None ):\n",
    "        self.df = df.copy()\n",
    "        if normalizedOutput == None:\n",
    "            pass\n",
    "        else :\n",
    "            if not is_val :\n",
    "                self.df[['X4_mean', 'X11_mean', 'X18_mean', 'X26_mean', 'X50_mean', 'X3112_mean' ]] = normalizedOutput.normalize(self.df[['X4_mean', 'X11_mean', 'X18_mean', 'X26_mean', 'X50_mean', 'X3112_mean' ]])\n",
    "        print(\"outside pass\")\n",
    "        self.transform =torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                                 #torchvision.transforms.Resize((384,384)),\n",
    "                                  torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225]),\n",
    "                                    torchvision.transforms.RandomVerticalFlip(p=0.5),\n",
    "                                    torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "                                    torchvision.transforms.RandomChoice([\n",
    "                                        torchvision.transforms.Lambda(lambda x : x + np.sqrt(0.1)*torch.randn_like(x)),\n",
    "                                        torchvision.transforms.Lambda(lambda x : x + 0.1*torch.randn_like(x)),\n",
    "                                        torchvision.transforms.Lambda(lambda x : x + torch.randn_like(x))])\n",
    "                             ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # def collate_fn(self,data):\n",
    "    #     print(\"hello\")\n",
    "    #     images =[(i[\"image\"]) for i in data]\n",
    "    #     print(images) \n",
    "    #     traits = np.array ( [i[\"traits\"] for i in data] )\n",
    "    #     #images = [self.resize_image(j) for i in data for j in i[\"images\"]]\n",
    "        \n",
    "    #     #images = torch.permute(torch.tensor(images,dtype=torch.float),(0,3,1,2)) # Batch x channels x height x width\n",
    "    #     #images = self.transform(images)\n",
    "    #     #images = torch.permute(images , (0,3,1,2))\n",
    "    #     traits = torch.tensor(traits,dtype=torch.float)\n",
    "    #     return images , traits\n",
    "    \n",
    "    \n",
    "    def __getitem__(self , index):\n",
    "        row = self.df.iloc[index]\n",
    "        image = plt.imread(row[\"image_path\"])\n",
    "        image = np.copy(image)\n",
    "        traits = row[['X4_mean', 'X11_mean', 'X18_mean', 'X26_mean', 'X50_mean', 'X3112_mean' ]].values.astype(np.float64)\n",
    "        if self.transform :\n",
    "            image = self.transform(image)\n",
    "            #image = torch.permute(image  )\n",
    "        traits = torch.tensor(traits,dtype=torch.float)\n",
    "        return  image , traits\n",
    "normalize_function = NormalizeOutput(Normalize_transform_type)\n",
    "train_dataset = data_loader(train_df, is_val = False,normalizedOutput=normalize_function)\n",
    "val_dataset  = data_loader(val_df,   is_val = True,normalizedOutput=normalize_function)    \n",
    "\n",
    "train_dataloader = DataLoader(train_dataset , batch_size = TRAIN_BATCH_SIZE , shuffle=True )\n",
    "val_dataloader = DataLoader(val_dataset , batch_size =  VAL_BATCH_SIZE , shuffle=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class data_loader_test(Dataset ):\n",
    "#     def __init__(self,df  ):\n",
    "#         self.df = df.copy()\n",
    "#         self.transform =torchvision.transforms.Compose([\n",
    "#                                torchvision.transforms.ToTensor(),\n",
    "#                                  #torchvision.transforms.Resize((384,384)),\n",
    "#                                   torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "#                                   ])\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.df)    \n",
    "#     def __getitem__(self , index):\n",
    "#         row = self.df.iloc[index]\n",
    "#         image = plt.imread(row[\"image_path\"])\n",
    "#         image = np.copy(image)\n",
    "#         if self.transform :\n",
    "#             image = self.transform(image)\n",
    "#         return  image \n",
    "# test_dataset = data_loader_test(test_df)\n",
    "# test_dataloader = DataLoader(test_dataset,batch_size =TEST_BATCH_SIZE,shuffle=False)\n",
    "\n",
    "# def predict_test(test_dataset , model):\n",
    "#     predictions = []\n",
    "#     for i in test_dataset:\n",
    "#         model.eval()\n",
    "#         prediction = model(i.to(DEVICE))\n",
    "#         prediction  = normalize_function.denormalize_tensor(prediction)\n",
    "#         predictions.extend(prediction.detach().cpu().numpy())\n",
    "#     predictions = np.array(predictions)\n",
    "#     output = np.reshape(predictions,(-1,predictions.shape[-1]))\n",
    "#     return pd.DataFrame(output , columns=['X4', 'X11', 'X18', 'X26', 'X50', 'X3112' ])\n",
    "# output = predict_test(test_dataloader , model)\n",
    "# output = pd.concat([test_df[\"id\"],output],axis=1 )\n",
    "# #output.to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class R2Loss(nn.Module):\n",
    "    def __init__(self, num_classes=6):\n",
    "        super(R2Loss, self).__init__()\n",
    "        # Initialize learnable weights for each class, one weight per class\n",
    "        # self.class_weights = nn.Parameter(torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 1.0], dtype=torch.float32))\n",
    "        # Increase weight for X_26_mean\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        # Calculate residual sum of squares per class\n",
    "        SS_res = torch.sum((y_true - y_pred) ** 2, dim=0)  # (B, C) -> (C,)\n",
    "        # Calculate total sum of squares per class\n",
    "        SS_tot = torch.sum(\n",
    "            (y_true - torch.mean(y_true, dim=0)) ** 2, dim=0\n",
    "        )  # (B, C) -> (C,)\n",
    "        # Calculate R2 loss per class, avoiding division by zero\n",
    "        r2_loss =SS_res / (SS_tot + 1e-6)  # (C,)\n",
    "        # Weight the R2 loss by the learnable class weights\n",
    "        # weighted_r2_loss = self.class_weights * r2_loss\n",
    "        # Return the mean of the weighted R2 loss\n",
    "        return torch.mean(r2_loss)\n",
    "\n",
    "def initialize_model(model_name  ):\n",
    "    model_ft  = None\n",
    "    if model_name == \"resnet34\" :\n",
    "        \"\"\" Resnet34 \"\"\"\n",
    "        model = timm.create_model('resnet34' , num_classes=6 )\n",
    "        return model\n",
    "    # if model_name == \"Swin_Transformer\":\n",
    "    #     model = timm.create_model('swin_large_patch4_window12_384.ms_in22k_ft_in1k' , num_classes = 6 , pretrained=True)\n",
    "    #     return model \n",
    "    if model_name ==\"convnextv2\":\n",
    "        model = timm.create_model('convnext_tiny.in12k_ft_in1k_384',pretrained=True)\n",
    "        model.head.fc = nn.Linear(in_features=768 , out_features= 6 , bias=True)\n",
    "        return model \n",
    "    if model_name ==\"efficientnet_b0\":\n",
    "        model = timm.create_model('cefficientnet_b0',pretrained=True)\n",
    "        model.trainable = False\n",
    "        #model.head.fc = nn.Linear(in_features=768 , out_features= 6 , bias=True)\n",
    "        model_expand = \n",
    "        return model \n",
    "\n",
    "def get_model_optimizer_lossFunction(model_name,learning_rate):\n",
    "    global DEVICE\n",
    "    model = initialize_model(model_name)\n",
    "    model.to(device = DEVICE)\n",
    "    loss_function = R2Loss()\n",
    "    loss_function.to(device=DEVICE)\n",
    "    optimizer =  torch.optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n",
    "    #scheduler  = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = 0.1 , patience=3 , verbose = True )  #torch.optim.lr_scheduler.LinearLR(optimizer, total_iters=25 , start_factor= 1 ,end_factor= 1e-4, verbose = True ) #1e-3*1e-4 = 1e-7\n",
    "    scheduler  = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        initial_learning_rate = 1e-5,\n",
    "        decay_steps = total_steps - warmup_steps,\n",
    "        warmup_target= CFG['MAX_LR'],\n",
    "        warmup_steps = warmup_steps   )\n",
    "    # optimizer.to(device = DEVICE)\n",
    "    return model,optimizer,loss_function , scheduler\n",
    "class BestModelSaveCallback:\n",
    "    def __init__(self, save_path):\n",
    "        self.save_path = save_path\n",
    "        self.best_accuracy = -1\n",
    "\n",
    "    def __call__(self, accuracy,model):\n",
    "        if accuracy > self.best_accuracy:\n",
    "            self.best_accuracy = accuracy\n",
    "            model.to(device = \"cpu\")\n",
    "            torch.save(model.state_dict(), self.save_path)\n",
    "            model.to(device=DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(inputs,model,loss_function,optimizer):\n",
    "    x,y = inputs\n",
    "    x = x.to(DEVICE)\n",
    "    y = y.to(DEVICE)\n",
    "    model.train()\n",
    "    prediction = model(x)\n",
    "    loss = loss_function(prediction,y)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    return loss.detach().cpu().numpy()\n",
    "\n",
    "@torch.no_grad\n",
    "def do_prediction(inputs,model, is_val=False):\n",
    "    global Train_std_tensor , Train_mean_tensor\n",
    "    x,y = inputs\n",
    "    x = x.to(DEVICE)\n",
    "    y = y.to(DEVICE)\n",
    "    model.eval()\n",
    "    prediction = model(x)\n",
    "    if is_val :\n",
    "        prediction = normalize_function.denormalize_tensor(batch=prediction)\n",
    "    return prediction.detach().cpu().numpy()\n",
    "\n",
    "@torch.no_grad()\n",
    "def validation_loss_batch(inputs,model,loss_function):\n",
    "    global Train_std_tensor , Train_mean_tensor\n",
    "    x,y = inputs\n",
    "    x = x.to(DEVICE)\n",
    "    y = y.to(DEVICE)\n",
    "    model.eval()\n",
    "    prediction = model(x)\n",
    "    prediction = normalize_function.denormalize_tensor(batch=prediction)\n",
    "    loss = loss_function(prediction, y)\n",
    "    return loss.detach().cpu().numpy()\n",
    "\n",
    "def utils_convert_to_2d_tensors(predictions,targets):\n",
    "    predictions  = np.array(predictions)\n",
    "    targets = np.array(targets)\n",
    "    predictions  = np.reshape(predictions , (-1, predictions.shape[-1]))\n",
    "    targets  = np.reshape(targets  , (-1 , targets.shape[-1]))\n",
    "    return torch.Tensor(predictions), torch.Tensor(targets)\n",
    "\n",
    "def train(trainLoader,valLoader,model,optimizer,loss_function,epochs,best_model_callback):\n",
    "    #wandb.watch(model,loss_function,log = \"all\",log_freq=50)\n",
    "    \n",
    "    train_epoch_loss , train_epoch_accuracy =[] , []\n",
    "    val_epoch_loss , val_epoch_accuracy = [],[]\n",
    "    \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f\"epoch: {epoch} , lr is { scheduler.get_last_lr()}\" )\n",
    "        train_loss  = [] \n",
    "        val_loss ,val_accuracy = [] , []\n",
    "        \n",
    "        # batch training loss\n",
    "        with tqdm.tqdm(total=len(trainLoader)) as trainingLoop:\n",
    "            for index,batch in enumerate(iter(trainLoader)): \n",
    "        \n",
    "                loss = train_batch(batch,model,loss_function,optimizer)\n",
    "                train_loss.append(loss)\n",
    "\n",
    "                trainingLoop.set_description(f\"Batch: {index}/{len(trainLoader)}\")\n",
    "                trainingLoop.set_postfix({\"training Loss \" : loss})\n",
    "                trainingLoop.update(1)\n",
    "                ##wandb.log({\"Training Loss\":loss })\n",
    "        train_loss  = np.array(train_loss).mean() \n",
    "        train_epoch_loss.append(train_loss)\n",
    "        \n",
    "        # find training accuracy \n",
    "        predictions,targets = [],[]\n",
    "        for index,batch in enumerate(iter(trainLoader)): \n",
    "        \n",
    "            prediction = do_prediction(batch,model)\n",
    "            predictions.extend(prediction)\n",
    "            targets.extend(batch[1].detach().cpu().numpy())\n",
    "           \n",
    "        \n",
    "        predictions = np.array(predictions)\n",
    "        targets = np.array(targets)\n",
    "        predictions , targets = utils_convert_to_2d_tensors(predictions , targets)\n",
    "        # print(\"predictions=\", predictions[0:2])\n",
    "        # print(\"targets=\",targets[0:2])\n",
    "        metric = R2Score()\n",
    "        metric.update(predictions , targets)\n",
    "        train_epoch_accuracy.append(metric.compute().detach().cpu().numpy())\n",
    "                \n",
    "        \n",
    "        # validation set loss & accuracy  \n",
    "        predictions,targets = [],[]\n",
    "        with tqdm.tqdm(total = len(valLoader)) as validationLoop:\n",
    "            for index,batch in enumerate(iter(valLoader)):\n",
    "                \n",
    "                loss = validation_loss_batch(batch,model,loss_function)\n",
    "                val_loss.append(loss)\n",
    "                prediction = do_prediction(batch,model,is_val=True)\n",
    "                predictions.extend(prediction)\n",
    "                targets.extend(batch[1].detach().cpu().numpy())\n",
    "                \n",
    "                validationLoop.set_description(f\"Batch: {index}/{len(valLoader)}\")\n",
    "                validationLoop.set_postfix({\"Validation loss \" : loss}) \n",
    "                ##wandb.log({\"Vlaidation loss\" : loss})\n",
    "                #wandb.log({\"Validation Loss \": val_loss.item()})\n",
    "                validationLoop.update(1)\n",
    "        \n",
    "        \n",
    "        val_loss  = np.array(val_loss).mean() \n",
    "        val_epoch_loss.append(val_loss)\n",
    "        \n",
    "        predictions = np.array(predictions)\n",
    "        targets = np.array(targets)\n",
    "        # print(\"predictions-val=\", predictions[0:2])\n",
    "        # print(\"targets-val=\",targets[0:2])\n",
    "        metric = R2Score()\n",
    "        predictions , targets = utils_convert_to_2d_tensors(predictions , targets)\n",
    "        metric.update(predictions , targets)\n",
    "        val_epoch_accuracy.append(metric.compute().detach().cpu().numpy().item())\n",
    "        \n",
    "        scheduler.step(train_loss)\n",
    "        \n",
    "        \n",
    "        best_model_callback(metric.compute().detach().cpu().numpy().item(),model)        # save the best model according to the validation accuracy\n",
    "        \n",
    "        \n",
    "    return train_epoch_loss,val_epoch_loss,train_epoch_accuracy , val_epoch_accuracy\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:timm.models._builder:Loading pretrained weights from Hugging Face hub (timm/convnext_tiny.in12k_ft_in1k_384)\n",
      "INFO:timm.models._hub:[timm/convnext_tiny.in12k_ft_in1k_384] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n",
      "/home/prajwal/anaconda3/envs/pytorch_gpu/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 , lr is [1e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 271/272: 100%|██████████| 272/272 [01:46<00:00,  2.56it/s, training Loss =554.27576] \n",
      "Batch: 67/68: 100%|██████████| 68/68 [00:14<00:00,  4.63it/s, Validation loss =0.95453155]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 , lr is [1e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 271/272: 100%|██████████| 272/272 [01:45<00:00,  2.57it/s, training Loss =1.9976343] \n",
      "Batch: 67/68: 100%|██████████| 68/68 [00:14<00:00,  4.65it/s, Validation loss =1.2981433]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 , lr is [1e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 271/272: 100%|██████████| 272/272 [01:45<00:00,  2.58it/s, training Loss =47.9826]   \n",
      "Batch: 67/68: 100%|██████████| 68/68 [00:14<00:00,  4.62it/s, Validation loss =1.0206107] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 , lr is [1e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch: 233/272:  86%|████████▌ | 234/272 [01:31<00:14,  2.56it/s, training Loss =1.0874095]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model,optimizer,loss_function,scheduler \u001b[38;5;241m=\u001b[39m get_model_optimizer_lossFunction(model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvnextv2\u001b[39m\u001b[38;5;124m\"\u001b[39m,learning_rate \u001b[38;5;241m=\u001b[39m LEARNING_RATE)\n\u001b[1;32m      2\u001b[0m best_model_callback \u001b[38;5;241m=\u001b[39m BestModelSaveCallback(save_path\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(BASE_DIR,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_model_transformation_convnextv2.pth\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m----> 3\u001b[0m train_losses, val_losses , train_accuracies,val_accuracies \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbest_model_callback\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 62\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(trainLoader, valLoader, model, optimizer, loss_function, epochs, best_model_callback)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(trainLoader)) \u001b[38;5;28;01mas\u001b[39;00m trainingLoop:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m index,batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28miter\u001b[39m(trainLoader)): \n\u001b[0;32m---> 62\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m         train_loss\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[1;32m     65\u001b[0m         trainingLoop\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(trainLoader)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[13], line 13\u001b[0m, in \u001b[0;36mtrain_batch\u001b[0;34m(inputs, model, loss_function, optimizer)\u001b[0m\n\u001b[1;32m     10\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     11\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model,optimizer,loss_function,scheduler = get_model_optimizer_lossFunction(model_name = \"convnextv2\",learning_rate = LEARNING_RATE)\n",
    "best_model_callback = BestModelSaveCallback(save_path=os.path.join(BASE_DIR,'best_model_transformation_convnextv2.pth'))\n",
    "train_losses, val_losses , train_accuracies,val_accuracies = train(train_dataloader,val_dataloader,model,optimizer,loss_function,EPOCHS,best_model_callback)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# predictions= torch.tensor([[ 1.2391, 30.3367, 30.3599, 29.7099, 20.0526, 31.2610],\n",
    "#         [ 1.2679, 30.3845, 30.3134, 29.7083, 20.3929, 31.2463]])\n",
    "# targets= torch.tensor([[1.1125e+00, 1.4686e+02, 1.9699e+04, 3.4597e+03, 1.5282e+01, 3.9792e+05],\n",
    "#         [9.7378e-01, 1.5390e+02, 1.9702e+04, 3.4673e+03, 1.4737e+01, 3.9847e+05]])\n",
    "# metric = R2Score()\n",
    "# metric.update(predictions , targets)\n",
    "# metric.compute()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# from sklearn.metrics import r2_score\n",
    "# predictions= np.array([[ 1.2391, 30.3367, 30.3599, 29.7099, 20.0526, 31.2610],\n",
    "#         [ 1.2679, 30.3845, 30.3134, 29.7083, 20.3929, 31.2463]])\n",
    "# targets= np.array([[1.1125e+00, 1.4686e+02, 1.9699e+04, 3.4597e+03, 1.5282e+01, 3.9792e+05],\n",
    "#         [9.7378e-01, 1.5390e+02, 1.9702e+04, 3.4673e+03, 1.4737e+01, 3.9847e+05]])\n",
    "# r2_score(y_true = targets , y_pred =predictions)\n",
    "\n",
    "\n",
    "\n",
    "# targets = torch.tensor([[0.0, 2.0], [1.0, 6.0]])\n",
    "# predictions = torch.tensor([[0.0, 1.0], [2.0, 5.0]])\n",
    "# torch.mean(1- (torch.sum((targets - predictions)**2,axis=0)/torch.sum((targets - targets.mean())**2,axis=0)))\n",
    "\n",
    "\n",
    "# metric = R2Score()\n",
    "# # input = torch.tensor([[0, 2], [1, 6]])\n",
    "# # target = torch.tensor([[0, 1], [2, 5]])\n",
    "# input = torch.tensor([[ 1.2391, 30.3367, 30.3599, 29.7099, 20.0526, 31.2610],\n",
    "#         [ 1.2679, 30.3845, 30.3134, 29.7083, 20.3929, 31.2463]])\n",
    "# target= torch.tensor([[1.1125e+00, 1.4686e+02, 1.9699e+04, 3.4597e+03, 1.5282e+01, 3.9792e+05],\n",
    "#         [9.7378e-01, 1.5390e+02, 1.9702e+04, 3.4673e+03, 1.4737e+01, 3.9847e+05]])\n",
    "# metric.update(input, target)\n",
    "# metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plot(train_losses,train_accuracies,val_losses,val_accuracies,path):\n",
    "    plt.plot(train_losses,label = \"train loss\")\n",
    "    plt.plot(val_losses,label = \"validation loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    #plt.savefig(os.path.join(path,\"Loss.png\"))\n",
    "    #wandb.log({\"Loss\": plt})\n",
    "\n",
    "    plt.plot(val_accuracies,label = \"validation accuracy\")\n",
    "    plt.plot(train_accuracies,label = \"train accuracy\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend() \n",
    "    #plt.savefig(os.path.join(path,\"Accuracy.png\"))\n",
    "    #wandb.log({\"Accuracy\": plt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Plot(train_losses,train_accuracies,val_losses,val_accuracies,path = BASE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
